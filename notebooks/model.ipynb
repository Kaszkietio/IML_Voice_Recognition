{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IML - Model exploration - ANNs\n",
    "\n",
    "Model has to be a Convolutional Neural Network, consuming as input a spectrogram and performing a\n",
    "classification task.\n",
    "\n",
    "In this notebook I will explore ANNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.api.utils import image_dataset_from_directory\n",
    "import keras\n",
    "from keras.api.layers import Dense\n",
    "from keras.api import Model\n",
    "from keras.api.optimizers import SGD\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.optimizers.schedules import ExponentialDecay\n",
    "from keras.api.metrics import F1Score, AUC, Precision, Recall, BinaryAccuracy\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading dataset\n",
    "\n",
    "Use convenient function image_dataset_from_directory from keras. Handles train/validation split, \n",
    "shuffle, converting to grayscale etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63840 files belonging to 2 classes.\n",
      "Using 51072 files for training.\n",
      "Using 12768 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731771246.350241     985 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), \"..\", \"data\", \"overlap_000_res_256x256_train_test_split\")\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "train_ds, valid_ds = image_dataset_from_directory(train_path, color_mode=\"grayscale\", seed=42,\n",
    "                                                   image_size=image_size, batch_size=batch_size,\n",
    "                                                   subset=\"both\", validation_split=0.2)\n",
    "\n",
    "train_ds = train_ds.map(lambda X, y: (tf.cast(X, tf.float32), tf.cast(y, tf.float32)))\n",
    "train_ds: tf.data.Dataset = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(lambda X, y: (tf.cast(X, tf.float32), tf.cast(y, tf.float32)))\n",
    "valid_ds: tf.data.Dataset = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model\n",
    "\n",
    "Time for fun :)\n",
    "\n",
    "#### 1. Simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), \"..\", \"logs\")\n",
    "FIT_LOG_DIR = os.path.join(LOG_DIR, \"fit\")\n",
    "\n",
    "\n",
    "def train_model(train_ds, valid_ds, model_constructor, batch_size: int, epochs: int,\n",
    "                optimizer, loss, log_dir: str = FIT_LOG_DIR):\n",
    "    model = model_constructor()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds,batch_size=batch_size, epochs=epochs,\n",
    "                callbacks=[tensorboard_cb])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m16,777,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,729</span> (64.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,777,729\u001b[0m (64.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,729</span> (64.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,777,729\u001b[0m (64.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_nn() -> Model:\n",
    "    input_shape = (256, 256, 1)\n",
    "    inputs = keras.Input(input_shape, dtype=np.float32)\n",
    "    x = keras.layers.Rescaling(scale=1./255)(inputs)\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"SimpleNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = simple_nn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731257654.304787   12587 service.cc:148] XLA service 0x7f6418007680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731257654.305341   12587 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-10 17:54:14.377465: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731257654.563706   12587 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-10 17:54:15.732436: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-10 17:54:15.851370: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  17/1288\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6468 - loss: 1.0842 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731257656.585596   12587 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6970 - loss: 0.6123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:54:39.378682: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.6970 - loss: 0.6122 - val_accuracy: 0.7275 - val_loss: 0.5687\n",
      "Epoch 2/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.7182 - loss: 0.5269 - val_accuracy: 0.7825 - val_loss: 0.4108\n",
      "Epoch 3/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.7446 - loss: 0.4920 - val_accuracy: 0.8421 - val_loss: 0.3820\n",
      "Epoch 4/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.7844 - loss: 0.4373 - val_accuracy: 0.8189 - val_loss: 0.3498\n",
      "Epoch 5/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8063 - loss: 0.3995 - val_accuracy: 0.8592 - val_loss: 0.3706\n",
      "Epoch 6/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8297 - loss: 0.3672 - val_accuracy: 0.8484 - val_loss: 0.3082\n",
      "Epoch 7/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.8409 - loss: 0.3481 - val_accuracy: 0.8875 - val_loss: 0.2813\n",
      "Epoch 8/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8500 - loss: 0.3210 - val_accuracy: 0.8073 - val_loss: 0.3922\n",
      "Epoch 9/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8635 - loss: 0.3029 - val_accuracy: 0.9035 - val_loss: 0.2382\n",
      "Epoch 10/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8689 - loss: 0.2912 - val_accuracy: 0.8950 - val_loss: 0.2490\n",
      "Epoch 11/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.8794 - loss: 0.2703 - val_accuracy: 0.7172 - val_loss: 0.8695\n",
      "Epoch 12/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8838 - loss: 0.2675 - val_accuracy: 0.7213 - val_loss: 0.8602\n",
      "Epoch 13/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8858 - loss: 0.2588 - val_accuracy: 0.9159 - val_loss: 0.2066\n",
      "Epoch 14/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 21ms/step - accuracy: 0.8895 - loss: 0.2450 - val_accuracy: 0.8249 - val_loss: 0.3335\n",
      "Epoch 15/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8960 - loss: 0.2382 - val_accuracy: 0.8837 - val_loss: 0.2503\n",
      "Epoch 16/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8988 - loss: 0.2323 - val_accuracy: 0.9129 - val_loss: 0.1988\n",
      "Epoch 17/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9040 - loss: 0.2211 - val_accuracy: 0.9215 - val_loss: 0.1760\n",
      "Epoch 18/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9116 - loss: 0.2066 - val_accuracy: 0.9222 - val_loss: 0.1781\n",
      "Epoch 19/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9113 - loss: 0.2107 - val_accuracy: 0.9198 - val_loss: 0.1875\n",
      "Epoch 20/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9126 - loss: 0.2030 - val_accuracy: 0.9312 - val_loss: 0.1606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=SimpleNN, built=True>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_ds, valid_ds, simple_nn, batch_size, 20, optimizer=\"sgd\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results are really surprising, we still haven't reached overfitting. Let's prolong our training\n",
    "to 50 epochs and see when model overfitts. \n",
    "\n",
    "Still no need for tweaking optimizer or loss metaparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731259377.689293   24084 service.cc:148] XLA service 0x7f4168006560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731259377.689395   24084 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-10 18:22:57.742256: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731259377.877004   24084 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-10 18:22:59.025333: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-10 18:22:59.044234: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  27/1288\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6698 - loss: 1.1676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731259379.804535   24084 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1283/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6973 - loss: 0.6218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 18:23:24.288150: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.6973 - loss: 0.6216 - val_accuracy: 0.7737 - val_loss: 0.5329\n",
      "Epoch 2/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7194 - loss: 0.5302 - val_accuracy: 0.7112 - val_loss: 0.4726\n",
      "Epoch 3/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.4811 - val_accuracy: 0.8473 - val_loss: 0.3753\n",
      "Epoch 4/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.7881 - loss: 0.4333 - val_accuracy: 0.8114 - val_loss: 0.3590\n",
      "Epoch 5/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.8081 - loss: 0.3976 - val_accuracy: 0.8232 - val_loss: 0.3955\n",
      "Epoch 6/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8316 - loss: 0.3656 - val_accuracy: 0.8317 - val_loss: 0.3240\n",
      "Epoch 7/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8404 - loss: 0.3469 - val_accuracy: 0.8896 - val_loss: 0.2678\n",
      "Epoch 8/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8516 - loss: 0.3226 - val_accuracy: 0.8402 - val_loss: 0.3331\n",
      "Epoch 9/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8644 - loss: 0.3012 - val_accuracy: 0.8987 - val_loss: 0.2584\n",
      "Epoch 10/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8708 - loss: 0.2901 - val_accuracy: 0.8943 - val_loss: 0.2417\n",
      "Epoch 11/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8793 - loss: 0.2719 - val_accuracy: 0.7546 - val_loss: 0.5981\n",
      "Epoch 12/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8871 - loss: 0.2606 - val_accuracy: 0.7697 - val_loss: 0.5478\n",
      "Epoch 13/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8875 - loss: 0.2557 - val_accuracy: 0.8902 - val_loss: 0.2391\n",
      "Epoch 14/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8905 - loss: 0.2446 - val_accuracy: 0.8047 - val_loss: 0.3771\n",
      "Epoch 15/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8991 - loss: 0.2311 - val_accuracy: 0.8601 - val_loss: 0.2966\n",
      "Epoch 16/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9021 - loss: 0.2280 - val_accuracy: 0.9162 - val_loss: 0.1919\n",
      "Epoch 17/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.9070 - loss: 0.2162 - val_accuracy: 0.9216 - val_loss: 0.1782\n",
      "Epoch 18/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9084 - loss: 0.2091 - val_accuracy: 0.9216 - val_loss: 0.1895\n",
      "Epoch 19/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9117 - loss: 0.2131 - val_accuracy: 0.9076 - val_loss: 0.2071\n",
      "Epoch 20/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9094 - loss: 0.2102 - val_accuracy: 0.9347 - val_loss: 0.1567\n",
      "Epoch 21/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9176 - loss: 0.1960 - val_accuracy: 0.9312 - val_loss: 0.1625\n",
      "Epoch 22/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9237 - loss: 0.1805 - val_accuracy: 0.7043 - val_loss: 1.6163\n",
      "Epoch 23/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9233 - loss: 0.1876 - val_accuracy: 0.8984 - val_loss: 0.2455\n",
      "Epoch 24/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9253 - loss: 0.1736 - val_accuracy: 0.9228 - val_loss: 0.1739\n",
      "Epoch 25/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9230 - loss: 0.1823 - val_accuracy: 0.9352 - val_loss: 0.1473\n",
      "Epoch 26/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9263 - loss: 0.1733 - val_accuracy: 0.8649 - val_loss: 0.3168\n",
      "Epoch 27/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9347 - loss: 0.1546 - val_accuracy: 0.9308 - val_loss: 0.1615\n",
      "Epoch 28/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9351 - loss: 0.1527 - val_accuracy: 0.9343 - val_loss: 0.1536\n",
      "Epoch 29/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9424 - loss: 0.1376 - val_accuracy: 0.8893 - val_loss: 0.2401\n",
      "Epoch 30/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9395 - loss: 0.1538 - val_accuracy: 0.9074 - val_loss: 0.2037\n",
      "Epoch 31/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9434 - loss: 0.1383 - val_accuracy: 0.9383 - val_loss: 0.1456\n",
      "Epoch 32/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.9446 - loss: 0.1420 - val_accuracy: 0.8885 - val_loss: 0.2314\n",
      "Epoch 33/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9436 - loss: 0.1317 - val_accuracy: 0.9385 - val_loss: 0.1474\n",
      "Epoch 34/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9455 - loss: 0.1322 - val_accuracy: 0.9028 - val_loss: 0.1935\n",
      "Epoch 35/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9473 - loss: 0.1277 - val_accuracy: 0.8984 - val_loss: 0.2386\n",
      "Epoch 36/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9428 - loss: 0.1429 - val_accuracy: 0.9397 - val_loss: 0.1370\n",
      "Epoch 37/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9529 - loss: 0.1161 - val_accuracy: 0.8637 - val_loss: 0.2877\n",
      "Epoch 38/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9328 - loss: 0.1724 - val_accuracy: 0.8714 - val_loss: 0.3671\n",
      "Epoch 39/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9523 - loss: 0.1193 - val_accuracy: 0.8502 - val_loss: 0.4192\n",
      "Epoch 40/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.9502 - loss: 0.1256 - val_accuracy: 0.9509 - val_loss: 0.1149\n",
      "Epoch 41/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9557 - loss: 0.1149 - val_accuracy: 0.9566 - val_loss: 0.1129\n",
      "Epoch 42/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9470 - loss: 0.1319 - val_accuracy: 0.9071 - val_loss: 0.2067\n",
      "Epoch 43/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9513 - loss: 0.1197 - val_accuracy: 0.9384 - val_loss: 0.1461\n",
      "Epoch 44/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.9572 - loss: 0.1047 - val_accuracy: 0.9513 - val_loss: 0.1111\n",
      "Epoch 45/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9504 - loss: 0.1314 - val_accuracy: 0.9493 - val_loss: 0.1144\n",
      "Epoch 46/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9595 - loss: 0.1059 - val_accuracy: 0.9498 - val_loss: 0.1163\n",
      "Epoch 47/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9512 - loss: 0.1247 - val_accuracy: 0.9512 - val_loss: 0.1109\n",
      "Epoch 48/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9511 - loss: 0.1250 - val_accuracy: 0.9396 - val_loss: 0.1410\n",
      "Epoch 49/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9626 - loss: 0.0931 - val_accuracy: 0.9189 - val_loss: 0.1727\n",
      "Epoch 50/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9612 - loss: 0.0959 - val_accuracy: 0.9320 - val_loss: 0.1723\n"
     ]
    }
   ],
   "source": [
    "model_50_epochs = train_model(train_ds, valid_ds, simple_nn, batch_size, 50,\n",
    "                              optimizer=\"sgd\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do **have to** take into account is that our classes are imbalanced - 30/70 ratio of \n",
    "class 1 to class 0. Let's try weighting loss for particular classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:47:52.707424: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: np.float64(0.7244666364049024), 1: np.float64(1.6137512639029323)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.concatenate([y for X, y in train_ds.as_numpy_iterator()])\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5963 - loss: 0.7021 - val_accuracy: 0.7650 - val_loss: 0.5280\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.6877 - loss: 0.5969 - val_accuracy: 0.7863 - val_loss: 0.4358\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7340 - loss: 0.5401 - val_accuracy: 0.6280 - val_loss: 0.6962\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7681 - loss: 0.4863 - val_accuracy: 0.8602 - val_loss: 0.3119\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7990 - loss: 0.4309 - val_accuracy: 0.4704 - val_loss: 1.4446\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8205 - loss: 0.3916 - val_accuracy: 0.8672 - val_loss: 0.2782\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8364 - loss: 0.3596 - val_accuracy: 0.8568 - val_loss: 0.2940\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8351 - loss: 0.3658 - val_accuracy: 0.8834 - val_loss: 0.2725\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8474 - loss: 0.3397 - val_accuracy: 0.9050 - val_loss: 0.2263\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8633 - loss: 0.2997 - val_accuracy: 0.8885 - val_loss: 0.2613\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8683 - loss: 0.3002 - val_accuracy: 0.8854 - val_loss: 0.2656\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8771 - loss: 0.2737 - val_accuracy: 0.9073 - val_loss: 0.2065\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8804 - loss: 0.2763 - val_accuracy: 0.9173 - val_loss: 0.2006\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8906 - loss: 0.2448 - val_accuracy: 0.7247 - val_loss: 0.5996\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8958 - loss: 0.2374 - val_accuracy: 0.9272 - val_loss: 0.1716\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.2377 - val_accuracy: 0.9270 - val_loss: 0.1695\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8955 - loss: 0.2444 - val_accuracy: 0.9255 - val_loss: 0.1684\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8924 - loss: 0.2518 - val_accuracy: 0.9167 - val_loss: 0.1890\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8905 - loss: 0.2614 - val_accuracy: 0.9219 - val_loss: 0.1784\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2199 - val_accuracy: 0.8420 - val_loss: 0.3935\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9136 - loss: 0.2034 - val_accuracy: 0.9274 - val_loss: 0.1716\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.1698 - val_accuracy: 0.9419 - val_loss: 0.1434\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.2151 - val_accuracy: 0.9263 - val_loss: 0.1839\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.1587 - val_accuracy: 0.9344 - val_loss: 0.1533\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9360 - loss: 0.1467 - val_accuracy: 0.9435 - val_loss: 0.1305\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9327 - loss: 0.1644 - val_accuracy: 0.9474 - val_loss: 0.1236\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.1852 - val_accuracy: 0.9250 - val_loss: 0.1690\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9339 - loss: 0.1619 - val_accuracy: 0.9278 - val_loss: 0.1728\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9404 - loss: 0.1366 - val_accuracy: 0.9459 - val_loss: 0.1252\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9480 - loss: 0.1231 - val_accuracy: 0.9293 - val_loss: 0.1586\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9314 - loss: 0.1734 - val_accuracy: 0.9517 - val_loss: 0.1157\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9409 - loss: 0.1415 - val_accuracy: 0.9545 - val_loss: 0.1065\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9273 - loss: 0.1865 - val_accuracy: 0.9515 - val_loss: 0.1154\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9478 - loss: 0.1265 - val_accuracy: 0.9352 - val_loss: 0.1554\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.9483 - loss: 0.1225 - val_accuracy: 0.9478 - val_loss: 0.1191\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9525 - loss: 0.1116 - val_accuracy: 0.9456 - val_loss: 0.1288\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9409 - loss: 0.1475 - val_accuracy: 0.9527 - val_loss: 0.1087\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.1593 - val_accuracy: 0.9461 - val_loss: 0.1277\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9483 - loss: 0.1318 - val_accuracy: 0.9591 - val_loss: 0.1034\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9431 - loss: 0.1447 - val_accuracy: 0.9497 - val_loss: 0.1114\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9520 - loss: 0.1164 - val_accuracy: 0.9590 - val_loss: 0.0985\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9544 - loss: 0.1182 - val_accuracy: 0.9543 - val_loss: 0.1112\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9508 - loss: 0.1224 - val_accuracy: 0.9429 - val_loss: 0.1297\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9490 - loss: 0.1268 - val_accuracy: 0.9380 - val_loss: 0.1387\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9552 - loss: 0.1081 - val_accuracy: 0.9466 - val_loss: 0.1212\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.0988 - val_accuracy: 0.9532 - val_loss: 0.1152\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1259 - val_accuracy: 0.9380 - val_loss: 0.1460\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9552 - loss: 0.1082 - val_accuracy: 0.9418 - val_loss: 0.1367\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9523 - loss: 0.1208 - val_accuracy: 0.9595 - val_loss: 0.1006\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9579 - loss: 0.1106 - val_accuracy: 0.9538 - val_loss: 0.1154\n"
     ]
    }
   ],
   "source": [
    "model = simple_nn()\n",
    "model.name = \"SimpleNN_class_weights\"\n",
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_log_dir = os.path.join(FIT_LOG_DIR, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=50,\n",
    "                    class_weight=class_weights, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weights outtakes: in this very take, it has improved validation loss and minimally increased\n",
    "training loss. We can conclude that balancing the data improved generalization.\n",
    "\n",
    "### Optimizer parameters\n",
    "#### 1. Learning rate\n",
    "From the previous experiment we can tell that learning rate was too high - around 50th epoch we could\n",
    "have observed potential overfitting. The plan is to:\n",
    "\n",
    "1. Develop a few models with different constant learning rates\n",
    "2. Develope a few models with exponential decay\n",
    "3. Compare results and pick the best model\n",
    "\n",
    "***Constant learning rates:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731506321.504975   16989 service.cc:148] XLA service 0x7f05240065d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731506321.508018   16989 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-13 14:58:41.538707: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731506321.667850   16989 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-13 14:58:42.893160: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-13 14:58:43.081935: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  18/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4962 - loss: 1.7616 - weighted_accuracy: 0.4721  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731506324.127316   16989 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - accuracy: 0.5997 - loss: 0.7025 - weighted_accuracy: 0.5766 - val_accuracy: 0.4427 - val_loss: 0.7933 - val_weighted_accuracy: 0.4427\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6774 - loss: 0.6118 - weighted_accuracy: 0.6722 - val_accuracy: 0.7151 - val_loss: 0.6126 - val_weighted_accuracy: 0.7151\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7326 - loss: 0.5451 - weighted_accuracy: 0.7332 - val_accuracy: 0.8432 - val_loss: 0.4092 - val_weighted_accuracy: 0.8432\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7732 - loss: 0.4711 - weighted_accuracy: 0.7745 - val_accuracy: 0.8518 - val_loss: 0.3524 - val_weighted_accuracy: 0.8518\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7990 - loss: 0.4288 - weighted_accuracy: 0.8015 - val_accuracy: 0.8300 - val_loss: 0.3303 - val_weighted_accuracy: 0.8300\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8232 - loss: 0.3873 - weighted_accuracy: 0.8250 - val_accuracy: 0.8393 - val_loss: 0.3162 - val_weighted_accuracy: 0.8393\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 0.3592 - weighted_accuracy: 0.8373 - val_accuracy: 0.8994 - val_loss: 0.2510 - val_weighted_accuracy: 0.8994\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8484 - loss: 0.3414 - weighted_accuracy: 0.8505 - val_accuracy: 0.8172 - val_loss: 0.3829 - val_weighted_accuracy: 0.8172\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8602 - loss: 0.3152 - weighted_accuracy: 0.8623 - val_accuracy: 0.8781 - val_loss: 0.2963 - val_weighted_accuracy: 0.8781\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8533 - loss: 0.3269 - weighted_accuracy: 0.8558 - val_accuracy: 0.8875 - val_loss: 0.2427 - val_weighted_accuracy: 0.8875\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3040 - weighted_accuracy: 0.8664 - val_accuracy: 0.8747 - val_loss: 0.3176 - val_weighted_accuracy: 0.8747\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8748 - loss: 0.2828 - weighted_accuracy: 0.8770 - val_accuracy: 0.8913 - val_loss: 0.2654 - val_weighted_accuracy: 0.8913\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8902 - loss: 0.2483 - weighted_accuracy: 0.8930 - val_accuracy: 0.7609 - val_loss: 0.5612 - val_weighted_accuracy: 0.7609\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8962 - loss: 0.2352 - weighted_accuracy: 0.8985 - val_accuracy: 0.9158 - val_loss: 0.1830 - val_weighted_accuracy: 0.9158\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9012 - loss: 0.2252 - weighted_accuracy: 0.9040 - val_accuracy: 0.8417 - val_loss: 0.4044 - val_weighted_accuracy: 0.8417\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9059 - loss: 0.2157 - weighted_accuracy: 0.9085 - val_accuracy: 0.9099 - val_loss: 0.2148 - val_weighted_accuracy: 0.9099\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9069 - loss: 0.2156 - weighted_accuracy: 0.9103 - val_accuracy: 0.9336 - val_loss: 0.1535 - val_weighted_accuracy: 0.9336\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9084 - loss: 0.2165 - weighted_accuracy: 0.9103 - val_accuracy: 0.7928 - val_loss: 0.4958 - val_weighted_accuracy: 0.7928\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9053 - loss: 0.2230 - weighted_accuracy: 0.9067 - val_accuracy: 0.9232 - val_loss: 0.1883 - val_weighted_accuracy: 0.9232\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9007 - loss: 0.2340 - weighted_accuracy: 0.9022 - val_accuracy: 0.9311 - val_loss: 0.1620 - val_weighted_accuracy: 0.9311\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9221 - loss: 0.1880 - weighted_accuracy: 0.9236 - val_accuracy: 0.9309 - val_loss: 0.1663 - val_weighted_accuracy: 0.9309\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9233 - loss: 0.1799 - weighted_accuracy: 0.9252 - val_accuracy: 0.7903 - val_loss: 0.5074 - val_weighted_accuracy: 0.7903\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9242 - loss: 0.1810 - weighted_accuracy: 0.9260 - val_accuracy: 0.9449 - val_loss: 0.1320 - val_weighted_accuracy: 0.9449\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9265 - loss: 0.1778 - weighted_accuracy: 0.9286 - val_accuracy: 0.9334 - val_loss: 0.1628 - val_weighted_accuracy: 0.9334\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9205 - loss: 0.1918 - weighted_accuracy: 0.9225 - val_accuracy: 0.9365 - val_loss: 0.1412 - val_weighted_accuracy: 0.9365\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9187 - loss: 0.1898 - weighted_accuracy: 0.9205 - val_accuracy: 0.9418 - val_loss: 0.1296 - val_weighted_accuracy: 0.9418\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9261 - loss: 0.1748 - weighted_accuracy: 0.9273 - val_accuracy: 0.9268 - val_loss: 0.1562 - val_weighted_accuracy: 0.9268\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9259 - loss: 0.1770 - weighted_accuracy: 0.9272 - val_accuracy: 0.9387 - val_loss: 0.1388 - val_weighted_accuracy: 0.9387\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9369 - loss: 0.1523 - weighted_accuracy: 0.9380 - val_accuracy: 0.9292 - val_loss: 0.1646 - val_weighted_accuracy: 0.9292\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9457 - loss: 0.1301 - weighted_accuracy: 0.9469 - val_accuracy: 0.9542 - val_loss: 0.1127 - val_weighted_accuracy: 0.9542\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9414 - loss: 0.1415 - weighted_accuracy: 0.9426 - val_accuracy: 0.9056 - val_loss: 0.2114 - val_weighted_accuracy: 0.9056\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9197 - loss: 0.1949 - weighted_accuracy: 0.9217 - val_accuracy: 0.9521 - val_loss: 0.1156 - val_weighted_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9331 - loss: 0.1600 - weighted_accuracy: 0.9353 - val_accuracy: 0.9419 - val_loss: 0.1487 - val_weighted_accuracy: 0.9419\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9225 - loss: 0.1965 - weighted_accuracy: 0.9229 - val_accuracy: 0.9409 - val_loss: 0.1366 - val_weighted_accuracy: 0.9409\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9341 - loss: 0.1630 - weighted_accuracy: 0.9354 - val_accuracy: 0.7690 - val_loss: 0.7127 - val_weighted_accuracy: 0.7690\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.2023 - weighted_accuracy: 0.9211 - val_accuracy: 0.9264 - val_loss: 0.1642 - val_weighted_accuracy: 0.9264\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9294 - loss: 0.1639 - weighted_accuracy: 0.9306 - val_accuracy: 0.9466 - val_loss: 0.1227 - val_weighted_accuracy: 0.9466\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9276 - loss: 0.1784 - weighted_accuracy: 0.9284 - val_accuracy: 0.9250 - val_loss: 0.1639 - val_weighted_accuracy: 0.9250\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9445 - loss: 0.1323 - weighted_accuracy: 0.9448 - val_accuracy: 0.9512 - val_loss: 0.1142 - val_weighted_accuracy: 0.9512\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9233 - loss: 0.1893 - weighted_accuracy: 0.9227 - val_accuracy: 0.9439 - val_loss: 0.1414 - val_weighted_accuracy: 0.9439\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9253 - loss: 0.1930 - weighted_accuracy: 0.9253 - val_accuracy: 0.9484 - val_loss: 0.1156 - val_weighted_accuracy: 0.9484\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9500 - loss: 0.1201 - weighted_accuracy: 0.9518 - val_accuracy: 0.9062 - val_loss: 0.2125 - val_weighted_accuracy: 0.9062\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9513 - loss: 0.1168 - weighted_accuracy: 0.9523 - val_accuracy: 0.9510 - val_loss: 0.1141 - val_weighted_accuracy: 0.9510\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9536 - loss: 0.1173 - weighted_accuracy: 0.9539 - val_accuracy: 0.9526 - val_loss: 0.1175 - val_weighted_accuracy: 0.9526\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9330 - loss: 0.1677 - weighted_accuracy: 0.9336 - val_accuracy: 0.9497 - val_loss: 0.1175 - val_weighted_accuracy: 0.9497\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9220 - loss: 0.2019 - weighted_accuracy: 0.9212 - val_accuracy: 0.9543 - val_loss: 0.1099 - val_weighted_accuracy: 0.9543\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9398 - loss: 0.1507 - weighted_accuracy: 0.9410 - val_accuracy: 0.9509 - val_loss: 0.1316 - val_weighted_accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9520 - loss: 0.1165 - weighted_accuracy: 0.9539 - val_accuracy: 0.9499 - val_loss: 0.1192 - val_weighted_accuracy: 0.9499\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.1426 - weighted_accuracy: 0.9445 - val_accuracy: 0.9261 - val_loss: 0.1507 - val_weighted_accuracy: 0.9261\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9545 - loss: 0.1117 - weighted_accuracy: 0.9551 - val_accuracy: 0.9500 - val_loss: 0.1151 - val_weighted_accuracy: 0.9500\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.4853 - loss: 0.9023 - weighted_accuracy: 0.5090 - val_accuracy: 0.6935 - val_loss: 0.6875 - val_weighted_accuracy: 0.6935\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6332 - loss: 0.6909 - weighted_accuracy: 0.5259 - val_accuracy: 0.3083 - val_loss: 0.6947 - val_weighted_accuracy: 0.3083\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6145 - loss: 0.6863 - weighted_accuracy: 0.5468 - val_accuracy: 0.6812 - val_loss: 0.6925 - val_weighted_accuracy: 0.6812\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6123 - loss: 0.6891 - weighted_accuracy: 0.5313 - val_accuracy: 0.6934 - val_loss: 0.6795 - val_weighted_accuracy: 0.6934\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6713 - loss: 0.6840 - weighted_accuracy: 0.5381 - val_accuracy: 0.6931 - val_loss: 0.6889 - val_weighted_accuracy: 0.6931\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6423 - loss: 0.6909 - weighted_accuracy: 0.5053 - val_accuracy: 0.6979 - val_loss: 0.6784 - val_weighted_accuracy: 0.6979\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6331 - loss: 0.6912 - weighted_accuracy: 0.5181 - val_accuracy: 0.3096 - val_loss: 0.6946 - val_weighted_accuracy: 0.3096\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5458 - loss: 0.6888 - weighted_accuracy: 0.5130 - val_accuracy: 0.3082 - val_loss: 0.6984 - val_weighted_accuracy: 0.3082\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5318 - loss: 0.6918 - weighted_accuracy: 0.4977 - val_accuracy: 0.6812 - val_loss: 0.6180 - val_weighted_accuracy: 0.6812\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4504 - loss: 0.6865 - weighted_accuracy: 0.5198 - val_accuracy: 0.3068 - val_loss: 0.6948 - val_weighted_accuracy: 0.3068\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5578 - loss: 0.6916 - weighted_accuracy: 0.4998 - val_accuracy: 0.5381 - val_loss: 0.7267 - val_weighted_accuracy: 0.5381\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6469 - loss: 0.6860 - weighted_accuracy: 0.5328 - val_accuracy: 0.3067 - val_loss: 0.6956 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5872 - loss: 0.6907 - weighted_accuracy: 0.4971 - val_accuracy: 0.3177 - val_loss: 0.7025 - val_weighted_accuracy: 0.3177\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4596 - loss: 0.6911 - weighted_accuracy: 0.5032 - val_accuracy: 0.3076 - val_loss: 0.6933 - val_weighted_accuracy: 0.3076\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5887 - loss: 0.6918 - weighted_accuracy: 0.4986 - val_accuracy: 0.3076 - val_loss: 0.6953 - val_weighted_accuracy: 0.3076\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5574 - loss: 0.6916 - weighted_accuracy: 0.4976 - val_accuracy: 0.7134 - val_loss: 0.6745 - val_weighted_accuracy: 0.7134\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6677 - loss: 0.6847 - weighted_accuracy: 0.5417 - val_accuracy: 0.4691 - val_loss: 0.8756 - val_weighted_accuracy: 0.4691\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6530 - loss: 0.6877 - weighted_accuracy: 0.5236 - val_accuracy: 0.6934 - val_loss: 0.6784 - val_weighted_accuracy: 0.6934\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.6625 - loss: 0.6813 - weighted_accuracy: 0.5439 - val_accuracy: 0.3079 - val_loss: 0.6952 - val_weighted_accuracy: 0.3079\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5803 - loss: 0.6889 - weighted_accuracy: 0.5083 - val_accuracy: 0.3078 - val_loss: 0.6946 - val_weighted_accuracy: 0.3078\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5477 - loss: 0.6918 - weighted_accuracy: 0.5013 - val_accuracy: 0.3079 - val_loss: 0.6952 - val_weighted_accuracy: 0.3079\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5466 - loss: 0.6918 - weighted_accuracy: 0.4981 - val_accuracy: 0.3079 - val_loss: 0.6946 - val_weighted_accuracy: 0.3079\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5978 - loss: 0.6914 - weighted_accuracy: 0.5110 - val_accuracy: 0.3079 - val_loss: 0.6950 - val_weighted_accuracy: 0.3079\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5564 - loss: 0.6918 - weighted_accuracy: 0.4947 - val_accuracy: 0.6920 - val_loss: 0.6918 - val_weighted_accuracy: 0.6920\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6201 - loss: 0.6916 - weighted_accuracy: 0.5022 - val_accuracy: 0.3080 - val_loss: 0.6956 - val_weighted_accuracy: 0.3080\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5632 - loss: 0.6904 - weighted_accuracy: 0.5001 - val_accuracy: 0.6933 - val_loss: 0.6801 - val_weighted_accuracy: 0.6933\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6435 - loss: 0.6914 - weighted_accuracy: 0.5035 - val_accuracy: 0.7517 - val_loss: 0.6632 - val_weighted_accuracy: 0.7517\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6673 - loss: 0.6743 - weighted_accuracy: 0.5631 - val_accuracy: 0.6923 - val_loss: 0.6888 - val_weighted_accuracy: 0.6923\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6571 - loss: 0.6904 - weighted_accuracy: 0.5085 - val_accuracy: 0.7574 - val_loss: 0.6753 - val_weighted_accuracy: 0.7574\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6668 - loss: 0.6748 - weighted_accuracy: 0.5635 - val_accuracy: 0.3086 - val_loss: 0.6950 - val_weighted_accuracy: 0.3086\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5463 - loss: 0.6916 - weighted_accuracy: 0.4965 - val_accuracy: 0.3087 - val_loss: 0.6954 - val_weighted_accuracy: 0.3087\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5344 - loss: 0.6917 - weighted_accuracy: 0.5005 - val_accuracy: 0.3090 - val_loss: 0.6954 - val_weighted_accuracy: 0.3090\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5472 - loss: 0.6916 - weighted_accuracy: 0.4982 - val_accuracy: 0.3092 - val_loss: 0.6952 - val_weighted_accuracy: 0.3092\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5354 - loss: 0.6914 - weighted_accuracy: 0.4966 - val_accuracy: 0.3090 - val_loss: 0.6954 - val_weighted_accuracy: 0.3090\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5437 - loss: 0.6914 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5446 - loss: 0.6915 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5471 - loss: 0.6919 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6951 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5579 - loss: 0.6918 - weighted_accuracy: 0.4973 - val_accuracy: 0.3067 - val_loss: 0.6956 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5394 - loss: 0.6919 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5573 - loss: 0.6917 - weighted_accuracy: 0.4960 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5426 - loss: 0.6917 - weighted_accuracy: 0.4965 - val_accuracy: 0.3067 - val_loss: 0.6952 - val_weighted_accuracy: 0.3067\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5537 - loss: 0.6918 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 0.6917 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5722 - loss: 0.6919 - weighted_accuracy: 0.4983 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5580 - loss: 0.6916 - weighted_accuracy: 0.4990 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5503 - loss: 0.6919 - weighted_accuracy: 0.4949 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5459 - loss: 0.6917 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.6952 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5572 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5600 - loss: 0.6917 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5352 - loss: 0.6917 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.6950 - val_weighted_accuracy: 0.3067\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5197 - loss: 1.1853 - weighted_accuracy: 0.4959 - val_accuracy: 0.3067 - val_loss: 0.6936 - val_weighted_accuracy: 0.3067\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5595 - loss: 0.6920 - weighted_accuracy: 0.4968 - val_accuracy: 0.6933 - val_loss: 0.6919 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5578 - loss: 0.6920 - weighted_accuracy: 0.4985 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5386 - loss: 0.6920 - weighted_accuracy: 0.4943 - val_accuracy: 0.3067 - val_loss: 0.6968 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5393 - loss: 0.6920 - weighted_accuracy: 0.4946 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5447 - loss: 0.6919 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6920 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5683 - loss: 0.6919 - weighted_accuracy: 0.4964 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5561 - loss: 0.6920 - weighted_accuracy: 0.4951 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5570 - loss: 0.6919 - weighted_accuracy: 0.4969 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5400 - loss: 0.6922 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5536 - loss: 0.6922 - weighted_accuracy: 0.4932 - val_accuracy: 0.3067 - val_loss: 0.6963 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5353 - loss: 0.6921 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5241 - loss: 0.6922 - weighted_accuracy: 0.4950 - val_accuracy: 0.6932 - val_loss: 0.6924 - val_weighted_accuracy: 0.6932\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5555 - loss: 0.6921 - weighted_accuracy: 0.4974 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5703 - loss: 0.6932 - weighted_accuracy: 0.4965 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 74ms/step - accuracy: 0.5486 - loss: 0.6921 - weighted_accuracy: 0.4934 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5383 - loss: 0.6922 - weighted_accuracy: 0.4878 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5604 - loss: 0.6920 - weighted_accuracy: 0.4972 - val_accuracy: 0.6932 - val_loss: 0.6931 - val_weighted_accuracy: 0.6932\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5480 - loss: 0.6921 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5354 - loss: 0.6918 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5510 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5480 - loss: 0.6918 - weighted_accuracy: 0.4950 - val_accuracy: 0.3067 - val_loss: 0.6947 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5544 - loss: 0.6920 - weighted_accuracy: 0.4959 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5502 - loss: 0.6921 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6963 - val_weighted_accuracy: 0.3067\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5428 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5497 - loss: 0.6921 - weighted_accuracy: 0.4972 - val_accuracy: 0.3067 - val_loss: 0.6945 - val_weighted_accuracy: 0.3067\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5365 - loss: 0.6922 - weighted_accuracy: 0.4923 - val_accuracy: 0.3067 - val_loss: 0.6941 - val_weighted_accuracy: 0.3067\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.6921 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.6959 - val_weighted_accuracy: 0.3067\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5369 - loss: 0.6920 - weighted_accuracy: 0.4944 - val_accuracy: 0.3067 - val_loss: 0.6939 - val_weighted_accuracy: 0.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5568 - loss: 0.6918 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5518 - loss: 0.6919 - weighted_accuracy: 0.4940 - val_accuracy: 0.3067 - val_loss: 0.6934 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5542 - loss: 0.6919 - weighted_accuracy: 0.4943 - val_accuracy: 0.6933 - val_loss: 0.6907 - val_weighted_accuracy: 0.6933\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5679 - loss: 0.6920 - weighted_accuracy: 0.4972 - val_accuracy: 0.3067 - val_loss: 0.6970 - val_weighted_accuracy: 0.3067\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5324 - loss: 0.6920 - weighted_accuracy: 0.4925 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5520 - loss: 0.6918 - weighted_accuracy: 0.4951 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5515 - loss: 0.6918 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5471 - loss: 0.6919 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 0.6920 - weighted_accuracy: 0.4925 - val_accuracy: 0.3067 - val_loss: 0.6936 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5461 - loss: 0.6919 - weighted_accuracy: 0.4977 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5405 - loss: 0.6920 - weighted_accuracy: 0.4957 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5326 - loss: 0.6922 - weighted_accuracy: 0.4956 - val_accuracy: 0.6933 - val_loss: 0.6917 - val_weighted_accuracy: 0.6933\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5496 - loss: 0.6922 - weighted_accuracy: 0.4920 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5361 - loss: 0.6923 - weighted_accuracy: 0.4944 - val_accuracy: 0.6933 - val_loss: 0.6925 - val_weighted_accuracy: 0.6933\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.6920 - weighted_accuracy: 0.4945 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5576 - loss: 0.6920 - weighted_accuracy: 0.4915 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5335 - loss: 0.6923 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5401 - loss: 0.6920 - weighted_accuracy: 0.4939 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5435 - loss: 0.6922 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5535 - loss: 0.6919 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5442 - loss: 0.6919 - weighted_accuracy: 0.4909 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.5030 - loss: 20.0770 - weighted_accuracy: 0.4940 - val_accuracy: 0.6933 - val_loss: 0.6898 - val_weighted_accuracy: 0.6933\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5356 - loss: 0.6924 - weighted_accuracy: 0.4995 - val_accuracy: 0.6933 - val_loss: 0.6846 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5302 - loss: 0.6928 - weighted_accuracy: 0.4952 - val_accuracy: 0.3067 - val_loss: 0.7024 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5108 - loss: 0.6925 - weighted_accuracy: 0.4890 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5213 - loss: 0.6924 - weighted_accuracy: 0.4946 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5154 - loss: 0.6924 - weighted_accuracy: 0.4970 - val_accuracy: 0.6933 - val_loss: 0.6816 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5318 - loss: 0.6929 - weighted_accuracy: 0.4933 - val_accuracy: 0.6933 - val_loss: 0.6813 - val_weighted_accuracy: 0.6933\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5187 - loss: 0.6926 - weighted_accuracy: 0.4957 - val_accuracy: 0.6934 - val_loss: 0.6914 - val_weighted_accuracy: 0.6934\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6928 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5266 - loss: 0.6923 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5217 - loss: 0.6922 - weighted_accuracy: 0.4964 - val_accuracy: 0.3067 - val_loss: 0.7020 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5092 - loss: 0.6926 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7006 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5126 - loss: 0.6926 - weighted_accuracy: 0.4933 - val_accuracy: 0.3067 - val_loss: 0.7058 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 0.6926 - weighted_accuracy: 0.4929 - val_accuracy: 0.3067 - val_loss: 0.6979 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5146 - loss: 0.6927 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5148 - loss: 0.6927 - weighted_accuracy: 0.4940 - val_accuracy: 0.3067 - val_loss: 0.7069 - val_weighted_accuracy: 0.3067\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5104 - loss: 0.6926 - weighted_accuracy: 0.4924 - val_accuracy: 0.3067 - val_loss: 0.7039 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.6925 - weighted_accuracy: 0.4922 - val_accuracy: 0.3067 - val_loss: 0.6964 - val_weighted_accuracy: 0.3067\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5150 - loss: 0.6927 - weighted_accuracy: 0.4944 - val_accuracy: 0.6933 - val_loss: 0.6905 - val_weighted_accuracy: 0.6933\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5285 - loss: 0.6923 - weighted_accuracy: 0.4999 - val_accuracy: 0.3067 - val_loss: 0.7092 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5169 - loss: 0.6924 - weighted_accuracy: 0.4914 - val_accuracy: 0.3067 - val_loss: 0.6968 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5124 - loss: 0.6926 - weighted_accuracy: 0.4910 - val_accuracy: 0.3067 - val_loss: 0.6970 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5312 - loss: 0.6923 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.7002 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5153 - loss: 0.6925 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6959 - val_weighted_accuracy: 0.3067\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5162 - loss: 0.6927 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6990 - val_weighted_accuracy: 0.3067\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4979 - loss: 0.6929 - weighted_accuracy: 0.4944 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5237 - loss: 0.6924 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.7002 - val_weighted_accuracy: 0.3067\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5256 - loss: 0.6926 - weighted_accuracy: 0.4993 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5130 - loss: 0.6926 - weighted_accuracy: 0.4942 - val_accuracy: 0.6933 - val_loss: 0.6901 - val_weighted_accuracy: 0.6933\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.4972 - loss: 0.6926 - weighted_accuracy: 0.4878 - val_accuracy: 0.6933 - val_loss: 0.6903 - val_weighted_accuracy: 0.6933\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6926 - weighted_accuracy: 0.4979 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5150 - loss: 0.6925 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6891 - val_weighted_accuracy: 0.6933\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5202 - loss: 0.6926 - weighted_accuracy: 0.4931 - val_accuracy: 0.6934 - val_loss: 0.6916 - val_weighted_accuracy: 0.6934\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5129 - loss: 0.6928 - weighted_accuracy: 0.4920 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5194 - loss: 0.6927 - weighted_accuracy: 0.4912 - val_accuracy: 0.6934 - val_loss: 0.6916 - val_weighted_accuracy: 0.6934\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5235 - loss: 0.6923 - weighted_accuracy: 0.4958 - val_accuracy: 0.6933 - val_loss: 0.6856 - val_weighted_accuracy: 0.6933\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6926 - weighted_accuracy: 0.4970 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5111 - loss: 0.6930 - weighted_accuracy: 0.4894 - val_accuracy: 0.6934 - val_loss: 0.6929 - val_weighted_accuracy: 0.6934\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5275 - loss: 0.6928 - weighted_accuracy: 0.4958 - val_accuracy: 0.6933 - val_loss: 0.6855 - val_weighted_accuracy: 0.6933\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5209 - loss: 0.6928 - weighted_accuracy: 0.4961 - val_accuracy: 0.6933 - val_loss: 0.6815 - val_weighted_accuracy: 0.6933\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5275 - loss: 0.6926 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.7006 - val_weighted_accuracy: 0.3067\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5109 - loss: 0.6927 - weighted_accuracy: 0.4902 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5128 - loss: 0.6927 - weighted_accuracy: 0.4941 - val_accuracy: 0.6934 - val_loss: 0.6922 - val_weighted_accuracy: 0.6934\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5210 - loss: 0.6928 - weighted_accuracy: 0.4902 - val_accuracy: 0.3067 - val_loss: 0.7058 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5100 - loss: 0.6930 - weighted_accuracy: 0.4925 - val_accuracy: 0.6933 - val_loss: 0.6856 - val_weighted_accuracy: 0.6933\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5275 - loss: 0.6924 - weighted_accuracy: 0.4941 - val_accuracy: 0.3067 - val_loss: 0.6997 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5178 - loss: 0.6924 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.7059 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5061 - loss: 0.6928 - weighted_accuracy: 0.4894 - val_accuracy: 0.6933 - val_loss: 0.6851 - val_weighted_accuracy: 0.6933\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5386 - loss: 0.6926 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6880 - val_weighted_accuracy: 0.6933\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5318 - loss: 0.6925 - weighted_accuracy: 0.4967 - val_accuracy: 0.6934 - val_loss: 0.6923 - val_weighted_accuracy: 0.6934\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.4950 - loss: 524.0928 - weighted_accuracy: 0.4980 - val_accuracy: 0.6933 - val_loss: 0.6903 - val_weighted_accuracy: 0.6933\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5110 - loss: 0.6945 - weighted_accuracy: 0.4973 - val_accuracy: 0.6933 - val_loss: 0.6830 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.6946 - weighted_accuracy: 0.4994 - val_accuracy: 0.3067 - val_loss: 0.7095 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5028 - loss: 0.6946 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.7033 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5058 - loss: 0.6947 - weighted_accuracy: 0.4933 - val_accuracy: 0.3067 - val_loss: 0.7047 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5091 - loss: 0.6944 - weighted_accuracy: 0.4975 - val_accuracy: 0.6933 - val_loss: 0.6568 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5194 - loss: 0.6948 - weighted_accuracy: 0.4987 - val_accuracy: 0.3067 - val_loss: 0.7029 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5092 - loss: 0.6945 - weighted_accuracy: 0.4941 - val_accuracy: 0.3067 - val_loss: 0.7137 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 251ms/step - accuracy: 0.5085 - loss: 0.6944 - weighted_accuracy: 0.4980 - val_accuracy: 0.6933 - val_loss: 0.6748 - val_weighted_accuracy: 0.6933\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.5033 - loss: 0.6943 - weighted_accuracy: 0.4960 - val_accuracy: 0.6933 - val_loss: 0.6779 - val_weighted_accuracy: 0.6933\n",
      "Epoch 11/50\n",
      "\u001b[1m  13/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.7003 - loss: 0.6639 - weighted_accuracy: 0.5403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:19:40.292700: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 16:19:40.293671: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5113 - loss: 0.6947 - weighted_accuracy: 0.4970 - val_accuracy: 0.6933 - val_loss: 0.6775 - val_weighted_accuracy: 0.6933\n",
      "Epoch 12/50\n",
      "\u001b[1m  16/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.4860 - loss: 0.7087 - weighted_accuracy: 0.4417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:20:01.269720: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 16:20:01.270064: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5050 - loss: 0.6950 - weighted_accuracy: 0.4913 - val_accuracy: 0.6933 - val_loss: 0.6796 - val_weighted_accuracy: 0.6933\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5179 - loss: 0.6947 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7107 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5096 - loss: 0.6945 - weighted_accuracy: 0.4984 - val_accuracy: 0.6933 - val_loss: 0.6855 - val_weighted_accuracy: 0.6933\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5061 - loss: 0.6946 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6984 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.4976 - loss: 0.6946 - weighted_accuracy: 0.4938 - val_accuracy: 0.6933 - val_loss: 0.6508 - val_weighted_accuracy: 0.6933\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5144 - loss: 0.6946 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.7163 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5035 - loss: 0.6946 - weighted_accuracy: 0.4964 - val_accuracy: 0.6933 - val_loss: 0.6832 - val_weighted_accuracy: 0.6933\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.5001 - loss: 0.6950 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.7197 - val_weighted_accuracy: 0.3067\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5165 - loss: 0.6944 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6948 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5081 - loss: 0.6948 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7012 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5066 - loss: 0.6946 - weighted_accuracy: 0.4949 - val_accuracy: 0.6933 - val_loss: 0.6521 - val_weighted_accuracy: 0.6933\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5208 - loss: 0.6948 - weighted_accuracy: 0.4969 - val_accuracy: 0.3067 - val_loss: 0.7124 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5030 - loss: 0.6950 - weighted_accuracy: 0.4925 - val_accuracy: 0.6933 - val_loss: 0.6900 - val_weighted_accuracy: 0.6933\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5032 - loss: 0.6947 - weighted_accuracy: 0.4901 - val_accuracy: 0.6933 - val_loss: 0.6675 - val_weighted_accuracy: 0.6933\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5098 - loss: 0.6949 - weighted_accuracy: 0.4965 - val_accuracy: 0.6933 - val_loss: 0.6679 - val_weighted_accuracy: 0.6933\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5015 - loss: 0.6949 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6565 - val_weighted_accuracy: 0.6933\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5138 - loss: 0.6944 - weighted_accuracy: 0.4978 - val_accuracy: 0.6933 - val_loss: 0.6815 - val_weighted_accuracy: 0.6933\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5023 - loss: 0.6952 - weighted_accuracy: 0.4911 - val_accuracy: 0.3067 - val_loss: 0.7060 - val_weighted_accuracy: 0.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5129 - loss: 0.6945 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.7233 - val_weighted_accuracy: 0.3067\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5056 - loss: 0.6949 - weighted_accuracy: 0.4993 - val_accuracy: 0.3067 - val_loss: 0.7283 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4980 - loss: 0.6949 - weighted_accuracy: 0.4922 - val_accuracy: 0.3067 - val_loss: 0.7027 - val_weighted_accuracy: 0.3067\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5066 - loss: 0.6949 - weighted_accuracy: 0.4937 - val_accuracy: 0.6933 - val_loss: 0.6675 - val_weighted_accuracy: 0.6933\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5066 - loss: 0.6944 - weighted_accuracy: 0.4945 - val_accuracy: 0.3067 - val_loss: 0.6933 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4993 - loss: 0.6947 - weighted_accuracy: 0.4895 - val_accuracy: 0.6933 - val_loss: 0.6669 - val_weighted_accuracy: 0.6933\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5105 - loss: 0.6941 - weighted_accuracy: 0.4967 - val_accuracy: 0.6933 - val_loss: 0.6800 - val_weighted_accuracy: 0.6933\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5100 - loss: 0.6945 - weighted_accuracy: 0.4981 - val_accuracy: 0.6933 - val_loss: 0.6764 - val_weighted_accuracy: 0.6933\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5130 - loss: 0.6944 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5062 - loss: 0.6949 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5152 - loss: 0.6944 - weighted_accuracy: 0.4990 - val_accuracy: 0.6933 - val_loss: 0.6568 - val_weighted_accuracy: 0.6933\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5049 - loss: 0.6946 - weighted_accuracy: 0.4920 - val_accuracy: 0.6933 - val_loss: 0.6894 - val_weighted_accuracy: 0.6933\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5148 - loss: 0.6944 - weighted_accuracy: 0.4949 - val_accuracy: 0.6933 - val_loss: 0.6537 - val_weighted_accuracy: 0.6933\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5126 - loss: 0.6946 - weighted_accuracy: 0.4965 - val_accuracy: 0.6933 - val_loss: 0.6728 - val_weighted_accuracy: 0.6933\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5093 - loss: 0.6946 - weighted_accuracy: 0.4917 - val_accuracy: 0.3067 - val_loss: 0.7185 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5084 - loss: 0.6944 - weighted_accuracy: 0.4974 - val_accuracy: 0.3067 - val_loss: 0.7016 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5083 - loss: 0.6945 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6995 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5069 - loss: 0.6946 - weighted_accuracy: 0.4983 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5035 - loss: 0.6950 - weighted_accuracy: 0.4922 - val_accuracy: 0.6933 - val_loss: 0.6848 - val_weighted_accuracy: 0.6933\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5083 - loss: 0.6947 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.6932 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5059 - loss: 0.6948 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6777 - val_weighted_accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-2, 0, 5)\n",
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model = simple_nn()\n",
    "    model.name = f\"simplenn_lr_{learning_rate}\"\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=50,\n",
    "                        class_weight=class_weights, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs, all learning rates above 0.033 do not converge, let's look at smaller \n",
    "learning rates. \n",
    "\n",
    "To shorten the fitting time, let's drop from 50 epochs to 30 and implement early \n",
    "stopping with parience of 8 epochs, starting after 8 epochs and restoring the best set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.5726 - loss: 0.6955 - weighted_accuracy: 0.5206 - val_accuracy: 0.6113 - val_loss: 0.6648 - val_weighted_accuracy: 0.6113\n",
      "Epoch 2/30\n",
      "\u001b[1m   3/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 53ms/step - accuracy: 0.6042 - loss: 0.6767 - weighted_accuracy: 0.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:39:00.415464: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6137 - loss: 0.6718 - weighted_accuracy: 0.5889 - val_accuracy: 0.6205 - val_loss: 0.6572 - val_weighted_accuracy: 0.6205\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.6289 - loss: 0.6603 - weighted_accuracy: 0.6124 - val_accuracy: 0.6378 - val_loss: 0.6469 - val_weighted_accuracy: 0.6378\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.6418 - loss: 0.6519 - weighted_accuracy: 0.6284 - val_accuracy: 0.6484 - val_loss: 0.6395 - val_weighted_accuracy: 0.6484\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.6519 - loss: 0.6445 - weighted_accuracy: 0.6410 - val_accuracy: 0.6523 - val_loss: 0.6360 - val_weighted_accuracy: 0.6523\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6633 - loss: 0.6381 - weighted_accuracy: 0.6541 - val_accuracy: 0.6660 - val_loss: 0.6269 - val_weighted_accuracy: 0.6660\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6715 - loss: 0.6315 - weighted_accuracy: 0.6639 - val_accuracy: 0.6786 - val_loss: 0.6182 - val_weighted_accuracy: 0.6786\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6804 - loss: 0.6256 - weighted_accuracy: 0.6733 - val_accuracy: 0.6814 - val_loss: 0.6162 - val_weighted_accuracy: 0.6814\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6890 - loss: 0.6199 - weighted_accuracy: 0.6834 - val_accuracy: 0.6911 - val_loss: 0.6089 - val_weighted_accuracy: 0.6911\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6955 - loss: 0.6145 - weighted_accuracy: 0.6904 - val_accuracy: 0.6881 - val_loss: 0.6081 - val_weighted_accuracy: 0.6881\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7011 - loss: 0.6090 - weighted_accuracy: 0.6978 - val_accuracy: 0.6969 - val_loss: 0.6022 - val_weighted_accuracy: 0.6969\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7084 - loss: 0.6037 - weighted_accuracy: 0.7053 - val_accuracy: 0.6969 - val_loss: 0.5999 - val_weighted_accuracy: 0.6969\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7127 - loss: 0.5989 - weighted_accuracy: 0.7107 - val_accuracy: 0.7054 - val_loss: 0.5943 - val_weighted_accuracy: 0.7054\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7198 - loss: 0.5938 - weighted_accuracy: 0.7188 - val_accuracy: 0.7116 - val_loss: 0.5899 - val_weighted_accuracy: 0.7116\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7250 - loss: 0.5892 - weighted_accuracy: 0.7242 - val_accuracy: 0.7292 - val_loss: 0.5781 - val_weighted_accuracy: 0.7292\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7309 - loss: 0.5843 - weighted_accuracy: 0.7303 - val_accuracy: 0.7220 - val_loss: 0.5815 - val_weighted_accuracy: 0.7220\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7358 - loss: 0.5797 - weighted_accuracy: 0.7369 - val_accuracy: 0.7386 - val_loss: 0.5702 - val_weighted_accuracy: 0.7386\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7409 - loss: 0.5750 - weighted_accuracy: 0.7420 - val_accuracy: 0.7393 - val_loss: 0.5682 - val_weighted_accuracy: 0.7393\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7434 - loss: 0.5709 - weighted_accuracy: 0.7453 - val_accuracy: 0.7401 - val_loss: 0.5666 - val_weighted_accuracy: 0.7401\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7483 - loss: 0.5671 - weighted_accuracy: 0.7508 - val_accuracy: 0.7464 - val_loss: 0.5613 - val_weighted_accuracy: 0.7464\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7513 - loss: 0.5627 - weighted_accuracy: 0.7546 - val_accuracy: 0.7521 - val_loss: 0.5554 - val_weighted_accuracy: 0.7521\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7572 - loss: 0.5583 - weighted_accuracy: 0.7601 - val_accuracy: 0.7563 - val_loss: 0.5499 - val_weighted_accuracy: 0.7563\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7596 - loss: 0.5545 - weighted_accuracy: 0.7627 - val_accuracy: 0.7570 - val_loss: 0.5487 - val_weighted_accuracy: 0.7570\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7633 - loss: 0.5507 - weighted_accuracy: 0.7674 - val_accuracy: 0.7628 - val_loss: 0.5432 - val_weighted_accuracy: 0.7628\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7666 - loss: 0.5469 - weighted_accuracy: 0.7708 - val_accuracy: 0.7615 - val_loss: 0.5438 - val_weighted_accuracy: 0.7615\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7712 - loss: 0.5429 - weighted_accuracy: 0.7764 - val_accuracy: 0.7719 - val_loss: 0.5343 - val_weighted_accuracy: 0.7719\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7737 - loss: 0.5395 - weighted_accuracy: 0.7788 - val_accuracy: 0.7722 - val_loss: 0.5329 - val_weighted_accuracy: 0.7722\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7765 - loss: 0.5360 - weighted_accuracy: 0.7816 - val_accuracy: 0.7719 - val_loss: 0.5331 - val_weighted_accuracy: 0.7719\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 0.5324 - weighted_accuracy: 0.7844 - val_accuracy: 0.7813 - val_loss: 0.5248 - val_weighted_accuracy: 0.7813\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7805 - loss: 0.5294 - weighted_accuracy: 0.7867 - val_accuracy: 0.7803 - val_loss: 0.5250 - val_weighted_accuracy: 0.7803\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5845 - loss: 0.6793 - weighted_accuracy: 0.5661 - val_accuracy: 0.6576 - val_loss: 0.6351 - val_weighted_accuracy: 0.6576\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6497 - loss: 0.6433 - weighted_accuracy: 0.6410 - val_accuracy: 0.6835 - val_loss: 0.6162 - val_weighted_accuracy: 0.6835\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6800 - loss: 0.6220 - weighted_accuracy: 0.6744 - val_accuracy: 0.7231 - val_loss: 0.5867 - val_weighted_accuracy: 0.7231\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7048 - loss: 0.6029 - weighted_accuracy: 0.7008 - val_accuracy: 0.7138 - val_loss: 0.5913 - val_weighted_accuracy: 0.7138\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7237 - loss: 0.5853 - weighted_accuracy: 0.7231 - val_accuracy: 0.7418 - val_loss: 0.5681 - val_weighted_accuracy: 0.7418\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7410 - loss: 0.5691 - weighted_accuracy: 0.7424 - val_accuracy: 0.7561 - val_loss: 0.5529 - val_weighted_accuracy: 0.7561\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7560 - loss: 0.5541 - weighted_accuracy: 0.7590 - val_accuracy: 0.7735 - val_loss: 0.5341 - val_weighted_accuracy: 0.7735\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7662 - loss: 0.5400 - weighted_accuracy: 0.7703 - val_accuracy: 0.7633 - val_loss: 0.5395 - val_weighted_accuracy: 0.7633\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7746 - loss: 0.5282 - weighted_accuracy: 0.7811 - val_accuracy: 0.7771 - val_loss: 0.5228 - val_weighted_accuracy: 0.7771\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7857 - loss: 0.5167 - weighted_accuracy: 0.7929 - val_accuracy: 0.7903 - val_loss: 0.5081 - val_weighted_accuracy: 0.7903\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7917 - loss: 0.5058 - weighted_accuracy: 0.7998 - val_accuracy: 0.7942 - val_loss: 0.5003 - val_weighted_accuracy: 0.7942\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8012 - loss: 0.4959 - weighted_accuracy: 0.8104 - val_accuracy: 0.8053 - val_loss: 0.4856 - val_weighted_accuracy: 0.8053\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8040 - loss: 0.4863 - weighted_accuracy: 0.8127 - val_accuracy: 0.8208 - val_loss: 0.4647 - val_weighted_accuracy: 0.8208\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.4776 - weighted_accuracy: 0.8186 - val_accuracy: 0.8145 - val_loss: 0.4680 - val_weighted_accuracy: 0.8145\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8145 - loss: 0.4696 - weighted_accuracy: 0.8247 - val_accuracy: 0.8240 - val_loss: 0.4555 - val_weighted_accuracy: 0.8240\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.4616 - weighted_accuracy: 0.8285 - val_accuracy: 0.8235 - val_loss: 0.4542 - val_weighted_accuracy: 0.8235\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.4541 - weighted_accuracy: 0.8319 - val_accuracy: 0.8293 - val_loss: 0.4450 - val_weighted_accuracy: 0.8293\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8255 - loss: 0.4474 - weighted_accuracy: 0.8365 - val_accuracy: 0.8350 - val_loss: 0.4319 - val_weighted_accuracy: 0.8350\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8295 - loss: 0.4404 - weighted_accuracy: 0.8403 - val_accuracy: 0.8347 - val_loss: 0.4318 - val_weighted_accuracy: 0.8347\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8309 - loss: 0.4343 - weighted_accuracy: 0.8419 - val_accuracy: 0.8360 - val_loss: 0.4276 - val_weighted_accuracy: 0.8360\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8349 - loss: 0.4277 - weighted_accuracy: 0.8461 - val_accuracy: 0.8423 - val_loss: 0.4154 - val_weighted_accuracy: 0.8423\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8364 - loss: 0.4222 - weighted_accuracy: 0.8483 - val_accuracy: 0.8361 - val_loss: 0.4222 - val_weighted_accuracy: 0.8361\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8368 - loss: 0.4168 - weighted_accuracy: 0.8484 - val_accuracy: 0.8463 - val_loss: 0.4065 - val_weighted_accuracy: 0.8463\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8414 - loss: 0.4115 - weighted_accuracy: 0.8526 - val_accuracy: 0.8387 - val_loss: 0.4134 - val_weighted_accuracy: 0.8387\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8419 - loss: 0.4066 - weighted_accuracy: 0.8539 - val_accuracy: 0.8449 - val_loss: 0.4042 - val_weighted_accuracy: 0.8449\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.4014 - weighted_accuracy: 0.8572 - val_accuracy: 0.8517 - val_loss: 0.3926 - val_weighted_accuracy: 0.8517\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8474 - loss: 0.3967 - weighted_accuracy: 0.8588 - val_accuracy: 0.8530 - val_loss: 0.3907 - val_weighted_accuracy: 0.8530\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8485 - loss: 0.3921 - weighted_accuracy: 0.8598 - val_accuracy: 0.8383 - val_loss: 0.4036 - val_weighted_accuracy: 0.8383\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8505 - loss: 0.3881 - weighted_accuracy: 0.8623 - val_accuracy: 0.8571 - val_loss: 0.3788 - val_weighted_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8530 - loss: 0.3836 - weighted_accuracy: 0.8636 - val_accuracy: 0.8547 - val_loss: 0.3814 - val_weighted_accuracy: 0.8547\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5908 - loss: 0.6693 - weighted_accuracy: 0.5819 - val_accuracy: 0.7188 - val_loss: 0.5851 - val_weighted_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6937 - loss: 0.6023 - weighted_accuracy: 0.6904 - val_accuracy: 0.7321 - val_loss: 0.5708 - val_weighted_accuracy: 0.7321\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7440 - loss: 0.5562 - weighted_accuracy: 0.7463 - val_accuracy: 0.7953 - val_loss: 0.4929 - val_weighted_accuracy: 0.7953\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7741 - loss: 0.5201 - weighted_accuracy: 0.7799 - val_accuracy: 0.8130 - val_loss: 0.4611 - val_weighted_accuracy: 0.8130\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7951 - loss: 0.4903 - weighted_accuracy: 0.8020 - val_accuracy: 0.8141 - val_loss: 0.4691 - val_weighted_accuracy: 0.8141\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8100 - loss: 0.4654 - weighted_accuracy: 0.8197 - val_accuracy: 0.8331 - val_loss: 0.4388 - val_weighted_accuracy: 0.8331\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.4436 - weighted_accuracy: 0.8320 - val_accuracy: 0.8450 - val_loss: 0.4143 - val_weighted_accuracy: 0.8450\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8304 - loss: 0.4253 - weighted_accuracy: 0.8408 - val_accuracy: 0.8320 - val_loss: 0.4217 - val_weighted_accuracy: 0.8320\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8377 - loss: 0.4091 - weighted_accuracy: 0.8486 - val_accuracy: 0.8344 - val_loss: 0.4103 - val_weighted_accuracy: 0.8344\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8421 - loss: 0.3954 - weighted_accuracy: 0.8532 - val_accuracy: 0.8457 - val_loss: 0.3930 - val_weighted_accuracy: 0.8457\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8493 - loss: 0.3812 - weighted_accuracy: 0.8598 - val_accuracy: 0.8640 - val_loss: 0.3614 - val_weighted_accuracy: 0.8640\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 0.3702 - weighted_accuracy: 0.8626 - val_accuracy: 0.8276 - val_loss: 0.3998 - val_weighted_accuracy: 0.8276\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8572 - loss: 0.3601 - weighted_accuracy: 0.8669 - val_accuracy: 0.8228 - val_loss: 0.4010 - val_weighted_accuracy: 0.8228\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8611 - loss: 0.3514 - weighted_accuracy: 0.8708 - val_accuracy: 0.8646 - val_loss: 0.3505 - val_weighted_accuracy: 0.8646\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8649 - loss: 0.3422 - weighted_accuracy: 0.8748 - val_accuracy: 0.8710 - val_loss: 0.3339 - val_weighted_accuracy: 0.8710\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8669 - loss: 0.3338 - weighted_accuracy: 0.8762 - val_accuracy: 0.8788 - val_loss: 0.3139 - val_weighted_accuracy: 0.8788\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8713 - loss: 0.3272 - weighted_accuracy: 0.8803 - val_accuracy: 0.8760 - val_loss: 0.3218 - val_weighted_accuracy: 0.8760\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8736 - loss: 0.3199 - weighted_accuracy: 0.8828 - val_accuracy: 0.8823 - val_loss: 0.3026 - val_weighted_accuracy: 0.8823\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8772 - loss: 0.3148 - weighted_accuracy: 0.8863 - val_accuracy: 0.8813 - val_loss: 0.3085 - val_weighted_accuracy: 0.8813\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8785 - loss: 0.3079 - weighted_accuracy: 0.8864 - val_accuracy: 0.8831 - val_loss: 0.3029 - val_weighted_accuracy: 0.8831\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8813 - loss: 0.3020 - weighted_accuracy: 0.8894 - val_accuracy: 0.8876 - val_loss: 0.2883 - val_weighted_accuracy: 0.8876\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8838 - loss: 0.2965 - weighted_accuracy: 0.8916 - val_accuracy: 0.8887 - val_loss: 0.2827 - val_weighted_accuracy: 0.8887\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8862 - loss: 0.2906 - weighted_accuracy: 0.8945 - val_accuracy: 0.8893 - val_loss: 0.2839 - val_weighted_accuracy: 0.8893\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8888 - loss: 0.2865 - weighted_accuracy: 0.8966 - val_accuracy: 0.8907 - val_loss: 0.2758 - val_weighted_accuracy: 0.8907\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8893 - loss: 0.2825 - weighted_accuracy: 0.8968 - val_accuracy: 0.8919 - val_loss: 0.2714 - val_weighted_accuracy: 0.8919\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8902 - loss: 0.2774 - weighted_accuracy: 0.8983 - val_accuracy: 0.8930 - val_loss: 0.2694 - val_weighted_accuracy: 0.8930\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8922 - loss: 0.2740 - weighted_accuracy: 0.9001 - val_accuracy: 0.8867 - val_loss: 0.2857 - val_weighted_accuracy: 0.8867\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8933 - loss: 0.2699 - weighted_accuracy: 0.9002 - val_accuracy: 0.8957 - val_loss: 0.2611 - val_weighted_accuracy: 0.8957\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8965 - loss: 0.2656 - weighted_accuracy: 0.9038 - val_accuracy: 0.8932 - val_loss: 0.2715 - val_weighted_accuracy: 0.8932\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8959 - loss: 0.2633 - weighted_accuracy: 0.9030 - val_accuracy: 0.9009 - val_loss: 0.2523 - val_weighted_accuracy: 0.9009\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6151 - loss: 0.6542 - weighted_accuracy: 0.6063 - val_accuracy: 0.7869 - val_loss: 0.4828 - val_weighted_accuracy: 0.7869\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7470 - loss: 0.5257 - weighted_accuracy: 0.7497 - val_accuracy: 0.7223 - val_loss: 0.5382 - val_weighted_accuracy: 0.7223\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7858 - loss: 0.4619 - weighted_accuracy: 0.7927 - val_accuracy: 0.8102 - val_loss: 0.4364 - val_weighted_accuracy: 0.8102\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.4156 - weighted_accuracy: 0.8249 - val_accuracy: 0.8654 - val_loss: 0.3400 - val_weighted_accuracy: 0.8654\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8384 - loss: 0.3794 - weighted_accuracy: 0.8458 - val_accuracy: 0.8492 - val_loss: 0.3632 - val_weighted_accuracy: 0.8492\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8455 - loss: 0.3547 - weighted_accuracy: 0.8538 - val_accuracy: 0.8765 - val_loss: 0.3164 - val_weighted_accuracy: 0.8765\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8554 - loss: 0.3372 - weighted_accuracy: 0.8629 - val_accuracy: 0.8855 - val_loss: 0.2935 - val_weighted_accuracy: 0.8855\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8620 - loss: 0.3219 - weighted_accuracy: 0.8689 - val_accuracy: 0.8899 - val_loss: 0.2806 - val_weighted_accuracy: 0.8899\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8720 - loss: 0.3053 - weighted_accuracy: 0.8778 - val_accuracy: 0.8790 - val_loss: 0.2964 - val_weighted_accuracy: 0.8790\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.2923 - weighted_accuracy: 0.8817 - val_accuracy: 0.8978 - val_loss: 0.2539 - val_weighted_accuracy: 0.8978\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8810 - loss: 0.2824 - weighted_accuracy: 0.8878 - val_accuracy: 0.8989 - val_loss: 0.2537 - val_weighted_accuracy: 0.8989\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8846 - loss: 0.2737 - weighted_accuracy: 0.8901 - val_accuracy: 0.8848 - val_loss: 0.2784 - val_weighted_accuracy: 0.8848\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8920 - loss: 0.2602 - weighted_accuracy: 0.8977 - val_accuracy: 0.8919 - val_loss: 0.2638 - val_weighted_accuracy: 0.8919\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8943 - loss: 0.2513 - weighted_accuracy: 0.8996 - val_accuracy: 0.8357 - val_loss: 0.3614 - val_weighted_accuracy: 0.8357\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8952 - loss: 0.2504 - weighted_accuracy: 0.9007 - val_accuracy: 0.9099 - val_loss: 0.2212 - val_weighted_accuracy: 0.9099\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9003 - loss: 0.2416 - weighted_accuracy: 0.9052 - val_accuracy: 0.8997 - val_loss: 0.2438 - val_weighted_accuracy: 0.8997\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9025 - loss: 0.2337 - weighted_accuracy: 0.9072 - val_accuracy: 0.8606 - val_loss: 0.3126 - val_weighted_accuracy: 0.8606\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9023 - loss: 0.2320 - weighted_accuracy: 0.9065 - val_accuracy: 0.8992 - val_loss: 0.2439 - val_weighted_accuracy: 0.8992\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9043 - loss: 0.2264 - weighted_accuracy: 0.9087 - val_accuracy: 0.9055 - val_loss: 0.2295 - val_weighted_accuracy: 0.9055\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9067 - loss: 0.2220 - weighted_accuracy: 0.9113 - val_accuracy: 0.9174 - val_loss: 0.2102 - val_weighted_accuracy: 0.9174\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9102 - loss: 0.2171 - weighted_accuracy: 0.9142 - val_accuracy: 0.9159 - val_loss: 0.2006 - val_weighted_accuracy: 0.9159\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9128 - loss: 0.2132 - weighted_accuracy: 0.9169 - val_accuracy: 0.9167 - val_loss: 0.2103 - val_weighted_accuracy: 0.9167\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9141 - loss: 0.2099 - weighted_accuracy: 0.9182 - val_accuracy: 0.8882 - val_loss: 0.2424 - val_weighted_accuracy: 0.8882\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9178 - loss: 0.2042 - weighted_accuracy: 0.9222 - val_accuracy: 0.9113 - val_loss: 0.2035 - val_weighted_accuracy: 0.9113\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9169 - loss: 0.2026 - weighted_accuracy: 0.9209 - val_accuracy: 0.9259 - val_loss: 0.1844 - val_weighted_accuracy: 0.9259\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9202 - loss: 0.1965 - weighted_accuracy: 0.9234 - val_accuracy: 0.9261 - val_loss: 0.1820 - val_weighted_accuracy: 0.9261\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9242 - loss: 0.1898 - weighted_accuracy: 0.9286 - val_accuracy: 0.9152 - val_loss: 0.2105 - val_weighted_accuracy: 0.9152\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9211 - loss: 0.1916 - weighted_accuracy: 0.9246 - val_accuracy: 0.9261 - val_loss: 0.1890 - val_weighted_accuracy: 0.9261\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9221 - loss: 0.1896 - weighted_accuracy: 0.9254 - val_accuracy: 0.9254 - val_loss: 0.1784 - val_weighted_accuracy: 0.9254\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.1830 - weighted_accuracy: 0.9296 - val_accuracy: 0.9310 - val_loss: 0.1728 - val_weighted_accuracy: 0.9310\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.6039 - loss: 0.6739 - weighted_accuracy: 0.5933 - val_accuracy: 0.6914 - val_loss: 0.5827 - val_weighted_accuracy: 0.6914\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7311 - loss: 0.5321 - weighted_accuracy: 0.7336 - val_accuracy: 0.8272 - val_loss: 0.4227 - val_weighted_accuracy: 0.8272\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7717 - loss: 0.4699 - weighted_accuracy: 0.7751 - val_accuracy: 0.8615 - val_loss: 0.3336 - val_weighted_accuracy: 0.8615\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8091 - loss: 0.4140 - weighted_accuracy: 0.8142 - val_accuracy: 0.7814 - val_loss: 0.4186 - val_weighted_accuracy: 0.7814\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8222 - loss: 0.3837 - weighted_accuracy: 0.8268 - val_accuracy: 0.8770 - val_loss: 0.2796 - val_weighted_accuracy: 0.8770\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 0.3524 - weighted_accuracy: 0.8440 - val_accuracy: 0.8849 - val_loss: 0.2852 - val_weighted_accuracy: 0.8849\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8494 - loss: 0.3318 - weighted_accuracy: 0.8530 - val_accuracy: 0.8403 - val_loss: 0.3214 - val_weighted_accuracy: 0.8403\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8652 - loss: 0.3089 - weighted_accuracy: 0.8686 - val_accuracy: 0.9025 - val_loss: 0.2343 - val_weighted_accuracy: 0.9025\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8711 - loss: 0.2865 - weighted_accuracy: 0.8750 - val_accuracy: 0.8969 - val_loss: 0.2287 - val_weighted_accuracy: 0.8969\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8774 - loss: 0.2785 - weighted_accuracy: 0.8817 - val_accuracy: 0.7283 - val_loss: 0.5726 - val_weighted_accuracy: 0.7283\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8844 - loss: 0.2648 - weighted_accuracy: 0.8888 - val_accuracy: 0.8838 - val_loss: 0.2721 - val_weighted_accuracy: 0.8838\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8944 - loss: 0.2491 - weighted_accuracy: 0.8981 - val_accuracy: 0.9131 - val_loss: 0.2007 - val_weighted_accuracy: 0.9131\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8941 - loss: 0.2446 - weighted_accuracy: 0.8970 - val_accuracy: 0.9057 - val_loss: 0.2274 - val_weighted_accuracy: 0.9057\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8991 - loss: 0.2398 - weighted_accuracy: 0.9027 - val_accuracy: 0.9240 - val_loss: 0.1875 - val_weighted_accuracy: 0.9240\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9016 - loss: 0.2278 - weighted_accuracy: 0.9052 - val_accuracy: 0.9250 - val_loss: 0.1872 - val_weighted_accuracy: 0.9250\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9055 - loss: 0.2212 - weighted_accuracy: 0.9086 - val_accuracy: 0.9294 - val_loss: 0.1786 - val_weighted_accuracy: 0.9294\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6050 - loss: 0.6723 - weighted_accuracy: 0.5938 - val_accuracy: 0.7783 - val_loss: 0.5131 - val_weighted_accuracy: 0.7783\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7098 - loss: 0.5534 - weighted_accuracy: 0.7120 - val_accuracy: 0.7419 - val_loss: 0.5104 - val_weighted_accuracy: 0.7419\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7634 - loss: 0.4742 - weighted_accuracy: 0.7678 - val_accuracy: 0.7589 - val_loss: 0.4559 - val_weighted_accuracy: 0.7589\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7952 - loss: 0.4211 - weighted_accuracy: 0.7997 - val_accuracy: 0.8824 - val_loss: 0.2878 - val_weighted_accuracy: 0.8824\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.3893 - weighted_accuracy: 0.8206 - val_accuracy: 0.8737 - val_loss: 0.2694 - val_weighted_accuracy: 0.8737\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8301 - loss: 0.3562 - weighted_accuracy: 0.8347 - val_accuracy: 0.8942 - val_loss: 0.2582 - val_weighted_accuracy: 0.8942\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.3176 - weighted_accuracy: 0.8562 - val_accuracy: 0.8786 - val_loss: 0.2798 - val_weighted_accuracy: 0.8786\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8573 - loss: 0.3096 - weighted_accuracy: 0.8627 - val_accuracy: 0.7446 - val_loss: 0.5241 - val_weighted_accuracy: 0.7446\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8759 - loss: 0.2744 - weighted_accuracy: 0.8805 - val_accuracy: 0.8513 - val_loss: 0.3018 - val_weighted_accuracy: 0.8513\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8807 - loss: 0.2645 - weighted_accuracy: 0.8845 - val_accuracy: 0.8859 - val_loss: 0.2493 - val_weighted_accuracy: 0.8859\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8853 - loss: 0.2550 - weighted_accuracy: 0.8899 - val_accuracy: 0.8792 - val_loss: 0.2565 - val_weighted_accuracy: 0.8792\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8940 - loss: 0.2411 - weighted_accuracy: 0.8979 - val_accuracy: 0.9217 - val_loss: 0.1805 - val_weighted_accuracy: 0.9217\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9002 - loss: 0.2286 - weighted_accuracy: 0.9041 - val_accuracy: 0.9257 - val_loss: 0.1779 - val_weighted_accuracy: 0.9257\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9044 - loss: 0.2156 - weighted_accuracy: 0.9074 - val_accuracy: 0.8700 - val_loss: 0.2785 - val_weighted_accuracy: 0.8700\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9097 - loss: 0.2077 - weighted_accuracy: 0.9132 - val_accuracy: 0.6154 - val_loss: 1.0038 - val_weighted_accuracy: 0.6154\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.9119 - loss: 0.2039 - weighted_accuracy: 0.9148 - val_accuracy: 0.9131 - val_loss: 0.2050 - val_weighted_accuracy: 0.9131\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.5948 - loss: 0.6906 - weighted_accuracy: 0.5759 - val_accuracy: 0.7909 - val_loss: 0.4947 - val_weighted_accuracy: 0.7909\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6755 - loss: 0.5920 - weighted_accuracy: 0.6863 - val_accuracy: 0.8217 - val_loss: 0.4351 - val_weighted_accuracy: 0.8217\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7264 - loss: 0.5438 - weighted_accuracy: 0.7267 - val_accuracy: 0.7755 - val_loss: 0.4856 - val_weighted_accuracy: 0.7755\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7660 - loss: 0.4830 - weighted_accuracy: 0.7667 - val_accuracy: 0.8528 - val_loss: 0.3124 - val_weighted_accuracy: 0.8528\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7985 - loss: 0.4326 - weighted_accuracy: 0.7962 - val_accuracy: 0.8320 - val_loss: 0.3357 - val_weighted_accuracy: 0.8320\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.3990 - weighted_accuracy: 0.8146 - val_accuracy: 0.8765 - val_loss: 0.2738 - val_weighted_accuracy: 0.8765\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8326 - loss: 0.3718 - weighted_accuracy: 0.8328 - val_accuracy: 0.8212 - val_loss: 0.3772 - val_weighted_accuracy: 0.8212\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8467 - loss: 0.3403 - weighted_accuracy: 0.8482 - val_accuracy: 0.8802 - val_loss: 0.2793 - val_weighted_accuracy: 0.8802\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8580 - loss: 0.3154 - weighted_accuracy: 0.8589 - val_accuracy: 0.7850 - val_loss: 0.4831 - val_weighted_accuracy: 0.7850\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8592 - loss: 0.3119 - weighted_accuracy: 0.8615 - val_accuracy: 0.8546 - val_loss: 0.3276 - val_weighted_accuracy: 0.8546\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8693 - loss: 0.2929 - weighted_accuracy: 0.8713 - val_accuracy: 0.9026 - val_loss: 0.2235 - val_weighted_accuracy: 0.9026\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8774 - loss: 0.2695 - weighted_accuracy: 0.8803 - val_accuracy: 0.9109 - val_loss: 0.1961 - val_weighted_accuracy: 0.9109\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8859 - loss: 0.2599 - weighted_accuracy: 0.8882 - val_accuracy: 0.9111 - val_loss: 0.2158 - val_weighted_accuracy: 0.9111\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8886 - loss: 0.2573 - weighted_accuracy: 0.8922 - val_accuracy: 0.9225 - val_loss: 0.1911 - val_weighted_accuracy: 0.9225\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8991 - loss: 0.2388 - weighted_accuracy: 0.9011 - val_accuracy: 0.9168 - val_loss: 0.1860 - val_weighted_accuracy: 0.9168\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9071 - loss: 0.2175 - weighted_accuracy: 0.9086 - val_accuracy: 0.9174 - val_loss: 0.1959 - val_weighted_accuracy: 0.9174\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.9112 - weighted_accuracy: 0.5045 - val_accuracy: 0.5192 - val_loss: 0.6944 - val_weighted_accuracy: 0.5192\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6074 - loss: 0.6912 - weighted_accuracy: 0.5222 - val_accuracy: 0.6935 - val_loss: 0.6893 - val_weighted_accuracy: 0.6935\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6182 - loss: 0.6915 - weighted_accuracy: 0.5050 - val_accuracy: 0.6941 - val_loss: 0.6927 - val_weighted_accuracy: 0.6941\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6202 - loss: 0.6908 - weighted_accuracy: 0.5183 - val_accuracy: 0.6680 - val_loss: 0.6824 - val_weighted_accuracy: 0.6680\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6445 - loss: 0.6913 - weighted_accuracy: 0.5116 - val_accuracy: 0.6933 - val_loss: 0.6780 - val_weighted_accuracy: 0.6933\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6468 - loss: 0.6918 - weighted_accuracy: 0.5027 - val_accuracy: 0.6931 - val_loss: 0.6928 - val_weighted_accuracy: 0.6931\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5786 - loss: 0.6915 - weighted_accuracy: 0.5043 - val_accuracy: 0.6480 - val_loss: 0.6610 - val_weighted_accuracy: 0.6480\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4860 - loss: 0.6918 - weighted_accuracy: 0.4991 - val_accuracy: 0.3112 - val_loss: 0.6939 - val_weighted_accuracy: 0.3112\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4713 - loss: 0.6886 - weighted_accuracy: 0.5160 - val_accuracy: 0.7159 - val_loss: 0.6658 - val_weighted_accuracy: 0.7159\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6549 - loss: 0.6819 - weighted_accuracy: 0.5544 - val_accuracy: 0.3067 - val_loss: 0.7000 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5166 - loss: 0.6915 - weighted_accuracy: 0.4982 - val_accuracy: 0.3080 - val_loss: 0.6995 - val_weighted_accuracy: 0.3080\n",
      "Epoch 12/30\n",
      "\u001b[1m   4/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 44ms/step - accuracy: 0.2852 - loss: 0.6790 - weighted_accuracy: 0.4699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 18:46:16.879739: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 18:46:16.880122: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4418 - loss: 0.6908 - weighted_accuracy: 0.5168 - val_accuracy: 0.3078 - val_loss: 0.6962 - val_weighted_accuracy: 0.3078\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5271 - loss: 0.6919 - weighted_accuracy: 0.4969 - val_accuracy: 0.3084 - val_loss: 0.6950 - val_weighted_accuracy: 0.3084\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5156 - loss: 0.6918 - weighted_accuracy: 0.5038 - val_accuracy: 0.3089 - val_loss: 0.6935 - val_weighted_accuracy: 0.3089\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5729 - loss: 0.6917 - weighted_accuracy: 0.4973 - val_accuracy: 0.3090 - val_loss: 0.6959 - val_weighted_accuracy: 0.3090\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5429 - loss: 0.6918 - weighted_accuracy: 0.4982 - val_accuracy: 0.3094 - val_loss: 0.6963 - val_weighted_accuracy: 0.3094\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.5422 - loss: 1.3444 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6939 - val_weighted_accuracy: 0.3067\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5455 - loss: 0.6919 - weighted_accuracy: 0.4952 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5504 - loss: 0.6920 - weighted_accuracy: 0.4943 - val_accuracy: 0.6934 - val_loss: 0.6931 - val_weighted_accuracy: 0.6934\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5476 - loss: 0.6923 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6925 - val_weighted_accuracy: 0.6933\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5547 - loss: 0.6921 - weighted_accuracy: 0.4987 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5434 - loss: 0.6922 - weighted_accuracy: 0.4942 - val_accuracy: 0.3067 - val_loss: 0.6932 - val_weighted_accuracy: 0.3067\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5405 - loss: 0.6921 - weighted_accuracy: 0.4939 - val_accuracy: 0.3067 - val_loss: 0.6950 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5484 - loss: 0.6919 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5543 - loss: 0.6919 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5600 - loss: 0.6920 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5504 - loss: 0.6920 - weighted_accuracy: 0.4957 - val_accuracy: 0.3067 - val_loss: 0.6948 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5435 - loss: 0.6919 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.6934 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5449 - loss: 0.6919 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5406 - loss: 0.6921 - weighted_accuracy: 0.4947 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5662 - loss: 0.6920 - weighted_accuracy: 0.4970 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5359 - loss: 0.6921 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-5, -1, 9)\n",
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "early_stopping = EarlyStopping(patience=8, start_from_epoch=8, restore_best_weights=True, verbose=1)\n",
    "\n",
    "models = [{model: None, history: None} for _ in learning_rates]\n",
    "\n",
    "for i, learning_rate in enumerate(learning_rates):\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model = simple_nn()\n",
    "    model.name = f\"simplenn_lr_{learning_rate}\"\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                        class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])\n",
    "    models[i][\"model\"] = model\n",
    "    models[i][\"history\"] = history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on loss and accuracy graphs, it is good to start with learning rate at 0.1 and gradually decrease it,\n",
    "i.e. use Exponential Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.5889 - loss: 0.7165 - weighted_accuracy: 0.5689 - val_accuracy: 0.7284 - val_loss: 0.5660 - val_weighted_accuracy: 0.7284\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6890 - loss: 0.5895 - weighted_accuracy: 0.6879 - val_accuracy: 0.8357 - val_loss: 0.3987 - val_weighted_accuracy: 0.8357\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7408 - loss: 0.5198 - weighted_accuracy: 0.7463 - val_accuracy: 0.8597 - val_loss: 0.3334 - val_weighted_accuracy: 0.8597\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7776 - loss: 0.4588 - weighted_accuracy: 0.7830 - val_accuracy: 0.8372 - val_loss: 0.4175 - val_weighted_accuracy: 0.8372\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8066 - loss: 0.4090 - weighted_accuracy: 0.8107 - val_accuracy: 0.8638 - val_loss: 0.2919 - val_weighted_accuracy: 0.8638\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8202 - loss: 0.3818 - weighted_accuracy: 0.8252 - val_accuracy: 0.8177 - val_loss: 0.3606 - val_weighted_accuracy: 0.8177\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8337 - loss: 0.3541 - weighted_accuracy: 0.8380 - val_accuracy: 0.8993 - val_loss: 0.2379 - val_weighted_accuracy: 0.8993\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8419 - loss: 0.3440 - weighted_accuracy: 0.8466 - val_accuracy: 0.8347 - val_loss: 0.3338 - val_weighted_accuracy: 0.8347\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8524 - loss: 0.3238 - weighted_accuracy: 0.8558 - val_accuracy: 0.8423 - val_loss: 0.3347 - val_weighted_accuracy: 0.8423\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8575 - loss: 0.3099 - weighted_accuracy: 0.8623 - val_accuracy: 0.8876 - val_loss: 0.2745 - val_weighted_accuracy: 0.8876\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8661 - loss: 0.2936 - weighted_accuracy: 0.8708 - val_accuracy: 0.7517 - val_loss: 0.5671 - val_weighted_accuracy: 0.7517\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8782 - loss: 0.2707 - weighted_accuracy: 0.8815 - val_accuracy: 0.8759 - val_loss: 0.2778 - val_weighted_accuracy: 0.8759\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8902 - loss: 0.2498 - weighted_accuracy: 0.8944 - val_accuracy: 0.8984 - val_loss: 0.2247 - val_weighted_accuracy: 0.8984\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8898 - loss: 0.2424 - weighted_accuracy: 0.8937 - val_accuracy: 0.9200 - val_loss: 0.1812 - val_weighted_accuracy: 0.9200\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9007 - loss: 0.2193 - weighted_accuracy: 0.9046 - val_accuracy: 0.9294 - val_loss: 0.1634 - val_weighted_accuracy: 0.9294\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9061 - loss: 0.2124 - weighted_accuracy: 0.9094 - val_accuracy: 0.9269 - val_loss: 0.1695 - val_weighted_accuracy: 0.9269\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9091 - loss: 0.2068 - weighted_accuracy: 0.9119 - val_accuracy: 0.8955 - val_loss: 0.2363 - val_weighted_accuracy: 0.8955\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9127 - loss: 0.2026 - weighted_accuracy: 0.9158 - val_accuracy: 0.9337 - val_loss: 0.1539 - val_weighted_accuracy: 0.9337\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9155 - loss: 0.1929 - weighted_accuracy: 0.9186 - val_accuracy: 0.9364 - val_loss: 0.1443 - val_weighted_accuracy: 0.9364\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9106 - loss: 0.2139 - weighted_accuracy: 0.9129 - val_accuracy: 0.9114 - val_loss: 0.1891 - val_weighted_accuracy: 0.9114\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9231 - loss: 0.1753 - weighted_accuracy: 0.9268 - val_accuracy: 0.9370 - val_loss: 0.1436 - val_weighted_accuracy: 0.9370\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9234 - loss: 0.1787 - weighted_accuracy: 0.9269 - val_accuracy: 0.9385 - val_loss: 0.1344 - val_weighted_accuracy: 0.9385\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9215 - loss: 0.1877 - weighted_accuracy: 0.9240 - val_accuracy: 0.9305 - val_loss: 0.1720 - val_weighted_accuracy: 0.9305\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9204 - loss: 0.1885 - weighted_accuracy: 0.9229 - val_accuracy: 0.8600 - val_loss: 0.3238 - val_weighted_accuracy: 0.8600\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9321 - loss: 0.1604 - weighted_accuracy: 0.9344 - val_accuracy: 0.9417 - val_loss: 0.1375 - val_weighted_accuracy: 0.9417\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9302 - loss: 0.1697 - weighted_accuracy: 0.9318 - val_accuracy: 0.9453 - val_loss: 0.1277 - val_weighted_accuracy: 0.9453\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9393 - loss: 0.1402 - weighted_accuracy: 0.9416 - val_accuracy: 0.9406 - val_loss: 0.1392 - val_weighted_accuracy: 0.9406\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9371 - loss: 0.1502 - weighted_accuracy: 0.9394 - val_accuracy: 0.9450 - val_loss: 0.1253 - val_weighted_accuracy: 0.9450\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9400 - loss: 0.1466 - weighted_accuracy: 0.9422 - val_accuracy: 0.9530 - val_loss: 0.1132 - val_weighted_accuracy: 0.9530\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9478 - loss: 0.1251 - weighted_accuracy: 0.9496 - val_accuracy: 0.9524 - val_loss: 0.1122 - val_weighted_accuracy: 0.9524\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "early_stopping = EarlyStopping(patience=8, start_from_epoch=8, restore_best_weights=True, verbose=1)\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "decay_steps = 10_000\n",
    "decay_rate = 0.96\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=initial_learning_rate,\n",
    "                               decay_steps=decay_steps, decay_rate=decay_rate)\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "\n",
    "optimizer = SGD(lr_schedule)\n",
    "\n",
    "model = simple_nn()\n",
    "model.name = f\"simplenn_exp_decay_lr_{initial_learning_rate}_steps_{decay_steps}_rate_{decay_rate}\"\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                    class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some other decay steps and decay rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6049 - loss: 0.7340 - weighted_accuracy: 0.5777 - val_accuracy: 0.8012 - val_loss: 0.4820 - val_weighted_accuracy: 0.8012\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.7622 - loss: 0.4895 - weighted_accuracy: 0.7676 - val_accuracy: 0.8342 - val_loss: 0.3934 - val_weighted_accuracy: 0.8342\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8373 - loss: 0.3829 - weighted_accuracy: 0.8482 - val_accuracy: 0.8484 - val_loss: 0.3650 - val_weighted_accuracy: 0.8484\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8485 - loss: 0.3633 - weighted_accuracy: 0.8600 - val_accuracy: 0.8484 - val_loss: 0.3628 - val_weighted_accuracy: 0.8484\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8507 - loss: 0.3589 - weighted_accuracy: 0.8620 - val_accuracy: 0.8476 - val_loss: 0.3648 - val_weighted_accuracy: 0.8476\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8511 - loss: 0.3581 - weighted_accuracy: 0.8629 - val_accuracy: 0.8459 - val_loss: 0.3655 - val_weighted_accuracy: 0.8459\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8510 - loss: 0.3577 - weighted_accuracy: 0.8633 - val_accuracy: 0.8475 - val_loss: 0.3645 - val_weighted_accuracy: 0.8475\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8510 - loss: 0.3578 - weighted_accuracy: 0.8632 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8515 - loss: 0.3574 - weighted_accuracy: 0.8635 - val_accuracy: 0.8479 - val_loss: 0.3643 - val_weighted_accuracy: 0.8479\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8513 - loss: 0.3578 - weighted_accuracy: 0.8632 - val_accuracy: 0.8479 - val_loss: 0.3643 - val_weighted_accuracy: 0.8479\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8513 - loss: 0.3576 - weighted_accuracy: 0.8633 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8514 - loss: 0.3576 - weighted_accuracy: 0.8634 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8514 - loss: 0.3578 - weighted_accuracy: 0.8634 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8512 - loss: 0.3575 - weighted_accuracy: 0.8633 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8510 - loss: 0.3580 - weighted_accuracy: 0.8631 - val_accuracy: 0.8479 - val_loss: 0.3644 - val_weighted_accuracy: 0.8479\n",
      "Epoch 15: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.6047 - loss: 0.6863 - weighted_accuracy: 0.5865 - val_accuracy: 0.4747 - val_loss: 0.8133 - val_weighted_accuracy: 0.4747\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7315 - loss: 0.5222 - weighted_accuracy: 0.7364 - val_accuracy: 0.7315 - val_loss: 0.5149 - val_weighted_accuracy: 0.7315\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.3822 - weighted_accuracy: 0.8264 - val_accuracy: 0.8742 - val_loss: 0.2987 - val_weighted_accuracy: 0.8742\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8631 - loss: 0.3084 - weighted_accuracy: 0.8711 - val_accuracy: 0.8858 - val_loss: 0.2698 - val_weighted_accuracy: 0.8858\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8787 - loss: 0.2813 - weighted_accuracy: 0.8864 - val_accuracy: 0.8876 - val_loss: 0.2715 - val_weighted_accuracy: 0.8876\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8843 - loss: 0.2702 - weighted_accuracy: 0.8918 - val_accuracy: 0.8882 - val_loss: 0.2711 - val_weighted_accuracy: 0.8882\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8872 - loss: 0.2656 - weighted_accuracy: 0.8940 - val_accuracy: 0.8864 - val_loss: 0.2717 - val_weighted_accuracy: 0.8864\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8883 - loss: 0.2636 - weighted_accuracy: 0.8953 - val_accuracy: 0.8859 - val_loss: 0.2734 - val_weighted_accuracy: 0.8859\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8887 - loss: 0.2629 - weighted_accuracy: 0.8960 - val_accuracy: 0.8847 - val_loss: 0.2747 - val_weighted_accuracy: 0.8847\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8887 - loss: 0.2625 - weighted_accuracy: 0.8958 - val_accuracy: 0.8844 - val_loss: 0.2754 - val_weighted_accuracy: 0.8844\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2618 - weighted_accuracy: 0.8961 - val_accuracy: 0.8843 - val_loss: 0.2754 - val_weighted_accuracy: 0.8843\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8884 - loss: 0.2621 - weighted_accuracy: 0.8957 - val_accuracy: 0.8844 - val_loss: 0.2750 - val_weighted_accuracy: 0.8844\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8885 - loss: 0.2622 - weighted_accuracy: 0.8959 - val_accuracy: 0.8846 - val_loss: 0.2746 - val_weighted_accuracy: 0.8846\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8886 - loss: 0.2623 - weighted_accuracy: 0.8959 - val_accuracy: 0.8847 - val_loss: 0.2744 - val_weighted_accuracy: 0.8847\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2619 - weighted_accuracy: 0.8962 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8889 - loss: 0.2619 - weighted_accuracy: 0.8961 - val_accuracy: 0.8849 - val_loss: 0.2743 - val_weighted_accuracy: 0.8849\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2619 - weighted_accuracy: 0.8962 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8891 - loss: 0.2619 - weighted_accuracy: 0.8963 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8886 - loss: 0.2624 - weighted_accuracy: 0.8958 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8888 - loss: 0.2622 - weighted_accuracy: 0.8960 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8889 - loss: 0.2618 - weighted_accuracy: 0.8961 - val_accuracy: 0.8849 - val_loss: 0.2744 - val_weighted_accuracy: 0.8849\n",
      "Epoch 21: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6028 - loss: 0.7201 - weighted_accuracy: 0.5848 - val_accuracy: 0.3976 - val_loss: 0.9139 - val_weighted_accuracy: 0.3976\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6994 - loss: 0.5685 - weighted_accuracy: 0.7062 - val_accuracy: 0.8023 - val_loss: 0.4159 - val_weighted_accuracy: 0.8023\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7509 - loss: 0.5061 - weighted_accuracy: 0.7525 - val_accuracy: 0.8250 - val_loss: 0.3424 - val_weighted_accuracy: 0.8250\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8145 - loss: 0.3936 - weighted_accuracy: 0.8189 - val_accuracy: 0.8556 - val_loss: 0.3270 - val_weighted_accuracy: 0.8556\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8415 - loss: 0.3416 - weighted_accuracy: 0.8457 - val_accuracy: 0.8784 - val_loss: 0.2575 - val_weighted_accuracy: 0.8784\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8689 - loss: 0.2911 - weighted_accuracy: 0.8730 - val_accuracy: 0.7527 - val_loss: 0.5369 - val_weighted_accuracy: 0.7527\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8844 - loss: 0.2590 - weighted_accuracy: 0.8891 - val_accuracy: 0.8936 - val_loss: 0.2514 - val_weighted_accuracy: 0.8936\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8994 - loss: 0.2336 - weighted_accuracy: 0.9024 - val_accuracy: 0.9103 - val_loss: 0.2117 - val_weighted_accuracy: 0.9103\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.9061 - loss: 0.2149 - weighted_accuracy: 0.9092 - val_accuracy: 0.9099 - val_loss: 0.2124 - val_weighted_accuracy: 0.9099\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9129 - loss: 0.2047 - weighted_accuracy: 0.9164 - val_accuracy: 0.9085 - val_loss: 0.2183 - val_weighted_accuracy: 0.9085\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9183 - loss: 0.1957 - weighted_accuracy: 0.9220 - val_accuracy: 0.9125 - val_loss: 0.2079 - val_weighted_accuracy: 0.9125\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9206 - loss: 0.1897 - weighted_accuracy: 0.9241 - val_accuracy: 0.9149 - val_loss: 0.2004 - val_weighted_accuracy: 0.9149\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9230 - loss: 0.1853 - weighted_accuracy: 0.9259 - val_accuracy: 0.9141 - val_loss: 0.2018 - val_weighted_accuracy: 0.9141\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9240 - loss: 0.1826 - weighted_accuracy: 0.9269 - val_accuracy: 0.9149 - val_loss: 0.1998 - val_weighted_accuracy: 0.9149\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9246 - loss: 0.1801 - weighted_accuracy: 0.9280 - val_accuracy: 0.9182 - val_loss: 0.1959 - val_weighted_accuracy: 0.9182\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9264 - loss: 0.1783 - weighted_accuracy: 0.9299 - val_accuracy: 0.9176 - val_loss: 0.1964 - val_weighted_accuracy: 0.9176\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.1770 - weighted_accuracy: 0.9300 - val_accuracy: 0.9200 - val_loss: 0.1926 - val_weighted_accuracy: 0.9200\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9275 - loss: 0.1757 - weighted_accuracy: 0.9312 - val_accuracy: 0.9188 - val_loss: 0.1938 - val_weighted_accuracy: 0.9188\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9271 - loss: 0.1755 - weighted_accuracy: 0.9304 - val_accuracy: 0.9183 - val_loss: 0.1955 - val_weighted_accuracy: 0.9183\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9279 - loss: 0.1748 - weighted_accuracy: 0.9310 - val_accuracy: 0.9170 - val_loss: 0.1964 - val_weighted_accuracy: 0.9170\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9286 - loss: 0.1742 - weighted_accuracy: 0.9319 - val_accuracy: 0.9169 - val_loss: 0.1969 - val_weighted_accuracy: 0.9169\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9285 - loss: 0.1740 - weighted_accuracy: 0.9317 - val_accuracy: 0.9160 - val_loss: 0.1977 - val_weighted_accuracy: 0.9160\n",
      "Epoch 22: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6020 - loss: 0.6972 - weighted_accuracy: 0.5755 - val_accuracy: 0.7542 - val_loss: 0.4639 - val_weighted_accuracy: 0.7542\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6885 - loss: 0.5778 - weighted_accuracy: 0.6984 - val_accuracy: 0.8330 - val_loss: 0.4531 - val_weighted_accuracy: 0.8330\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7546 - loss: 0.4904 - weighted_accuracy: 0.7601 - val_accuracy: 0.8542 - val_loss: 0.3882 - val_weighted_accuracy: 0.8542\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7965 - loss: 0.4200 - weighted_accuracy: 0.8026 - val_accuracy: 0.8246 - val_loss: 0.3670 - val_weighted_accuracy: 0.8246\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8251 - loss: 0.3639 - weighted_accuracy: 0.8308 - val_accuracy: 0.8940 - val_loss: 0.2785 - val_weighted_accuracy: 0.8940\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8509 - loss: 0.3179 - weighted_accuracy: 0.8573 - val_accuracy: 0.8864 - val_loss: 0.2604 - val_weighted_accuracy: 0.8864\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8647 - loss: 0.2873 - weighted_accuracy: 0.8708 - val_accuracy: 0.8946 - val_loss: 0.2415 - val_weighted_accuracy: 0.8946\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8799 - loss: 0.2568 - weighted_accuracy: 0.8858 - val_accuracy: 0.8854 - val_loss: 0.2579 - val_weighted_accuracy: 0.8854\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8924 - loss: 0.2339 - weighted_accuracy: 0.8976 - val_accuracy: 0.9013 - val_loss: 0.2139 - val_weighted_accuracy: 0.9013\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9064 - loss: 0.2093 - weighted_accuracy: 0.9114 - val_accuracy: 0.9189 - val_loss: 0.1850 - val_weighted_accuracy: 0.9189\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9115 - loss: 0.1959 - weighted_accuracy: 0.9160 - val_accuracy: 0.8713 - val_loss: 0.2839 - val_weighted_accuracy: 0.8713\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9187 - loss: 0.1812 - weighted_accuracy: 0.9225 - val_accuracy: 0.8990 - val_loss: 0.2326 - val_weighted_accuracy: 0.8990\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9261 - loss: 0.1694 - weighted_accuracy: 0.9301 - val_accuracy: 0.9172 - val_loss: 0.1871 - val_weighted_accuracy: 0.9172\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9306 - loss: 0.1612 - weighted_accuracy: 0.9345 - val_accuracy: 0.9276 - val_loss: 0.1696 - val_weighted_accuracy: 0.9276\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9339 - loss: 0.1530 - weighted_accuracy: 0.9373 - val_accuracy: 0.9318 - val_loss: 0.1579 - val_weighted_accuracy: 0.9318\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9375 - loss: 0.1465 - weighted_accuracy: 0.9411 - val_accuracy: 0.9305 - val_loss: 0.1613 - val_weighted_accuracy: 0.9305\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9410 - loss: 0.1379 - weighted_accuracy: 0.9446 - val_accuracy: 0.9315 - val_loss: 0.1592 - val_weighted_accuracy: 0.9315\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9435 - loss: 0.1351 - weighted_accuracy: 0.9470 - val_accuracy: 0.9340 - val_loss: 0.1528 - val_weighted_accuracy: 0.9340\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.1317 - weighted_accuracy: 0.9473 - val_accuracy: 0.9308 - val_loss: 0.1613 - val_weighted_accuracy: 0.9308\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9466 - loss: 0.1276 - weighted_accuracy: 0.9503 - val_accuracy: 0.9344 - val_loss: 0.1528 - val_weighted_accuracy: 0.9344\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9479 - loss: 0.1254 - weighted_accuracy: 0.9514 - val_accuracy: 0.9352 - val_loss: 0.1502 - val_weighted_accuracy: 0.9352\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9490 - loss: 0.1229 - weighted_accuracy: 0.9524 - val_accuracy: 0.9352 - val_loss: 0.1498 - val_weighted_accuracy: 0.9352\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9490 - loss: 0.1210 - weighted_accuracy: 0.9523 - val_accuracy: 0.9360 - val_loss: 0.1468 - val_weighted_accuracy: 0.9360\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9512 - loss: 0.1187 - weighted_accuracy: 0.9543 - val_accuracy: 0.9339 - val_loss: 0.1526 - val_weighted_accuracy: 0.9339\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9511 - loss: 0.1175 - weighted_accuracy: 0.9543 - val_accuracy: 0.9366 - val_loss: 0.1469 - val_weighted_accuracy: 0.9366\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9524 - loss: 0.1162 - weighted_accuracy: 0.9554 - val_accuracy: 0.9393 - val_loss: 0.1423 - val_weighted_accuracy: 0.9393\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9525 - loss: 0.1151 - weighted_accuracy: 0.9554 - val_accuracy: 0.9371 - val_loss: 0.1468 - val_weighted_accuracy: 0.9371\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9523 - loss: 0.1136 - weighted_accuracy: 0.9553 - val_accuracy: 0.9398 - val_loss: 0.1412 - val_weighted_accuracy: 0.9398\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9526 - loss: 0.1136 - weighted_accuracy: 0.9557 - val_accuracy: 0.9373 - val_loss: 0.1442 - val_weighted_accuracy: 0.9373\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9536 - loss: 0.1123 - weighted_accuracy: 0.9566 - val_accuracy: 0.9392 - val_loss: 0.1413 - val_weighted_accuracy: 0.9392\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6090 - loss: 0.7054 - weighted_accuracy: 0.5785 - val_accuracy: 0.7784 - val_loss: 0.5373 - val_weighted_accuracy: 0.7784\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6906 - loss: 0.5928 - weighted_accuracy: 0.6873 - val_accuracy: 0.7234 - val_loss: 0.5305 - val_weighted_accuracy: 0.7234\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7501 - loss: 0.5095 - weighted_accuracy: 0.7526 - val_accuracy: 0.7929 - val_loss: 0.4445 - val_weighted_accuracy: 0.7929\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7837 - loss: 0.4463 - weighted_accuracy: 0.7855 - val_accuracy: 0.8749 - val_loss: 0.2861 - val_weighted_accuracy: 0.8749\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8175 - loss: 0.3917 - weighted_accuracy: 0.8210 - val_accuracy: 0.8928 - val_loss: 0.2569 - val_weighted_accuracy: 0.8928\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8354 - loss: 0.3578 - weighted_accuracy: 0.8381 - val_accuracy: 0.8864 - val_loss: 0.2677 - val_weighted_accuracy: 0.8864\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8581 - loss: 0.3110 - weighted_accuracy: 0.8621 - val_accuracy: 0.9057 - val_loss: 0.2315 - val_weighted_accuracy: 0.9057\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8682 - loss: 0.2909 - weighted_accuracy: 0.8719 - val_accuracy: 0.9019 - val_loss: 0.2368 - val_weighted_accuracy: 0.9019\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8816 - loss: 0.2636 - weighted_accuracy: 0.8865 - val_accuracy: 0.5125 - val_loss: 1.4171 - val_weighted_accuracy: 0.5125\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8871 - loss: 0.2510 - weighted_accuracy: 0.8911 - val_accuracy: 0.9110 - val_loss: 0.2128 - val_weighted_accuracy: 0.9110\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8940 - loss: 0.2366 - weighted_accuracy: 0.8976 - val_accuracy: 0.9155 - val_loss: 0.2003 - val_weighted_accuracy: 0.9155\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9102 - loss: 0.2074 - weighted_accuracy: 0.9134 - val_accuracy: 0.9175 - val_loss: 0.1984 - val_weighted_accuracy: 0.9175\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.2019 - weighted_accuracy: 0.9139 - val_accuracy: 0.8955 - val_loss: 0.2266 - val_weighted_accuracy: 0.8955\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.5980 - loss: 0.6989 - weighted_accuracy: 0.5801 - val_accuracy: 0.7155 - val_loss: 0.5215 - val_weighted_accuracy: 0.7155\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6979 - loss: 0.5784 - weighted_accuracy: 0.7016 - val_accuracy: 0.8267 - val_loss: 0.4330 - val_weighted_accuracy: 0.8267\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7442 - loss: 0.5076 - weighted_accuracy: 0.7519 - val_accuracy: 0.7111 - val_loss: 0.5494 - val_weighted_accuracy: 0.7111\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7816 - loss: 0.4547 - weighted_accuracy: 0.7867 - val_accuracy: 0.8386 - val_loss: 0.3597 - val_weighted_accuracy: 0.8386\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8076 - loss: 0.4038 - weighted_accuracy: 0.8112 - val_accuracy: 0.8905 - val_loss: 0.2628 - val_weighted_accuracy: 0.8905\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8301 - loss: 0.3639 - weighted_accuracy: 0.8339 - val_accuracy: 0.8749 - val_loss: 0.2678 - val_weighted_accuracy: 0.8749\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8372 - loss: 0.3564 - weighted_accuracy: 0.8403 - val_accuracy: 0.8910 - val_loss: 0.2540 - val_weighted_accuracy: 0.8910\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8532 - loss: 0.3293 - weighted_accuracy: 0.8573 - val_accuracy: 0.7935 - val_loss: 0.4292 - val_weighted_accuracy: 0.7935\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8608 - loss: 0.3074 - weighted_accuracy: 0.8652 - val_accuracy: 0.8943 - val_loss: 0.2265 - val_weighted_accuracy: 0.8943\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8676 - loss: 0.2978 - weighted_accuracy: 0.8716 - val_accuracy: 0.9052 - val_loss: 0.2249 - val_weighted_accuracy: 0.9052\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8832 - loss: 0.2641 - weighted_accuracy: 0.8874 - val_accuracy: 0.9102 - val_loss: 0.2213 - val_weighted_accuracy: 0.9102\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8922 - loss: 0.2403 - weighted_accuracy: 0.8961 - val_accuracy: 0.9243 - val_loss: 0.1769 - val_weighted_accuracy: 0.9243\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8982 - loss: 0.2314 - weighted_accuracy: 0.9012 - val_accuracy: 0.8836 - val_loss: 0.2652 - val_weighted_accuracy: 0.8836\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.5879 - loss: 0.7091 - weighted_accuracy: 0.5707 - val_accuracy: 0.7786 - val_loss: 0.4864 - val_weighted_accuracy: 0.7786\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6964 - loss: 0.5792 - weighted_accuracy: 0.7005 - val_accuracy: 0.7327 - val_loss: 0.6149 - val_weighted_accuracy: 0.7327\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7417 - loss: 0.5184 - weighted_accuracy: 0.7479 - val_accuracy: 0.8202 - val_loss: 0.4280 - val_weighted_accuracy: 0.8202\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7767 - loss: 0.4625 - weighted_accuracy: 0.7823 - val_accuracy: 0.8719 - val_loss: 0.3245 - val_weighted_accuracy: 0.8719\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7972 - loss: 0.4288 - weighted_accuracy: 0.8005 - val_accuracy: 0.8871 - val_loss: 0.2670 - val_weighted_accuracy: 0.8871\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8221 - loss: 0.3841 - weighted_accuracy: 0.8250 - val_accuracy: 0.7881 - val_loss: 0.4522 - val_weighted_accuracy: 0.7881\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 0.3455 - weighted_accuracy: 0.8437 - val_accuracy: 0.8854 - val_loss: 0.2522 - val_weighted_accuracy: 0.8854\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8580 - loss: 0.3142 - weighted_accuracy: 0.8622 - val_accuracy: 0.6797 - val_loss: 0.7271 - val_weighted_accuracy: 0.6797\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8632 - loss: 0.3047 - weighted_accuracy: 0.8676 - val_accuracy: 0.7737 - val_loss: 0.4974 - val_weighted_accuracy: 0.7737\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8684 - loss: 0.2950 - weighted_accuracy: 0.8731 - val_accuracy: 0.8115 - val_loss: 0.3993 - val_weighted_accuracy: 0.8115\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8764 - loss: 0.2726 - weighted_accuracy: 0.8806 - val_accuracy: 0.9102 - val_loss: 0.2023 - val_weighted_accuracy: 0.9102\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8903 - loss: 0.2451 - weighted_accuracy: 0.8931 - val_accuracy: 0.8924 - val_loss: 0.2322 - val_weighted_accuracy: 0.8924\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.2450 - weighted_accuracy: 0.8949 - val_accuracy: 0.9193 - val_loss: 0.1907 - val_weighted_accuracy: 0.9193\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5893 - loss: 0.6913 - weighted_accuracy: 0.5771 - val_accuracy: 0.7886 - val_loss: 0.4948 - val_weighted_accuracy: 0.7886\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6882 - loss: 0.5845 - weighted_accuracy: 0.6925 - val_accuracy: 0.6940 - val_loss: 0.5782 - val_weighted_accuracy: 0.6940\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7410 - loss: 0.5169 - weighted_accuracy: 0.7460 - val_accuracy: 0.7985 - val_loss: 0.3789 - val_weighted_accuracy: 0.7985\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.7767 - loss: 0.4548 - weighted_accuracy: 0.7823 - val_accuracy: 0.7690 - val_loss: 0.4606 - val_weighted_accuracy: 0.7690\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8008 - loss: 0.4179 - weighted_accuracy: 0.8066 - val_accuracy: 0.8453 - val_loss: 0.3478 - val_weighted_accuracy: 0.8453\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8222 - loss: 0.3739 - weighted_accuracy: 0.8283 - val_accuracy: 0.8887 - val_loss: 0.3016 - val_weighted_accuracy: 0.8887\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8362 - loss: 0.3488 - weighted_accuracy: 0.8418 - val_accuracy: 0.8600 - val_loss: 0.3103 - val_weighted_accuracy: 0.8600\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8508 - loss: 0.3267 - weighted_accuracy: 0.8555 - val_accuracy: 0.7470 - val_loss: 0.5297 - val_weighted_accuracy: 0.7470\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8568 - loss: 0.3134 - weighted_accuracy: 0.8617 - val_accuracy: 0.8347 - val_loss: 0.3776 - val_weighted_accuracy: 0.8347\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8598 - loss: 0.3065 - weighted_accuracy: 0.8652 - val_accuracy: 0.9093 - val_loss: 0.2079 - val_weighted_accuracy: 0.9093\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8723 - loss: 0.2838 - weighted_accuracy: 0.8763 - val_accuracy: 0.8257 - val_loss: 0.3858 - val_weighted_accuracy: 0.8257\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8803 - loss: 0.2637 - weighted_accuracy: 0.8848 - val_accuracy: 0.8953 - val_loss: 0.2195 - val_weighted_accuracy: 0.8953\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8837 - loss: 0.2685 - weighted_accuracy: 0.8876 - val_accuracy: 0.9191 - val_loss: 0.1867 - val_weighted_accuracy: 0.9191\n",
      "Epoch 13: early stopping\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.5831 - loss: 0.7148 - weighted_accuracy: 0.5822 - val_accuracy: 0.7598 - val_loss: 0.5586 - val_weighted_accuracy: 0.7598\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6752 - loss: 0.6179 - weighted_accuracy: 0.6692 - val_accuracy: 0.8069 - val_loss: 0.4243 - val_weighted_accuracy: 0.8069\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7416 - loss: 0.5262 - weighted_accuracy: 0.7427 - val_accuracy: 0.7034 - val_loss: 0.7337 - val_weighted_accuracy: 0.7034\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7793 - loss: 0.4685 - weighted_accuracy: 0.7788 - val_accuracy: 0.8548 - val_loss: 0.3819 - val_weighted_accuracy: 0.8548\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7985 - loss: 0.4320 - weighted_accuracy: 0.7991 - val_accuracy: 0.4019 - val_loss: 1.5383 - val_weighted_accuracy: 0.4019\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8174 - loss: 0.3922 - weighted_accuracy: 0.8196 - val_accuracy: 0.8561 - val_loss: 0.3272 - val_weighted_accuracy: 0.8561\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8359 - loss: 0.3570 - weighted_accuracy: 0.8381 - val_accuracy: 0.7834 - val_loss: 0.4427 - val_weighted_accuracy: 0.7834\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8385 - loss: 0.3574 - weighted_accuracy: 0.8391 - val_accuracy: 0.7415 - val_loss: 0.6420 - val_weighted_accuracy: 0.7415\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8527 - loss: 0.3323 - weighted_accuracy: 0.8528 - val_accuracy: 0.8615 - val_loss: 0.3121 - val_weighted_accuracy: 0.8615\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8697 - loss: 0.2959 - weighted_accuracy: 0.8728 - val_accuracy: 0.8763 - val_loss: 0.2581 - val_weighted_accuracy: 0.8763\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8775 - loss: 0.2726 - weighted_accuracy: 0.8801 - val_accuracy: 0.8725 - val_loss: 0.2949 - val_weighted_accuracy: 0.8725\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8798 - loss: 0.2706 - weighted_accuracy: 0.8823 - val_accuracy: 0.9150 - val_loss: 0.2133 - val_weighted_accuracy: 0.9150\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8905 - loss: 0.2473 - weighted_accuracy: 0.8931 - val_accuracy: 0.8898 - val_loss: 0.2533 - val_weighted_accuracy: 0.8898\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "early_stopping = EarlyStopping(patience=5, start_from_epoch=8, verbose=1)\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "decay_steps = np.logspace(3, 5, 3)\n",
    "decay_rates = np.linspace(0.4, 0.84, 3)\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "\n",
    "for decay_step in decay_steps:\n",
    "    for decay_rate in decay_rates:\n",
    "        lr_schedule = ExponentialDecay(initial_learning_rate=initial_learning_rate,\n",
    "                                    decay_steps=decay_step, decay_rate=decay_rate)\n",
    "        optimizer = SGD(lr_schedule)\n",
    "\n",
    "        model = simple_nn()\n",
    "        model.name = f\"simplenn_exp_decay_lr_{initial_learning_rate}_steps_{decay_step}_rate_{decay_rate}\"\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "        model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "        tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "\n",
    "        history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                        class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters are decay_steps $=10000$ and decay_rate $=0.4$.\n",
    "\n",
    "Based on loss graph, we hit underfitting, time to slap 2 more hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_nn() -> Model:\n",
    "    input_shape = (256, 256, 1)\n",
    "    inputs = keras.Input(input_shape, dtype=np.float32)\n",
    "    x = keras.layers.Rescaling(scale=1./255)(inputs)\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"DeepNN\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.5792 - loss: 0.6801 - weighted_accuracy: 0.5609 - val_accuracy: 0.7272 - val_loss: 0.6002 - val_weighted_accuracy: 0.7272\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6493 - loss: 0.6004 - weighted_accuracy: 0.6739 - val_accuracy: 0.7724 - val_loss: 0.4276 - val_weighted_accuracy: 0.7724\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.6639 - loss: 0.5658 - weighted_accuracy: 0.7020 - val_accuracy: 0.8441 - val_loss: 0.3831 - val_weighted_accuracy: 0.8441\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6831 - loss: 0.5385 - weighted_accuracy: 0.7295 - val_accuracy: 0.8432 - val_loss: 0.3420 - val_weighted_accuracy: 0.8432\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7461 - loss: 0.4593 - weighted_accuracy: 0.7830 - val_accuracy: 0.8698 - val_loss: 0.2816 - val_weighted_accuracy: 0.8698\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7707 - loss: 0.4334 - weighted_accuracy: 0.8006 - val_accuracy: 0.8026 - val_loss: 0.3858 - val_weighted_accuracy: 0.8026\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8068 - loss: 0.3817 - weighted_accuracy: 0.8304 - val_accuracy: 0.8318 - val_loss: 0.3625 - val_weighted_accuracy: 0.8318\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8109 - loss: 0.3705 - weighted_accuracy: 0.8338 - val_accuracy: 0.8836 - val_loss: 0.2626 - val_weighted_accuracy: 0.8836\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.3553 - weighted_accuracy: 0.8432 - val_accuracy: 0.8390 - val_loss: 0.3234 - val_weighted_accuracy: 0.8390\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.8362 - loss: 0.3376 - weighted_accuracy: 0.8549 - val_accuracy: 0.8694 - val_loss: 0.2732 - val_weighted_accuracy: 0.8694\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8506 - loss: 0.3104 - weighted_accuracy: 0.8661 - val_accuracy: 0.8986 - val_loss: 0.2353 - val_weighted_accuracy: 0.8986\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8601 - loss: 0.2992 - weighted_accuracy: 0.8749 - val_accuracy: 0.9116 - val_loss: 0.2039 - val_weighted_accuracy: 0.9116\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8652 - loss: 0.2847 - weighted_accuracy: 0.8772 - val_accuracy: 0.9008 - val_loss: 0.2290 - val_weighted_accuracy: 0.9008\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8729 - loss: 0.2666 - weighted_accuracy: 0.8850 - val_accuracy: 0.9034 - val_loss: 0.2126 - val_weighted_accuracy: 0.9034\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8823 - loss: 0.2503 - weighted_accuracy: 0.8942 - val_accuracy: 0.9166 - val_loss: 0.1916 - val_weighted_accuracy: 0.9166\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8882 - loss: 0.2404 - weighted_accuracy: 0.8989 - val_accuracy: 0.9222 - val_loss: 0.1766 - val_weighted_accuracy: 0.9222\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8939 - loss: 0.2275 - weighted_accuracy: 0.9037 - val_accuracy: 0.9096 - val_loss: 0.2208 - val_weighted_accuracy: 0.9096\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8889 - loss: 0.2314 - weighted_accuracy: 0.9002 - val_accuracy: 0.8928 - val_loss: 0.2223 - val_weighted_accuracy: 0.8928\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8975 - loss: 0.2212 - weighted_accuracy: 0.9094 - val_accuracy: 0.9232 - val_loss: 0.1711 - val_weighted_accuracy: 0.9232\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9038 - loss: 0.2092 - weighted_accuracy: 0.9125 - val_accuracy: 0.8260 - val_loss: 0.3570 - val_weighted_accuracy: 0.8260\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9048 - loss: 0.2105 - weighted_accuracy: 0.9137 - val_accuracy: 0.9326 - val_loss: 0.1593 - val_weighted_accuracy: 0.9326\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9077 - loss: 0.2114 - weighted_accuracy: 0.9172 - val_accuracy: 0.9358 - val_loss: 0.1503 - val_weighted_accuracy: 0.9358\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9116 - loss: 0.1926 - weighted_accuracy: 0.9192 - val_accuracy: 0.9409 - val_loss: 0.1416 - val_weighted_accuracy: 0.9409\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9133 - loss: 0.1908 - weighted_accuracy: 0.9207 - val_accuracy: 0.9384 - val_loss: 0.1480 - val_weighted_accuracy: 0.9384\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9223 - loss: 0.1715 - weighted_accuracy: 0.9290 - val_accuracy: 0.9247 - val_loss: 0.1661 - val_weighted_accuracy: 0.9247\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9236 - loss: 0.1718 - weighted_accuracy: 0.9309 - val_accuracy: 0.9405 - val_loss: 0.1378 - val_weighted_accuracy: 0.9405\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9267 - loss: 0.1612 - weighted_accuracy: 0.9331 - val_accuracy: 0.9461 - val_loss: 0.1259 - val_weighted_accuracy: 0.9461\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.1634 - weighted_accuracy: 0.9327 - val_accuracy: 0.9391 - val_loss: 0.1375 - val_weighted_accuracy: 0.9391\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9321 - loss: 0.1520 - weighted_accuracy: 0.9377 - val_accuracy: 0.9198 - val_loss: 0.1653 - val_weighted_accuracy: 0.9198\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9305 - loss: 0.1571 - weighted_accuracy: 0.9362 - val_accuracy: 0.9435 - val_loss: 0.1428 - val_weighted_accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "lr_dir = os.path.join(LOG_DIR, \"simple_vs_deep\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "learning_rate = 0.01\n",
    "# early_stopping = EarlyStopping(patience=5, start_from_epoch=8, verbose=1)\n",
    "\n",
    "# initial_learning_rate = 0.01\n",
    "# decay_steps = np.logspace(3, 5, 3)\n",
    "# decay_rates = np.linspace(0.4, 0.84, 3)\n",
    "\n",
    "optimizer = SGD(learning_rate)\n",
    "\n",
    "model = deep_nn()\n",
    "model.name = model.name + f\"_lr_{initial_learning_rate}\"\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                            write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                class_weight=class_weights, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with higher learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.4992 - loss: 0.8221 - weighted_accuracy: 0.4997 - val_accuracy: 0.3084 - val_loss: 0.6939 - val_weighted_accuracy: 0.3084\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5457 - loss: 0.6824 - weighted_accuracy: 0.5405 - val_accuracy: 0.3068 - val_loss: 0.6933 - val_weighted_accuracy: 0.3068\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5821 - loss: 0.6920 - weighted_accuracy: 0.4965 - val_accuracy: 0.3067 - val_loss: 0.6956 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5547 - loss: 0.6920 - weighted_accuracy: 0.4978 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.5625 - loss: 0.6919 - weighted_accuracy: 0.4974 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5751 - loss: 0.6902 - weighted_accuracy: 0.5099 - val_accuracy: 0.6905 - val_loss: 0.6398 - val_weighted_accuracy: 0.6905\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6515 - loss: 0.6625 - weighted_accuracy: 0.6039 - val_accuracy: 0.6933 - val_loss: 0.6641 - val_weighted_accuracy: 0.6933\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6693 - loss: 0.6790 - weighted_accuracy: 0.5546 - val_accuracy: 0.6139 - val_loss: 0.6897 - val_weighted_accuracy: 0.6139\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.6555 - loss: 0.6694 - weighted_accuracy: 0.5756 - val_accuracy: 0.7391 - val_loss: 0.5924 - val_weighted_accuracy: 0.7391\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6958 - loss: 0.6340 - weighted_accuracy: 0.6438 - val_accuracy: 0.7474 - val_loss: 0.5637 - val_weighted_accuracy: 0.7474\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7281 - loss: 0.5987 - weighted_accuracy: 0.6877 - val_accuracy: 0.8450 - val_loss: 0.4538 - val_weighted_accuracy: 0.8450\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7530 - loss: 0.5631 - weighted_accuracy: 0.7195 - val_accuracy: 0.7433 - val_loss: 0.5756 - val_weighted_accuracy: 0.7433\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7744 - loss: 0.5325 - weighted_accuracy: 0.7466 - val_accuracy: 0.8018 - val_loss: 0.4633 - val_weighted_accuracy: 0.8018\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7879 - loss: 0.5027 - weighted_accuracy: 0.7687 - val_accuracy: 0.8687 - val_loss: 0.3588 - val_weighted_accuracy: 0.8687\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7935 - loss: 0.4801 - weighted_accuracy: 0.7887 - val_accuracy: 0.8705 - val_loss: 0.3019 - val_weighted_accuracy: 0.8705\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7906 - loss: 0.4541 - weighted_accuracy: 0.8068 - val_accuracy: 0.4850 - val_loss: 0.7111 - val_weighted_accuracy: 0.4850\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.6434 - loss: 0.5841 - weighted_accuracy: 0.6613 - val_accuracy: 0.8405 - val_loss: 0.3436 - val_weighted_accuracy: 0.8405\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6667 - loss: 0.5110 - weighted_accuracy: 0.7300 - val_accuracy: 0.3067 - val_loss: 0.6963 - val_weighted_accuracy: 0.3067\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5541 - loss: 0.6918 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5546 - loss: 0.6917 - weighted_accuracy: 0.4934 - val_accuracy: 0.3067 - val_loss: 0.6948 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5441 - loss: 0.6921 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6945 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5534 - loss: 0.6920 - weighted_accuracy: 0.4941 - val_accuracy: 0.3067 - val_loss: 0.6952 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5425 - loss: 0.6920 - weighted_accuracy: 0.4972 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "lr_dir = os.path.join(LOG_DIR, \"simple_vs_deep\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "early_stopping = EarlyStopping(patience=8, start_from_epoch=8, verbose=1)\n",
    "\n",
    "initial_learning_rate = 0.01\n",
    "decay_steps = 0.4\n",
    "decay_rates = 10_000\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=initial_learning_rate,\n",
    "                               )\n",
    "optimizer = SGD(learning_rate)\n",
    "\n",
    "model = deep_nn()\n",
    "model.name = model.name + f\"_lr_{learning_rate}\"\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                            write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 21ms/step - accuracy: 0.5880 - auc_2: 0.6024 - binary_accuracy: 0.5723 - loss: 0.6831 - precision_2: 0.5751 - recall_2: 0.5306 - val_accuracy: 0.7803 - val_auc_2: 0.8537 - val_binary_accuracy: 0.7803 - val_loss: 0.4837 - val_precision_2: 0.6921 - val_recall_2: 0.5110\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.6748 - auc_2: 0.7506 - binary_accuracy: 0.6943 - loss: 0.5884 - precision_2: 0.6742 - recall_2: 0.7460 - val_accuracy: 0.7693 - val_auc_2: 0.8542 - val_binary_accuracy: 0.7693 - val_loss: 0.5196 - val_precision_2: 0.7583 - val_recall_2: 0.3636\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.7178 - auc_2: 0.8132 - binary_accuracy: 0.7429 - loss: 0.5169 - precision_2: 0.7127 - recall_2: 0.8094 - val_accuracy: 0.7422 - val_auc_2: 0.9247 - val_binary_accuracy: 0.7422 - val_loss: 0.4683 - val_precision_2: 0.5444 - val_recall_2: 0.9778\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - accuracy: 0.7575 - auc_2: 0.8598 - binary_accuracy: 0.7866 - loss: 0.4497 - precision_2: 0.7468 - recall_2: 0.8639 - val_accuracy: 0.8424 - val_auc_2: 0.9199 - val_binary_accuracy: 0.8424 - val_loss: 0.3513 - val_precision_2: 0.7652 - val_recall_2: 0.7015\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.8002 - auc_2: 0.8950 - binary_accuracy: 0.8216 - loss: 0.3941 - precision_2: 0.7875 - recall_2: 0.8783 - val_accuracy: 0.8853 - val_auc_2: 0.9521 - val_binary_accuracy: 0.8853 - val_loss: 0.2590 - val_precision_2: 0.8255 - val_recall_2: 0.7937\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.8299 - auc_2: 0.9234 - binary_accuracy: 0.8465 - loss: 0.3403 - precision_2: 0.8172 - recall_2: 0.8906 - val_accuracy: 0.8950 - val_auc_2: 0.9616 - val_binary_accuracy: 0.8950 - val_loss: 0.2421 - val_precision_2: 0.7948 - val_recall_2: 0.8864\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.8541 - auc_2: 0.9390 - binary_accuracy: 0.8684 - loss: 0.3042 - precision_2: 0.8414 - recall_2: 0.9061 - val_accuracy: 0.8564 - val_auc_2: 0.9663 - val_binary_accuracy: 0.8564 - val_loss: 0.2981 - val_precision_2: 0.6871 - val_recall_2: 0.9763\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.8703 - auc_2: 0.9519 - binary_accuracy: 0.8823 - loss: 0.2723 - precision_2: 0.8583 - recall_2: 0.9142 - val_accuracy: 0.8917 - val_auc_2: 0.9692 - val_binary_accuracy: 0.8917 - val_loss: 0.2408 - val_precision_2: 0.7584 - val_recall_2: 0.9492\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.8831 - auc_2: 0.9605 - binary_accuracy: 0.8933 - loss: 0.2469 - precision_2: 0.8724 - recall_2: 0.9203 - val_accuracy: 0.8862 - val_auc_2: 0.9665 - val_binary_accuracy: 0.8862 - val_loss: 0.2622 - val_precision_2: 0.9173 - val_recall_2: 0.6913\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.8971 - auc_2: 0.9676 - binary_accuracy: 0.9064 - loss: 0.2241 - precision_2: 0.8865 - recall_2: 0.9310 - val_accuracy: 0.9053 - val_auc_2: 0.9747 - val_binary_accuracy: 0.9053 - val_loss: 0.2159 - val_precision_2: 0.7855 - val_recall_2: 0.9510\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9036 - auc_2: 0.9727 - binary_accuracy: 0.9119 - loss: 0.2064 - precision_2: 0.8938 - recall_2: 0.9337 - val_accuracy: 0.9178 - val_auc_2: 0.9765 - val_binary_accuracy: 0.9178 - val_loss: 0.1890 - val_precision_2: 0.8263 - val_recall_2: 0.9267\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.9109 - auc_2: 0.9761 - binary_accuracy: 0.9176 - loss: 0.1938 - precision_2: 0.9025 - recall_2: 0.9354 - val_accuracy: 0.8629 - val_auc_2: 0.9759 - val_binary_accuracy: 0.8629 - val_loss: 0.3071 - val_precision_2: 0.6945 - val_recall_2: 0.9870\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.9196 - auc_2: 0.9800 - binary_accuracy: 0.9266 - loss: 0.1764 - precision_2: 0.9107 - recall_2: 0.9450 - val_accuracy: 0.9276 - val_auc_2: 0.9793 - val_binary_accuracy: 0.9276 - val_loss: 0.1693 - val_precision_2: 0.8738 - val_recall_2: 0.8927\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9252 - auc_2: 0.9824 - binary_accuracy: 0.9314 - loss: 0.1659 - precision_2: 0.9171 - recall_2: 0.9479 - val_accuracy: 0.9294 - val_auc_2: 0.9796 - val_binary_accuracy: 0.9294 - val_loss: 0.1678 - val_precision_2: 0.8852 - val_recall_2: 0.8843\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9300 - auc_2: 0.9846 - binary_accuracy: 0.9362 - loss: 0.1555 - precision_2: 0.9218 - recall_2: 0.9524 - val_accuracy: 0.9281 - val_auc_2: 0.9818 - val_binary_accuracy: 0.9281 - val_loss: 0.1669 - val_precision_2: 0.8473 - val_recall_2: 0.9339\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - accuracy: 0.9352 - auc_2: 0.9866 - binary_accuracy: 0.9409 - loss: 0.1450 - precision_2: 0.9274 - recall_2: 0.9560 - val_accuracy: 0.9314 - val_auc_2: 0.9819 - val_binary_accuracy: 0.9314 - val_loss: 0.1589 - val_precision_2: 0.9038 - val_recall_2: 0.8687\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.9390 - auc_2: 0.9878 - binary_accuracy: 0.9440 - loss: 0.1386 - precision_2: 0.9321 - recall_2: 0.9571 - val_accuracy: 0.9279 - val_auc_2: 0.9838 - val_binary_accuracy: 0.9279 - val_loss: 0.1684 - val_precision_2: 0.8354 - val_recall_2: 0.9528\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - accuracy: 0.9423 - auc_2: 0.9889 - binary_accuracy: 0.9472 - loss: 0.1322 - precision_2: 0.9353 - recall_2: 0.9600 - val_accuracy: 0.9305 - val_auc_2: 0.9843 - val_binary_accuracy: 0.9305 - val_loss: 0.1621 - val_precision_2: 0.8424 - val_recall_2: 0.9512\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9445 - auc_2: 0.9899 - binary_accuracy: 0.9494 - loss: 0.1262 - precision_2: 0.9374 - recall_2: 0.9624 - val_accuracy: 0.9369 - val_auc_2: 0.9841 - val_binary_accuracy: 0.9369 - val_loss: 0.1479 - val_precision_2: 0.8991 - val_recall_2: 0.8945\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9477 - auc_2: 0.9906 - binary_accuracy: 0.9524 - loss: 0.1215 - precision_2: 0.9410 - recall_2: 0.9648 - val_accuracy: 0.9355 - val_auc_2: 0.9849 - val_binary_accuracy: 0.9355 - val_loss: 0.1523 - val_precision_2: 0.8647 - val_recall_2: 0.9364\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9490 - auc_2: 0.9913 - binary_accuracy: 0.9538 - loss: 0.1173 - precision_2: 0.9421 - recall_2: 0.9664 - val_accuracy: 0.9382 - val_auc_2: 0.9856 - val_binary_accuracy: 0.9382 - val_loss: 0.1494 - val_precision_2: 0.8676 - val_recall_2: 0.9423\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9500 - auc_2: 0.9919 - binary_accuracy: 0.9544 - loss: 0.1136 - precision_2: 0.9436 - recall_2: 0.9660 - val_accuracy: 0.9396 - val_auc_2: 0.9858 - val_binary_accuracy: 0.9396 - val_loss: 0.1433 - val_precision_2: 0.8821 - val_recall_2: 0.9270\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9510 - auc_2: 0.9922 - binary_accuracy: 0.9553 - loss: 0.1115 - precision_2: 0.9448 - recall_2: 0.9666 - val_accuracy: 0.9398 - val_auc_2: 0.9863 - val_binary_accuracy: 0.9398 - val_loss: 0.1449 - val_precision_2: 0.8718 - val_recall_2: 0.9425\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9537 - auc_2: 0.9926 - binary_accuracy: 0.9581 - loss: 0.1085 - precision_2: 0.9471 - recall_2: 0.9697 - val_accuracy: 0.9420 - val_auc_2: 0.9862 - val_binary_accuracy: 0.9420 - val_loss: 0.1390 - val_precision_2: 0.8932 - val_recall_2: 0.9208\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9534 - auc_2: 0.9929 - binary_accuracy: 0.9576 - loss: 0.1063 - precision_2: 0.9472 - recall_2: 0.9687 - val_accuracy: 0.9426 - val_auc_2: 0.9861 - val_binary_accuracy: 0.9426 - val_loss: 0.1382 - val_precision_2: 0.8994 - val_recall_2: 0.9152\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - accuracy: 0.9549 - auc_2: 0.9932 - binary_accuracy: 0.9587 - loss: 0.1041 - precision_2: 0.9494 - recall_2: 0.9685 - val_accuracy: 0.9424 - val_auc_2: 0.9867 - val_binary_accuracy: 0.9424 - val_loss: 0.1369 - val_precision_2: 0.8912 - val_recall_2: 0.9249\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.9560 - auc_2: 0.9935 - binary_accuracy: 0.9601 - loss: 0.1022 - precision_2: 0.9499 - recall_2: 0.9710 - val_accuracy: 0.9427 - val_auc_2: 0.9869 - val_binary_accuracy: 0.9427 - val_loss: 0.1371 - val_precision_2: 0.8864 - val_recall_2: 0.9326\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - accuracy: 0.9563 - auc_2: 0.9936 - binary_accuracy: 0.9603 - loss: 0.1009 - precision_2: 0.9504 - recall_2: 0.9707 - val_accuracy: 0.9422 - val_auc_2: 0.9872 - val_binary_accuracy: 0.9422 - val_loss: 0.1391 - val_precision_2: 0.8783 - val_recall_2: 0.9420\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.9562 - auc_2: 0.9937 - binary_accuracy: 0.9601 - loss: 0.1002 - precision_2: 0.9504 - recall_2: 0.9703 - val_accuracy: 0.9432 - val_auc_2: 0.9872 - val_binary_accuracy: 0.9432 - val_loss: 0.1350 - val_precision_2: 0.8900 - val_recall_2: 0.9298\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - accuracy: 0.9572 - auc_2: 0.9939 - binary_accuracy: 0.9610 - loss: 0.0990 - precision_2: 0.9514 - recall_2: 0.9712 - val_accuracy: 0.9430 - val_auc_2: 0.9873 - val_binary_accuracy: 0.9430 - val_loss: 0.1346 - val_precision_2: 0.8890 - val_recall_2: 0.9303\n"
     ]
    }
   ],
   "source": [
    "lr_dir = os.path.join(LOG_DIR, \"simple_vs_deep\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\n",
    "    BinaryAccuracy(),\n",
    "                    Recall(),\n",
    "                    Precision(),\n",
    "                    AUC(),\n",
    "                    ]\n",
    "early_stopping = EarlyStopping(patience=8, start_from_epoch=8, verbose=1)\n",
    "\n",
    "initial_learning_rate=0.01\n",
    "decay_step=10_000\n",
    "decay_rate=0.4\n",
    "\n",
    "lr_schedule = ExponentialDecay(initial_learning_rate=initial_learning_rate,\n",
    "                               decay_steps=decay_step,\n",
    "                               decay_rate=decay_rate)\n",
    "optimizer = SGD(lr_schedule)\n",
    "\n",
    "model = deep_nn()\n",
    "model.name = \"best_\" + model.name + f\"_exp_decay_lr_{initial_learning_rate}_steps_{decay_step}_rate_{decay_rate}\"\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                            write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/best_ann.keras\", zipped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see with which data it had problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1000.,  10000., 100000.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(3, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4 , 0.62, 0.84])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.4, 0.84, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
