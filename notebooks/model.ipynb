{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IML - Model exploration\n",
    "\n",
    "Model has to be a Convolutional Neural Network, consuming as input a spectrogram and performing a\n",
    "classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.api.utils import image_dataset_from_directory\n",
    "import keras\n",
    "from keras.api.layers import Dense\n",
    "from keras.api import Model\n",
    "from keras.api.optimizers import SGD\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading dataset\n",
    "\n",
    "Use convenient function image_dataset_from_directory from keras. Handles train/validation split, \n",
    "shuffle, converting to grayscale etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63840 files belonging to 2 classes.\n",
      "Using 51072 files for training.\n",
      "Using 12768 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731506205.275213   16772 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), \"..\", \"data\", \"overlap_000_res_256x256_train_test_split\")\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "train_ds, valid_ds = image_dataset_from_directory(train_path, color_mode=\"grayscale\", seed=42,\n",
    "                                                   image_size=image_size, batch_size=batch_size,\n",
    "                                                   subset=\"both\", validation_split=0.2)\n",
    "\n",
    "train_ds = train_ds.map(lambda X, y: (tf.cast(X, tf.float32), tf.cast(y, tf.float32)))\n",
    "train_ds: tf.data.Dataset = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(lambda X, y: (tf.cast(X, tf.float32), tf.cast(y, tf.float32)))\n",
    "valid_ds: tf.data.Dataset = valid_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model\n",
    "\n",
    "Time for fun :)\n",
    "\n",
    "#### 1. Simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(os.getcwd(), \"..\", \"logs\")\n",
    "FIT_LOG_DIR = os.path.join(LOG_DIR, \"fit\")\n",
    "\n",
    "\n",
    "def train_model(train_ds, valid_ds, model_constructor, batch_size: int, epochs: int,\n",
    "                optimizer, loss, log_dir: str = FIT_LOG_DIR):\n",
    "    model = model_constructor()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds,batch_size=batch_size, epochs=epochs,\n",
    "                callbacks=[tensorboard_cb])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m16,777,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,729</span> (64.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,777,729\u001b[0m (64.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,729</span> (64.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,777,729\u001b[0m (64.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_nn() -> Model:\n",
    "    input_shape = (256, 256, 1)\n",
    "    inputs = keras.Input(input_shape, dtype=np.float32)\n",
    "    x = keras.layers.Rescaling(scale=1./255)(inputs)\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"SimpleNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = simple_nn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731257654.304787   12587 service.cc:148] XLA service 0x7f6418007680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731257654.305341   12587 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-10 17:54:14.377465: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731257654.563706   12587 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-10 17:54:15.732436: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-10 17:54:15.851370: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  17/1288\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6468 - loss: 1.0842 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731257656.585596   12587 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6970 - loss: 0.6123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 17:54:39.378682: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.6970 - loss: 0.6122 - val_accuracy: 0.7275 - val_loss: 0.5687\n",
      "Epoch 2/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.7182 - loss: 0.5269 - val_accuracy: 0.7825 - val_loss: 0.4108\n",
      "Epoch 3/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.7446 - loss: 0.4920 - val_accuracy: 0.8421 - val_loss: 0.3820\n",
      "Epoch 4/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.7844 - loss: 0.4373 - val_accuracy: 0.8189 - val_loss: 0.3498\n",
      "Epoch 5/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8063 - loss: 0.3995 - val_accuracy: 0.8592 - val_loss: 0.3706\n",
      "Epoch 6/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8297 - loss: 0.3672 - val_accuracy: 0.8484 - val_loss: 0.3082\n",
      "Epoch 7/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.8409 - loss: 0.3481 - val_accuracy: 0.8875 - val_loss: 0.2813\n",
      "Epoch 8/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8500 - loss: 0.3210 - val_accuracy: 0.8073 - val_loss: 0.3922\n",
      "Epoch 9/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8635 - loss: 0.3029 - val_accuracy: 0.9035 - val_loss: 0.2382\n",
      "Epoch 10/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8689 - loss: 0.2912 - val_accuracy: 0.8950 - val_loss: 0.2490\n",
      "Epoch 11/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.8794 - loss: 0.2703 - val_accuracy: 0.7172 - val_loss: 0.8695\n",
      "Epoch 12/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8838 - loss: 0.2675 - val_accuracy: 0.7213 - val_loss: 0.8602\n",
      "Epoch 13/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8858 - loss: 0.2588 - val_accuracy: 0.9159 - val_loss: 0.2066\n",
      "Epoch 14/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 21ms/step - accuracy: 0.8895 - loss: 0.2450 - val_accuracy: 0.8249 - val_loss: 0.3335\n",
      "Epoch 15/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8960 - loss: 0.2382 - val_accuracy: 0.8837 - val_loss: 0.2503\n",
      "Epoch 16/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8988 - loss: 0.2323 - val_accuracy: 0.9129 - val_loss: 0.1988\n",
      "Epoch 17/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9040 - loss: 0.2211 - val_accuracy: 0.9215 - val_loss: 0.1760\n",
      "Epoch 18/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9116 - loss: 0.2066 - val_accuracy: 0.9222 - val_loss: 0.1781\n",
      "Epoch 19/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9113 - loss: 0.2107 - val_accuracy: 0.9198 - val_loss: 0.1875\n",
      "Epoch 20/20\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9126 - loss: 0.2030 - val_accuracy: 0.9312 - val_loss: 0.1606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=SimpleNN, built=True>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_ds, valid_ds, simple_nn, batch_size, 20, optimizer=\"sgd\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those results are really surprising, we still haven't reached overfitting. Let's prolong our training\n",
    "to 50 epochs and see when model overfitts. \n",
    "\n",
    "Still no need for tweaking optimizer or loss metaparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731259377.689293   24084 service.cc:148] XLA service 0x7f4168006560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731259377.689395   24084 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-10 18:22:57.742256: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731259377.877004   24084 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-10 18:22:59.025333: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-10 18:22:59.044234: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  27/1288\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6698 - loss: 1.1676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731259379.804535   24084 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1283/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6973 - loss: 0.6218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-10 18:23:24.288150: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 21ms/step - accuracy: 0.6973 - loss: 0.6216 - val_accuracy: 0.7737 - val_loss: 0.5329\n",
      "Epoch 2/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.7194 - loss: 0.5302 - val_accuracy: 0.7112 - val_loss: 0.4726\n",
      "Epoch 3/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.4811 - val_accuracy: 0.8473 - val_loss: 0.3753\n",
      "Epoch 4/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.7881 - loss: 0.4333 - val_accuracy: 0.8114 - val_loss: 0.3590\n",
      "Epoch 5/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.8081 - loss: 0.3976 - val_accuracy: 0.8232 - val_loss: 0.3955\n",
      "Epoch 6/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8316 - loss: 0.3656 - val_accuracy: 0.8317 - val_loss: 0.3240\n",
      "Epoch 7/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8404 - loss: 0.3469 - val_accuracy: 0.8896 - val_loss: 0.2678\n",
      "Epoch 8/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8516 - loss: 0.3226 - val_accuracy: 0.8402 - val_loss: 0.3331\n",
      "Epoch 9/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.8644 - loss: 0.3012 - val_accuracy: 0.8987 - val_loss: 0.2584\n",
      "Epoch 10/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8708 - loss: 0.2901 - val_accuracy: 0.8943 - val_loss: 0.2417\n",
      "Epoch 11/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8793 - loss: 0.2719 - val_accuracy: 0.7546 - val_loss: 0.5981\n",
      "Epoch 12/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8871 - loss: 0.2606 - val_accuracy: 0.7697 - val_loss: 0.5478\n",
      "Epoch 13/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8875 - loss: 0.2557 - val_accuracy: 0.8902 - val_loss: 0.2391\n",
      "Epoch 14/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.8905 - loss: 0.2446 - val_accuracy: 0.8047 - val_loss: 0.3771\n",
      "Epoch 15/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.8991 - loss: 0.2311 - val_accuracy: 0.8601 - val_loss: 0.2966\n",
      "Epoch 16/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9021 - loss: 0.2280 - val_accuracy: 0.9162 - val_loss: 0.1919\n",
      "Epoch 17/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 20ms/step - accuracy: 0.9070 - loss: 0.2162 - val_accuracy: 0.9216 - val_loss: 0.1782\n",
      "Epoch 18/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9084 - loss: 0.2091 - val_accuracy: 0.9216 - val_loss: 0.1895\n",
      "Epoch 19/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9117 - loss: 0.2131 - val_accuracy: 0.9076 - val_loss: 0.2071\n",
      "Epoch 20/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9094 - loss: 0.2102 - val_accuracy: 0.9347 - val_loss: 0.1567\n",
      "Epoch 21/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9176 - loss: 0.1960 - val_accuracy: 0.9312 - val_loss: 0.1625\n",
      "Epoch 22/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9237 - loss: 0.1805 - val_accuracy: 0.7043 - val_loss: 1.6163\n",
      "Epoch 23/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9233 - loss: 0.1876 - val_accuracy: 0.8984 - val_loss: 0.2455\n",
      "Epoch 24/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9253 - loss: 0.1736 - val_accuracy: 0.9228 - val_loss: 0.1739\n",
      "Epoch 25/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9230 - loss: 0.1823 - val_accuracy: 0.9352 - val_loss: 0.1473\n",
      "Epoch 26/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9263 - loss: 0.1733 - val_accuracy: 0.8649 - val_loss: 0.3168\n",
      "Epoch 27/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9347 - loss: 0.1546 - val_accuracy: 0.9308 - val_loss: 0.1615\n",
      "Epoch 28/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9351 - loss: 0.1527 - val_accuracy: 0.9343 - val_loss: 0.1536\n",
      "Epoch 29/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9424 - loss: 0.1376 - val_accuracy: 0.8893 - val_loss: 0.2401\n",
      "Epoch 30/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9395 - loss: 0.1538 - val_accuracy: 0.9074 - val_loss: 0.2037\n",
      "Epoch 31/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9434 - loss: 0.1383 - val_accuracy: 0.9383 - val_loss: 0.1456\n",
      "Epoch 32/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.9446 - loss: 0.1420 - val_accuracy: 0.8885 - val_loss: 0.2314\n",
      "Epoch 33/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9436 - loss: 0.1317 - val_accuracy: 0.9385 - val_loss: 0.1474\n",
      "Epoch 34/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9455 - loss: 0.1322 - val_accuracy: 0.9028 - val_loss: 0.1935\n",
      "Epoch 35/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9473 - loss: 0.1277 - val_accuracy: 0.8984 - val_loss: 0.2386\n",
      "Epoch 36/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.9428 - loss: 0.1429 - val_accuracy: 0.9397 - val_loss: 0.1370\n",
      "Epoch 37/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9529 - loss: 0.1161 - val_accuracy: 0.8637 - val_loss: 0.2877\n",
      "Epoch 38/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9328 - loss: 0.1724 - val_accuracy: 0.8714 - val_loss: 0.3671\n",
      "Epoch 39/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9523 - loss: 0.1193 - val_accuracy: 0.8502 - val_loss: 0.4192\n",
      "Epoch 40/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.9502 - loss: 0.1256 - val_accuracy: 0.9509 - val_loss: 0.1149\n",
      "Epoch 41/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.9557 - loss: 0.1149 - val_accuracy: 0.9566 - val_loss: 0.1129\n",
      "Epoch 42/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 20ms/step - accuracy: 0.9470 - loss: 0.1319 - val_accuracy: 0.9071 - val_loss: 0.2067\n",
      "Epoch 43/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9513 - loss: 0.1197 - val_accuracy: 0.9384 - val_loss: 0.1461\n",
      "Epoch 44/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.9572 - loss: 0.1047 - val_accuracy: 0.9513 - val_loss: 0.1111\n",
      "Epoch 45/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.9504 - loss: 0.1314 - val_accuracy: 0.9493 - val_loss: 0.1144\n",
      "Epoch 46/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9595 - loss: 0.1059 - val_accuracy: 0.9498 - val_loss: 0.1163\n",
      "Epoch 47/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9512 - loss: 0.1247 - val_accuracy: 0.9512 - val_loss: 0.1109\n",
      "Epoch 48/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9511 - loss: 0.1250 - val_accuracy: 0.9396 - val_loss: 0.1410\n",
      "Epoch 49/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9626 - loss: 0.0931 - val_accuracy: 0.9189 - val_loss: 0.1727\n",
      "Epoch 50/50\n",
      "\u001b[1m1288/1288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 19ms/step - accuracy: 0.9612 - loss: 0.0959 - val_accuracy: 0.9320 - val_loss: 0.1723\n"
     ]
    }
   ],
   "source": [
    "model_50_epochs = train_model(train_ds, valid_ds, simple_nn, batch_size, 50,\n",
    "                              optimizer=\"sgd\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do **have to** take into account is that our classes are imbalanced - 30/70 ratio of \n",
    "class 1 to class 0. Let's try weighting loss for particular classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 14:57:09.749390: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: np.float64(0.7244666364049024), 1: np.float64(1.6137512639029323)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.concatenate([y for X, y in train_ds.as_numpy_iterator()])\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5963 - loss: 0.7021 - val_accuracy: 0.7650 - val_loss: 0.5280\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.6877 - loss: 0.5969 - val_accuracy: 0.7863 - val_loss: 0.4358\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7340 - loss: 0.5401 - val_accuracy: 0.6280 - val_loss: 0.6962\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7681 - loss: 0.4863 - val_accuracy: 0.8602 - val_loss: 0.3119\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7990 - loss: 0.4309 - val_accuracy: 0.4704 - val_loss: 1.4446\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8205 - loss: 0.3916 - val_accuracy: 0.8672 - val_loss: 0.2782\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8364 - loss: 0.3596 - val_accuracy: 0.8568 - val_loss: 0.2940\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8351 - loss: 0.3658 - val_accuracy: 0.8834 - val_loss: 0.2725\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8474 - loss: 0.3397 - val_accuracy: 0.9050 - val_loss: 0.2263\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8633 - loss: 0.2997 - val_accuracy: 0.8885 - val_loss: 0.2613\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8683 - loss: 0.3002 - val_accuracy: 0.8854 - val_loss: 0.2656\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8771 - loss: 0.2737 - val_accuracy: 0.9073 - val_loss: 0.2065\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8804 - loss: 0.2763 - val_accuracy: 0.9173 - val_loss: 0.2006\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8906 - loss: 0.2448 - val_accuracy: 0.7247 - val_loss: 0.5996\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8958 - loss: 0.2374 - val_accuracy: 0.9272 - val_loss: 0.1716\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.2377 - val_accuracy: 0.9270 - val_loss: 0.1695\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8955 - loss: 0.2444 - val_accuracy: 0.9255 - val_loss: 0.1684\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8924 - loss: 0.2518 - val_accuracy: 0.9167 - val_loss: 0.1890\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8905 - loss: 0.2614 - val_accuracy: 0.9219 - val_loss: 0.1784\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2199 - val_accuracy: 0.8420 - val_loss: 0.3935\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9136 - loss: 0.2034 - val_accuracy: 0.9274 - val_loss: 0.1716\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.1698 - val_accuracy: 0.9419 - val_loss: 0.1434\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.2151 - val_accuracy: 0.9263 - val_loss: 0.1839\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9306 - loss: 0.1587 - val_accuracy: 0.9344 - val_loss: 0.1533\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9360 - loss: 0.1467 - val_accuracy: 0.9435 - val_loss: 0.1305\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9327 - loss: 0.1644 - val_accuracy: 0.9474 - val_loss: 0.1236\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.1852 - val_accuracy: 0.9250 - val_loss: 0.1690\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9339 - loss: 0.1619 - val_accuracy: 0.9278 - val_loss: 0.1728\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9404 - loss: 0.1366 - val_accuracy: 0.9459 - val_loss: 0.1252\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9480 - loss: 0.1231 - val_accuracy: 0.9293 - val_loss: 0.1586\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9314 - loss: 0.1734 - val_accuracy: 0.9517 - val_loss: 0.1157\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9409 - loss: 0.1415 - val_accuracy: 0.9545 - val_loss: 0.1065\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9273 - loss: 0.1865 - val_accuracy: 0.9515 - val_loss: 0.1154\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9478 - loss: 0.1265 - val_accuracy: 0.9352 - val_loss: 0.1554\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.9483 - loss: 0.1225 - val_accuracy: 0.9478 - val_loss: 0.1191\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9525 - loss: 0.1116 - val_accuracy: 0.9456 - val_loss: 0.1288\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9409 - loss: 0.1475 - val_accuracy: 0.9527 - val_loss: 0.1087\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9386 - loss: 0.1593 - val_accuracy: 0.9461 - val_loss: 0.1277\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9483 - loss: 0.1318 - val_accuracy: 0.9591 - val_loss: 0.1034\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9431 - loss: 0.1447 - val_accuracy: 0.9497 - val_loss: 0.1114\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9520 - loss: 0.1164 - val_accuracy: 0.9590 - val_loss: 0.0985\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.9544 - loss: 0.1182 - val_accuracy: 0.9543 - val_loss: 0.1112\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9508 - loss: 0.1224 - val_accuracy: 0.9429 - val_loss: 0.1297\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9490 - loss: 0.1268 - val_accuracy: 0.9380 - val_loss: 0.1387\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9552 - loss: 0.1081 - val_accuracy: 0.9466 - val_loss: 0.1212\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.0988 - val_accuracy: 0.9532 - val_loss: 0.1152\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9479 - loss: 0.1259 - val_accuracy: 0.9380 - val_loss: 0.1460\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9552 - loss: 0.1082 - val_accuracy: 0.9418 - val_loss: 0.1367\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9523 - loss: 0.1208 - val_accuracy: 0.9595 - val_loss: 0.1006\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9579 - loss: 0.1106 - val_accuracy: 0.9538 - val_loss: 0.1154\n"
     ]
    }
   ],
   "source": [
    "model = simple_nn()\n",
    "model.name = \"SimpleNN_class_weights\"\n",
    "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model_log_dir = os.path.join(FIT_LOG_DIR, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                write_images=True)\n",
    "\n",
    "history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=50,\n",
    "                    class_weight=class_weights, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weights outtakes: in this very take, it has improved validation loss and minimally increased\n",
    "training loss. We can conclude that balancing the data improved generalization.\n",
    "\n",
    "### Optimizer parameters\n",
    "#### 1. Learning rate\n",
    "From the previous experiment we can tell that learning rate was too high - around 50th epoch we could\n",
    "have observed potential overfitting. The plan is to:\n",
    "\n",
    "1. Develop a few models with different constant learning rates\n",
    "2. Develope a few models with exponential decay\n",
    "3. Compare results and pick the best model\n",
    "\n",
    "***Constant learning rates:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731506321.504975   16989 service.cc:148] XLA service 0x7f05240065d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1731506321.508018   16989 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-13 14:58:41.538707: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1731506321.667850   16989 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-13 14:58:42.893160: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-13 14:58:43.081935: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_36_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  18/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4962 - loss: 1.7616 - weighted_accuracy: 0.4721  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731506324.127316   16989 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - accuracy: 0.5997 - loss: 0.7025 - weighted_accuracy: 0.5766 - val_accuracy: 0.4427 - val_loss: 0.7933 - val_weighted_accuracy: 0.4427\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6774 - loss: 0.6118 - weighted_accuracy: 0.6722 - val_accuracy: 0.7151 - val_loss: 0.6126 - val_weighted_accuracy: 0.7151\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7326 - loss: 0.5451 - weighted_accuracy: 0.7332 - val_accuracy: 0.8432 - val_loss: 0.4092 - val_weighted_accuracy: 0.8432\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7732 - loss: 0.4711 - weighted_accuracy: 0.7745 - val_accuracy: 0.8518 - val_loss: 0.3524 - val_weighted_accuracy: 0.8518\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7990 - loss: 0.4288 - weighted_accuracy: 0.8015 - val_accuracy: 0.8300 - val_loss: 0.3303 - val_weighted_accuracy: 0.8300\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8232 - loss: 0.3873 - weighted_accuracy: 0.8250 - val_accuracy: 0.8393 - val_loss: 0.3162 - val_weighted_accuracy: 0.8393\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 0.3592 - weighted_accuracy: 0.8373 - val_accuracy: 0.8994 - val_loss: 0.2510 - val_weighted_accuracy: 0.8994\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8484 - loss: 0.3414 - weighted_accuracy: 0.8505 - val_accuracy: 0.8172 - val_loss: 0.3829 - val_weighted_accuracy: 0.8172\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8602 - loss: 0.3152 - weighted_accuracy: 0.8623 - val_accuracy: 0.8781 - val_loss: 0.2963 - val_weighted_accuracy: 0.8781\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8533 - loss: 0.3269 - weighted_accuracy: 0.8558 - val_accuracy: 0.8875 - val_loss: 0.2427 - val_weighted_accuracy: 0.8875\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8645 - loss: 0.3040 - weighted_accuracy: 0.8664 - val_accuracy: 0.8747 - val_loss: 0.3176 - val_weighted_accuracy: 0.8747\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.8748 - loss: 0.2828 - weighted_accuracy: 0.8770 - val_accuracy: 0.8913 - val_loss: 0.2654 - val_weighted_accuracy: 0.8913\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8902 - loss: 0.2483 - weighted_accuracy: 0.8930 - val_accuracy: 0.7609 - val_loss: 0.5612 - val_weighted_accuracy: 0.7609\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8962 - loss: 0.2352 - weighted_accuracy: 0.8985 - val_accuracy: 0.9158 - val_loss: 0.1830 - val_weighted_accuracy: 0.9158\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9012 - loss: 0.2252 - weighted_accuracy: 0.9040 - val_accuracy: 0.8417 - val_loss: 0.4044 - val_weighted_accuracy: 0.8417\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9059 - loss: 0.2157 - weighted_accuracy: 0.9085 - val_accuracy: 0.9099 - val_loss: 0.2148 - val_weighted_accuracy: 0.9099\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9069 - loss: 0.2156 - weighted_accuracy: 0.9103 - val_accuracy: 0.9336 - val_loss: 0.1535 - val_weighted_accuracy: 0.9336\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9084 - loss: 0.2165 - weighted_accuracy: 0.9103 - val_accuracy: 0.7928 - val_loss: 0.4958 - val_weighted_accuracy: 0.7928\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9053 - loss: 0.2230 - weighted_accuracy: 0.9067 - val_accuracy: 0.9232 - val_loss: 0.1883 - val_weighted_accuracy: 0.9232\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9007 - loss: 0.2340 - weighted_accuracy: 0.9022 - val_accuracy: 0.9311 - val_loss: 0.1620 - val_weighted_accuracy: 0.9311\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9221 - loss: 0.1880 - weighted_accuracy: 0.9236 - val_accuracy: 0.9309 - val_loss: 0.1663 - val_weighted_accuracy: 0.9309\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9233 - loss: 0.1799 - weighted_accuracy: 0.9252 - val_accuracy: 0.7903 - val_loss: 0.5074 - val_weighted_accuracy: 0.7903\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9242 - loss: 0.1810 - weighted_accuracy: 0.9260 - val_accuracy: 0.9449 - val_loss: 0.1320 - val_weighted_accuracy: 0.9449\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9265 - loss: 0.1778 - weighted_accuracy: 0.9286 - val_accuracy: 0.9334 - val_loss: 0.1628 - val_weighted_accuracy: 0.9334\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9205 - loss: 0.1918 - weighted_accuracy: 0.9225 - val_accuracy: 0.9365 - val_loss: 0.1412 - val_weighted_accuracy: 0.9365\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.9187 - loss: 0.1898 - weighted_accuracy: 0.9205 - val_accuracy: 0.9418 - val_loss: 0.1296 - val_weighted_accuracy: 0.9418\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9261 - loss: 0.1748 - weighted_accuracy: 0.9273 - val_accuracy: 0.9268 - val_loss: 0.1562 - val_weighted_accuracy: 0.9268\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9259 - loss: 0.1770 - weighted_accuracy: 0.9272 - val_accuracy: 0.9387 - val_loss: 0.1388 - val_weighted_accuracy: 0.9387\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9369 - loss: 0.1523 - weighted_accuracy: 0.9380 - val_accuracy: 0.9292 - val_loss: 0.1646 - val_weighted_accuracy: 0.9292\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9457 - loss: 0.1301 - weighted_accuracy: 0.9469 - val_accuracy: 0.9542 - val_loss: 0.1127 - val_weighted_accuracy: 0.9542\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9414 - loss: 0.1415 - weighted_accuracy: 0.9426 - val_accuracy: 0.9056 - val_loss: 0.2114 - val_weighted_accuracy: 0.9056\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.9197 - loss: 0.1949 - weighted_accuracy: 0.9217 - val_accuracy: 0.9521 - val_loss: 0.1156 - val_weighted_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9331 - loss: 0.1600 - weighted_accuracy: 0.9353 - val_accuracy: 0.9419 - val_loss: 0.1487 - val_weighted_accuracy: 0.9419\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9225 - loss: 0.1965 - weighted_accuracy: 0.9229 - val_accuracy: 0.9409 - val_loss: 0.1366 - val_weighted_accuracy: 0.9409\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9341 - loss: 0.1630 - weighted_accuracy: 0.9354 - val_accuracy: 0.7690 - val_loss: 0.7127 - val_weighted_accuracy: 0.7690\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.2023 - weighted_accuracy: 0.9211 - val_accuracy: 0.9264 - val_loss: 0.1642 - val_weighted_accuracy: 0.9264\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9294 - loss: 0.1639 - weighted_accuracy: 0.9306 - val_accuracy: 0.9466 - val_loss: 0.1227 - val_weighted_accuracy: 0.9466\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9276 - loss: 0.1784 - weighted_accuracy: 0.9284 - val_accuracy: 0.9250 - val_loss: 0.1639 - val_weighted_accuracy: 0.9250\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9445 - loss: 0.1323 - weighted_accuracy: 0.9448 - val_accuracy: 0.9512 - val_loss: 0.1142 - val_weighted_accuracy: 0.9512\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9233 - loss: 0.1893 - weighted_accuracy: 0.9227 - val_accuracy: 0.9439 - val_loss: 0.1414 - val_weighted_accuracy: 0.9439\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9253 - loss: 0.1930 - weighted_accuracy: 0.9253 - val_accuracy: 0.9484 - val_loss: 0.1156 - val_weighted_accuracy: 0.9484\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9500 - loss: 0.1201 - weighted_accuracy: 0.9518 - val_accuracy: 0.9062 - val_loss: 0.2125 - val_weighted_accuracy: 0.9062\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9513 - loss: 0.1168 - weighted_accuracy: 0.9523 - val_accuracy: 0.9510 - val_loss: 0.1141 - val_weighted_accuracy: 0.9510\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9536 - loss: 0.1173 - weighted_accuracy: 0.9539 - val_accuracy: 0.9526 - val_loss: 0.1175 - val_weighted_accuracy: 0.9526\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9330 - loss: 0.1677 - weighted_accuracy: 0.9336 - val_accuracy: 0.9497 - val_loss: 0.1175 - val_weighted_accuracy: 0.9497\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.9220 - loss: 0.2019 - weighted_accuracy: 0.9212 - val_accuracy: 0.9543 - val_loss: 0.1099 - val_weighted_accuracy: 0.9543\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9398 - loss: 0.1507 - weighted_accuracy: 0.9410 - val_accuracy: 0.9509 - val_loss: 0.1316 - val_weighted_accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9520 - loss: 0.1165 - weighted_accuracy: 0.9539 - val_accuracy: 0.9499 - val_loss: 0.1192 - val_weighted_accuracy: 0.9499\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.1426 - weighted_accuracy: 0.9445 - val_accuracy: 0.9261 - val_loss: 0.1507 - val_weighted_accuracy: 0.9261\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9545 - loss: 0.1117 - weighted_accuracy: 0.9551 - val_accuracy: 0.9500 - val_loss: 0.1151 - val_weighted_accuracy: 0.9500\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.4853 - loss: 0.9023 - weighted_accuracy: 0.5090 - val_accuracy: 0.6935 - val_loss: 0.6875 - val_weighted_accuracy: 0.6935\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6332 - loss: 0.6909 - weighted_accuracy: 0.5259 - val_accuracy: 0.3083 - val_loss: 0.6947 - val_weighted_accuracy: 0.3083\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6145 - loss: 0.6863 - weighted_accuracy: 0.5468 - val_accuracy: 0.6812 - val_loss: 0.6925 - val_weighted_accuracy: 0.6812\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6123 - loss: 0.6891 - weighted_accuracy: 0.5313 - val_accuracy: 0.6934 - val_loss: 0.6795 - val_weighted_accuracy: 0.6934\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6713 - loss: 0.6840 - weighted_accuracy: 0.5381 - val_accuracy: 0.6931 - val_loss: 0.6889 - val_weighted_accuracy: 0.6931\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6423 - loss: 0.6909 - weighted_accuracy: 0.5053 - val_accuracy: 0.6979 - val_loss: 0.6784 - val_weighted_accuracy: 0.6979\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6331 - loss: 0.6912 - weighted_accuracy: 0.5181 - val_accuracy: 0.3096 - val_loss: 0.6946 - val_weighted_accuracy: 0.3096\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5458 - loss: 0.6888 - weighted_accuracy: 0.5130 - val_accuracy: 0.3082 - val_loss: 0.6984 - val_weighted_accuracy: 0.3082\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5318 - loss: 0.6918 - weighted_accuracy: 0.4977 - val_accuracy: 0.6812 - val_loss: 0.6180 - val_weighted_accuracy: 0.6812\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4504 - loss: 0.6865 - weighted_accuracy: 0.5198 - val_accuracy: 0.3068 - val_loss: 0.6948 - val_weighted_accuracy: 0.3068\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5578 - loss: 0.6916 - weighted_accuracy: 0.4998 - val_accuracy: 0.5381 - val_loss: 0.7267 - val_weighted_accuracy: 0.5381\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6469 - loss: 0.6860 - weighted_accuracy: 0.5328 - val_accuracy: 0.3067 - val_loss: 0.6956 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5872 - loss: 0.6907 - weighted_accuracy: 0.4971 - val_accuracy: 0.3177 - val_loss: 0.7025 - val_weighted_accuracy: 0.3177\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4596 - loss: 0.6911 - weighted_accuracy: 0.5032 - val_accuracy: 0.3076 - val_loss: 0.6933 - val_weighted_accuracy: 0.3076\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5887 - loss: 0.6918 - weighted_accuracy: 0.4986 - val_accuracy: 0.3076 - val_loss: 0.6953 - val_weighted_accuracy: 0.3076\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5574 - loss: 0.6916 - weighted_accuracy: 0.4976 - val_accuracy: 0.7134 - val_loss: 0.6745 - val_weighted_accuracy: 0.7134\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6677 - loss: 0.6847 - weighted_accuracy: 0.5417 - val_accuracy: 0.4691 - val_loss: 0.8756 - val_weighted_accuracy: 0.4691\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6530 - loss: 0.6877 - weighted_accuracy: 0.5236 - val_accuracy: 0.6934 - val_loss: 0.6784 - val_weighted_accuracy: 0.6934\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.6625 - loss: 0.6813 - weighted_accuracy: 0.5439 - val_accuracy: 0.3079 - val_loss: 0.6952 - val_weighted_accuracy: 0.3079\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5803 - loss: 0.6889 - weighted_accuracy: 0.5083 - val_accuracy: 0.3078 - val_loss: 0.6946 - val_weighted_accuracy: 0.3078\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5477 - loss: 0.6918 - weighted_accuracy: 0.5013 - val_accuracy: 0.3079 - val_loss: 0.6952 - val_weighted_accuracy: 0.3079\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5466 - loss: 0.6918 - weighted_accuracy: 0.4981 - val_accuracy: 0.3079 - val_loss: 0.6946 - val_weighted_accuracy: 0.3079\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5978 - loss: 0.6914 - weighted_accuracy: 0.5110 - val_accuracy: 0.3079 - val_loss: 0.6950 - val_weighted_accuracy: 0.3079\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5564 - loss: 0.6918 - weighted_accuracy: 0.4947 - val_accuracy: 0.6920 - val_loss: 0.6918 - val_weighted_accuracy: 0.6920\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6201 - loss: 0.6916 - weighted_accuracy: 0.5022 - val_accuracy: 0.3080 - val_loss: 0.6956 - val_weighted_accuracy: 0.3080\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5632 - loss: 0.6904 - weighted_accuracy: 0.5001 - val_accuracy: 0.6933 - val_loss: 0.6801 - val_weighted_accuracy: 0.6933\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6435 - loss: 0.6914 - weighted_accuracy: 0.5035 - val_accuracy: 0.7517 - val_loss: 0.6632 - val_weighted_accuracy: 0.7517\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6673 - loss: 0.6743 - weighted_accuracy: 0.5631 - val_accuracy: 0.6923 - val_loss: 0.6888 - val_weighted_accuracy: 0.6923\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6571 - loss: 0.6904 - weighted_accuracy: 0.5085 - val_accuracy: 0.7574 - val_loss: 0.6753 - val_weighted_accuracy: 0.7574\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6668 - loss: 0.6748 - weighted_accuracy: 0.5635 - val_accuracy: 0.3086 - val_loss: 0.6950 - val_weighted_accuracy: 0.3086\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5463 - loss: 0.6916 - weighted_accuracy: 0.4965 - val_accuracy: 0.3087 - val_loss: 0.6954 - val_weighted_accuracy: 0.3087\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5344 - loss: 0.6917 - weighted_accuracy: 0.5005 - val_accuracy: 0.3090 - val_loss: 0.6954 - val_weighted_accuracy: 0.3090\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5472 - loss: 0.6916 - weighted_accuracy: 0.4982 - val_accuracy: 0.3092 - val_loss: 0.6952 - val_weighted_accuracy: 0.3092\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5354 - loss: 0.6914 - weighted_accuracy: 0.4966 - val_accuracy: 0.3090 - val_loss: 0.6954 - val_weighted_accuracy: 0.3090\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5437 - loss: 0.6914 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5446 - loss: 0.6915 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5471 - loss: 0.6919 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6951 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5579 - loss: 0.6918 - weighted_accuracy: 0.4973 - val_accuracy: 0.3067 - val_loss: 0.6956 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5394 - loss: 0.6919 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5573 - loss: 0.6917 - weighted_accuracy: 0.4960 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5426 - loss: 0.6917 - weighted_accuracy: 0.4965 - val_accuracy: 0.3067 - val_loss: 0.6952 - val_weighted_accuracy: 0.3067\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5537 - loss: 0.6918 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 0.6917 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5722 - loss: 0.6919 - weighted_accuracy: 0.4983 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5580 - loss: 0.6916 - weighted_accuracy: 0.4990 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5503 - loss: 0.6919 - weighted_accuracy: 0.4949 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5459 - loss: 0.6917 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.6952 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5572 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5600 - loss: 0.6917 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5352 - loss: 0.6917 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.6950 - val_weighted_accuracy: 0.3067\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5197 - loss: 1.1853 - weighted_accuracy: 0.4959 - val_accuracy: 0.3067 - val_loss: 0.6936 - val_weighted_accuracy: 0.3067\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5595 - loss: 0.6920 - weighted_accuracy: 0.4968 - val_accuracy: 0.6933 - val_loss: 0.6919 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5578 - loss: 0.6920 - weighted_accuracy: 0.4985 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5386 - loss: 0.6920 - weighted_accuracy: 0.4943 - val_accuracy: 0.3067 - val_loss: 0.6968 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5393 - loss: 0.6920 - weighted_accuracy: 0.4946 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5447 - loss: 0.6919 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6920 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5683 - loss: 0.6919 - weighted_accuracy: 0.4964 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5561 - loss: 0.6920 - weighted_accuracy: 0.4951 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5570 - loss: 0.6919 - weighted_accuracy: 0.4969 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5400 - loss: 0.6922 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5536 - loss: 0.6922 - weighted_accuracy: 0.4932 - val_accuracy: 0.3067 - val_loss: 0.6963 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5353 - loss: 0.6921 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5241 - loss: 0.6922 - weighted_accuracy: 0.4950 - val_accuracy: 0.6932 - val_loss: 0.6924 - val_weighted_accuracy: 0.6932\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5555 - loss: 0.6921 - weighted_accuracy: 0.4974 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5703 - loss: 0.6932 - weighted_accuracy: 0.4965 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 74ms/step - accuracy: 0.5486 - loss: 0.6921 - weighted_accuracy: 0.4934 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5383 - loss: 0.6922 - weighted_accuracy: 0.4878 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5604 - loss: 0.6920 - weighted_accuracy: 0.4972 - val_accuracy: 0.6932 - val_loss: 0.6931 - val_weighted_accuracy: 0.6932\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5480 - loss: 0.6921 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5354 - loss: 0.6918 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5510 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5480 - loss: 0.6918 - weighted_accuracy: 0.4950 - val_accuracy: 0.3067 - val_loss: 0.6947 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5544 - loss: 0.6920 - weighted_accuracy: 0.4959 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5502 - loss: 0.6921 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6963 - val_weighted_accuracy: 0.3067\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5428 - loss: 0.6919 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5497 - loss: 0.6921 - weighted_accuracy: 0.4972 - val_accuracy: 0.3067 - val_loss: 0.6945 - val_weighted_accuracy: 0.3067\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5365 - loss: 0.6922 - weighted_accuracy: 0.4923 - val_accuracy: 0.3067 - val_loss: 0.6941 - val_weighted_accuracy: 0.3067\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.6921 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.6959 - val_weighted_accuracy: 0.3067\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5369 - loss: 0.6920 - weighted_accuracy: 0.4944 - val_accuracy: 0.3067 - val_loss: 0.6939 - val_weighted_accuracy: 0.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5568 - loss: 0.6918 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5518 - loss: 0.6919 - weighted_accuracy: 0.4940 - val_accuracy: 0.3067 - val_loss: 0.6934 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5542 - loss: 0.6919 - weighted_accuracy: 0.4943 - val_accuracy: 0.6933 - val_loss: 0.6907 - val_weighted_accuracy: 0.6933\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5679 - loss: 0.6920 - weighted_accuracy: 0.4972 - val_accuracy: 0.3067 - val_loss: 0.6970 - val_weighted_accuracy: 0.3067\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5324 - loss: 0.6920 - weighted_accuracy: 0.4925 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5520 - loss: 0.6918 - weighted_accuracy: 0.4951 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5515 - loss: 0.6918 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5471 - loss: 0.6919 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.5485 - loss: 0.6920 - weighted_accuracy: 0.4925 - val_accuracy: 0.3067 - val_loss: 0.6936 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5461 - loss: 0.6919 - weighted_accuracy: 0.4977 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5405 - loss: 0.6920 - weighted_accuracy: 0.4957 - val_accuracy: 0.3067 - val_loss: 0.6953 - val_weighted_accuracy: 0.3067\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5326 - loss: 0.6922 - weighted_accuracy: 0.4956 - val_accuracy: 0.6933 - val_loss: 0.6917 - val_weighted_accuracy: 0.6933\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5496 - loss: 0.6922 - weighted_accuracy: 0.4920 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5361 - loss: 0.6923 - weighted_accuracy: 0.4944 - val_accuracy: 0.6933 - val_loss: 0.6925 - val_weighted_accuracy: 0.6933\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5586 - loss: 0.6920 - weighted_accuracy: 0.4945 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5576 - loss: 0.6920 - weighted_accuracy: 0.4915 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5335 - loss: 0.6923 - weighted_accuracy: 0.4958 - val_accuracy: 0.3067 - val_loss: 0.6955 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5401 - loss: 0.6920 - weighted_accuracy: 0.4939 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5435 - loss: 0.6922 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6943 - val_weighted_accuracy: 0.3067\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5535 - loss: 0.6919 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6946 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5442 - loss: 0.6919 - weighted_accuracy: 0.4909 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.5030 - loss: 20.0770 - weighted_accuracy: 0.4940 - val_accuracy: 0.6933 - val_loss: 0.6898 - val_weighted_accuracy: 0.6933\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5356 - loss: 0.6924 - weighted_accuracy: 0.4995 - val_accuracy: 0.6933 - val_loss: 0.6846 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5302 - loss: 0.6928 - weighted_accuracy: 0.4952 - val_accuracy: 0.3067 - val_loss: 0.7024 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5108 - loss: 0.6925 - weighted_accuracy: 0.4890 - val_accuracy: 0.3067 - val_loss: 0.6942 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5213 - loss: 0.6924 - weighted_accuracy: 0.4946 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5154 - loss: 0.6924 - weighted_accuracy: 0.4970 - val_accuracy: 0.6933 - val_loss: 0.6816 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5318 - loss: 0.6929 - weighted_accuracy: 0.4933 - val_accuracy: 0.6933 - val_loss: 0.6813 - val_weighted_accuracy: 0.6933\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5187 - loss: 0.6926 - weighted_accuracy: 0.4957 - val_accuracy: 0.6934 - val_loss: 0.6914 - val_weighted_accuracy: 0.6934\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6928 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5266 - loss: 0.6923 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5217 - loss: 0.6922 - weighted_accuracy: 0.4964 - val_accuracy: 0.3067 - val_loss: 0.7020 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5092 - loss: 0.6926 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7006 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5126 - loss: 0.6926 - weighted_accuracy: 0.4933 - val_accuracy: 0.3067 - val_loss: 0.7058 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 0.6926 - weighted_accuracy: 0.4929 - val_accuracy: 0.3067 - val_loss: 0.6979 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5146 - loss: 0.6927 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5148 - loss: 0.6927 - weighted_accuracy: 0.4940 - val_accuracy: 0.3067 - val_loss: 0.7069 - val_weighted_accuracy: 0.3067\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5104 - loss: 0.6926 - weighted_accuracy: 0.4924 - val_accuracy: 0.3067 - val_loss: 0.7039 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.6925 - weighted_accuracy: 0.4922 - val_accuracy: 0.3067 - val_loss: 0.6964 - val_weighted_accuracy: 0.3067\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5150 - loss: 0.6927 - weighted_accuracy: 0.4944 - val_accuracy: 0.6933 - val_loss: 0.6905 - val_weighted_accuracy: 0.6933\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5285 - loss: 0.6923 - weighted_accuracy: 0.4999 - val_accuracy: 0.3067 - val_loss: 0.7092 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5169 - loss: 0.6924 - weighted_accuracy: 0.4914 - val_accuracy: 0.3067 - val_loss: 0.6968 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5124 - loss: 0.6926 - weighted_accuracy: 0.4910 - val_accuracy: 0.3067 - val_loss: 0.6970 - val_weighted_accuracy: 0.3067\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5312 - loss: 0.6923 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.7002 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5153 - loss: 0.6925 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6959 - val_weighted_accuracy: 0.3067\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5162 - loss: 0.6927 - weighted_accuracy: 0.4948 - val_accuracy: 0.3067 - val_loss: 0.6990 - val_weighted_accuracy: 0.3067\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4979 - loss: 0.6929 - weighted_accuracy: 0.4944 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5237 - loss: 0.6924 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.7002 - val_weighted_accuracy: 0.3067\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5256 - loss: 0.6926 - weighted_accuracy: 0.4993 - val_accuracy: 0.3067 - val_loss: 0.6972 - val_weighted_accuracy: 0.3067\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5130 - loss: 0.6926 - weighted_accuracy: 0.4942 - val_accuracy: 0.6933 - val_loss: 0.6901 - val_weighted_accuracy: 0.6933\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.4972 - loss: 0.6926 - weighted_accuracy: 0.4878 - val_accuracy: 0.6933 - val_loss: 0.6903 - val_weighted_accuracy: 0.6933\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6926 - weighted_accuracy: 0.4979 - val_accuracy: 0.3067 - val_loss: 0.6944 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5150 - loss: 0.6925 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6891 - val_weighted_accuracy: 0.6933\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5202 - loss: 0.6926 - weighted_accuracy: 0.4931 - val_accuracy: 0.6934 - val_loss: 0.6916 - val_weighted_accuracy: 0.6934\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5129 - loss: 0.6928 - weighted_accuracy: 0.4920 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5194 - loss: 0.6927 - weighted_accuracy: 0.4912 - val_accuracy: 0.6934 - val_loss: 0.6916 - val_weighted_accuracy: 0.6934\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5235 - loss: 0.6923 - weighted_accuracy: 0.4958 - val_accuracy: 0.6933 - val_loss: 0.6856 - val_weighted_accuracy: 0.6933\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6926 - weighted_accuracy: 0.4970 - val_accuracy: 0.3067 - val_loss: 0.6958 - val_weighted_accuracy: 0.3067\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5111 - loss: 0.6930 - weighted_accuracy: 0.4894 - val_accuracy: 0.6934 - val_loss: 0.6929 - val_weighted_accuracy: 0.6934\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5275 - loss: 0.6928 - weighted_accuracy: 0.4958 - val_accuracy: 0.6933 - val_loss: 0.6855 - val_weighted_accuracy: 0.6933\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5209 - loss: 0.6928 - weighted_accuracy: 0.4961 - val_accuracy: 0.6933 - val_loss: 0.6815 - val_weighted_accuracy: 0.6933\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5275 - loss: 0.6926 - weighted_accuracy: 0.4966 - val_accuracy: 0.3067 - val_loss: 0.7006 - val_weighted_accuracy: 0.3067\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5109 - loss: 0.6927 - weighted_accuracy: 0.4902 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5128 - loss: 0.6927 - weighted_accuracy: 0.4941 - val_accuracy: 0.6934 - val_loss: 0.6922 - val_weighted_accuracy: 0.6934\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5210 - loss: 0.6928 - weighted_accuracy: 0.4902 - val_accuracy: 0.3067 - val_loss: 0.7058 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5100 - loss: 0.6930 - weighted_accuracy: 0.4925 - val_accuracy: 0.6933 - val_loss: 0.6856 - val_weighted_accuracy: 0.6933\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5275 - loss: 0.6924 - weighted_accuracy: 0.4941 - val_accuracy: 0.3067 - val_loss: 0.6997 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5178 - loss: 0.6924 - weighted_accuracy: 0.4956 - val_accuracy: 0.3067 - val_loss: 0.7059 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5061 - loss: 0.6928 - weighted_accuracy: 0.4894 - val_accuracy: 0.6933 - val_loss: 0.6851 - val_weighted_accuracy: 0.6933\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5386 - loss: 0.6926 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6880 - val_weighted_accuracy: 0.6933\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5318 - loss: 0.6925 - weighted_accuracy: 0.4967 - val_accuracy: 0.6934 - val_loss: 0.6923 - val_weighted_accuracy: 0.6934\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.4950 - loss: 524.0928 - weighted_accuracy: 0.4980 - val_accuracy: 0.6933 - val_loss: 0.6903 - val_weighted_accuracy: 0.6933\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5110 - loss: 0.6945 - weighted_accuracy: 0.4973 - val_accuracy: 0.6933 - val_loss: 0.6830 - val_weighted_accuracy: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.6946 - weighted_accuracy: 0.4994 - val_accuracy: 0.3067 - val_loss: 0.7095 - val_weighted_accuracy: 0.3067\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5028 - loss: 0.6946 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.7033 - val_weighted_accuracy: 0.3067\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5058 - loss: 0.6947 - weighted_accuracy: 0.4933 - val_accuracy: 0.3067 - val_loss: 0.7047 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5091 - loss: 0.6944 - weighted_accuracy: 0.4975 - val_accuracy: 0.6933 - val_loss: 0.6568 - val_weighted_accuracy: 0.6933\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5194 - loss: 0.6948 - weighted_accuracy: 0.4987 - val_accuracy: 0.3067 - val_loss: 0.7029 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5092 - loss: 0.6945 - weighted_accuracy: 0.4941 - val_accuracy: 0.3067 - val_loss: 0.7137 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 251ms/step - accuracy: 0.5085 - loss: 0.6944 - weighted_accuracy: 0.4980 - val_accuracy: 0.6933 - val_loss: 0.6748 - val_weighted_accuracy: 0.6933\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.5033 - loss: 0.6943 - weighted_accuracy: 0.4960 - val_accuracy: 0.6933 - val_loss: 0.6779 - val_weighted_accuracy: 0.6933\n",
      "Epoch 11/50\n",
      "\u001b[1m  13/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.7003 - loss: 0.6639 - weighted_accuracy: 0.5403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:19:40.292700: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 16:19:40.293671: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5113 - loss: 0.6947 - weighted_accuracy: 0.4970 - val_accuracy: 0.6933 - val_loss: 0.6775 - val_weighted_accuracy: 0.6933\n",
      "Epoch 12/50\n",
      "\u001b[1m  16/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.4860 - loss: 0.7087 - weighted_accuracy: 0.4417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 16:20:01.269720: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 16:20:01.270064: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.5050 - loss: 0.6950 - weighted_accuracy: 0.4913 - val_accuracy: 0.6933 - val_loss: 0.6796 - val_weighted_accuracy: 0.6933\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5179 - loss: 0.6947 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7107 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5096 - loss: 0.6945 - weighted_accuracy: 0.4984 - val_accuracy: 0.6933 - val_loss: 0.6855 - val_weighted_accuracy: 0.6933\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5061 - loss: 0.6946 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6984 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.4976 - loss: 0.6946 - weighted_accuracy: 0.4938 - val_accuracy: 0.6933 - val_loss: 0.6508 - val_weighted_accuracy: 0.6933\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5144 - loss: 0.6946 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.7163 - val_weighted_accuracy: 0.3067\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5035 - loss: 0.6946 - weighted_accuracy: 0.4964 - val_accuracy: 0.6933 - val_loss: 0.6832 - val_weighted_accuracy: 0.6933\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.5001 - loss: 0.6950 - weighted_accuracy: 0.4971 - val_accuracy: 0.3067 - val_loss: 0.7197 - val_weighted_accuracy: 0.3067\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5165 - loss: 0.6944 - weighted_accuracy: 0.4991 - val_accuracy: 0.3067 - val_loss: 0.6948 - val_weighted_accuracy: 0.3067\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5081 - loss: 0.6948 - weighted_accuracy: 0.4955 - val_accuracy: 0.3067 - val_loss: 0.7012 - val_weighted_accuracy: 0.3067\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5066 - loss: 0.6946 - weighted_accuracy: 0.4949 - val_accuracy: 0.6933 - val_loss: 0.6521 - val_weighted_accuracy: 0.6933\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5208 - loss: 0.6948 - weighted_accuracy: 0.4969 - val_accuracy: 0.3067 - val_loss: 0.7124 - val_weighted_accuracy: 0.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5030 - loss: 0.6950 - weighted_accuracy: 0.4925 - val_accuracy: 0.6933 - val_loss: 0.6900 - val_weighted_accuracy: 0.6933\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5032 - loss: 0.6947 - weighted_accuracy: 0.4901 - val_accuracy: 0.6933 - val_loss: 0.6675 - val_weighted_accuracy: 0.6933\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5098 - loss: 0.6949 - weighted_accuracy: 0.4965 - val_accuracy: 0.6933 - val_loss: 0.6679 - val_weighted_accuracy: 0.6933\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5015 - loss: 0.6949 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6565 - val_weighted_accuracy: 0.6933\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5138 - loss: 0.6944 - weighted_accuracy: 0.4978 - val_accuracy: 0.6933 - val_loss: 0.6815 - val_weighted_accuracy: 0.6933\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5023 - loss: 0.6952 - weighted_accuracy: 0.4911 - val_accuracy: 0.3067 - val_loss: 0.7060 - val_weighted_accuracy: 0.3067\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5129 - loss: 0.6945 - weighted_accuracy: 0.4980 - val_accuracy: 0.3067 - val_loss: 0.7233 - val_weighted_accuracy: 0.3067\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5056 - loss: 0.6949 - weighted_accuracy: 0.4993 - val_accuracy: 0.3067 - val_loss: 0.7283 - val_weighted_accuracy: 0.3067\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4980 - loss: 0.6949 - weighted_accuracy: 0.4922 - val_accuracy: 0.3067 - val_loss: 0.7027 - val_weighted_accuracy: 0.3067\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5066 - loss: 0.6949 - weighted_accuracy: 0.4937 - val_accuracy: 0.6933 - val_loss: 0.6675 - val_weighted_accuracy: 0.6933\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5066 - loss: 0.6944 - weighted_accuracy: 0.4945 - val_accuracy: 0.3067 - val_loss: 0.6933 - val_weighted_accuracy: 0.3067\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4993 - loss: 0.6947 - weighted_accuracy: 0.4895 - val_accuracy: 0.6933 - val_loss: 0.6669 - val_weighted_accuracy: 0.6933\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5105 - loss: 0.6941 - weighted_accuracy: 0.4967 - val_accuracy: 0.6933 - val_loss: 0.6800 - val_weighted_accuracy: 0.6933\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5100 - loss: 0.6945 - weighted_accuracy: 0.4981 - val_accuracy: 0.6933 - val_loss: 0.6764 - val_weighted_accuracy: 0.6933\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5130 - loss: 0.6944 - weighted_accuracy: 0.4953 - val_accuracy: 0.3067 - val_loss: 0.6957 - val_weighted_accuracy: 0.3067\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5062 - loss: 0.6949 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6949 - val_weighted_accuracy: 0.3067\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5152 - loss: 0.6944 - weighted_accuracy: 0.4990 - val_accuracy: 0.6933 - val_loss: 0.6568 - val_weighted_accuracy: 0.6933\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5049 - loss: 0.6946 - weighted_accuracy: 0.4920 - val_accuracy: 0.6933 - val_loss: 0.6894 - val_weighted_accuracy: 0.6933\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5148 - loss: 0.6944 - weighted_accuracy: 0.4949 - val_accuracy: 0.6933 - val_loss: 0.6537 - val_weighted_accuracy: 0.6933\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5126 - loss: 0.6946 - weighted_accuracy: 0.4965 - val_accuracy: 0.6933 - val_loss: 0.6728 - val_weighted_accuracy: 0.6933\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5093 - loss: 0.6946 - weighted_accuracy: 0.4917 - val_accuracy: 0.3067 - val_loss: 0.7185 - val_weighted_accuracy: 0.3067\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5084 - loss: 0.6944 - weighted_accuracy: 0.4974 - val_accuracy: 0.3067 - val_loss: 0.7016 - val_weighted_accuracy: 0.3067\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5083 - loss: 0.6945 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6995 - val_weighted_accuracy: 0.3067\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5069 - loss: 0.6946 - weighted_accuracy: 0.4983 - val_accuracy: 0.3067 - val_loss: 0.6938 - val_weighted_accuracy: 0.3067\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5035 - loss: 0.6950 - weighted_accuracy: 0.4922 - val_accuracy: 0.6933 - val_loss: 0.6848 - val_weighted_accuracy: 0.6933\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5083 - loss: 0.6947 - weighted_accuracy: 0.4963 - val_accuracy: 0.3067 - val_loss: 0.6932 - val_weighted_accuracy: 0.3067\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5059 - loss: 0.6948 - weighted_accuracy: 0.4952 - val_accuracy: 0.6933 - val_loss: 0.6777 - val_weighted_accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-2, 0, 5)\n",
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model = simple_nn()\n",
    "    model.name = f\"simplenn_lr_{learning_rate}\"\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=50,\n",
    "                        class_weight=class_weights, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs, all learning rates above 0.033 do not converge, let's look at smaller \n",
    "learning rates. \n",
    "\n",
    "To shorten the fitting time, let's drop from 50 epochs to 30 and implement early \n",
    "stopping with parience of 8 epochs, starting after 8 epochs and restoring the best set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.5726 - loss: 0.6955 - weighted_accuracy: 0.5206 - val_accuracy: 0.6113 - val_loss: 0.6648 - val_weighted_accuracy: 0.6113\n",
      "Epoch 2/30\n",
      "\u001b[1m   3/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 53ms/step - accuracy: 0.6042 - loss: 0.6767 - weighted_accuracy: 0.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 17:39:00.415464: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6137 - loss: 0.6718 - weighted_accuracy: 0.5889 - val_accuracy: 0.6205 - val_loss: 0.6572 - val_weighted_accuracy: 0.6205\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.6289 - loss: 0.6603 - weighted_accuracy: 0.6124 - val_accuracy: 0.6378 - val_loss: 0.6469 - val_weighted_accuracy: 0.6378\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.6418 - loss: 0.6519 - weighted_accuracy: 0.6284 - val_accuracy: 0.6484 - val_loss: 0.6395 - val_weighted_accuracy: 0.6484\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.6519 - loss: 0.6445 - weighted_accuracy: 0.6410 - val_accuracy: 0.6523 - val_loss: 0.6360 - val_weighted_accuracy: 0.6523\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6633 - loss: 0.6381 - weighted_accuracy: 0.6541 - val_accuracy: 0.6660 - val_loss: 0.6269 - val_weighted_accuracy: 0.6660\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6715 - loss: 0.6315 - weighted_accuracy: 0.6639 - val_accuracy: 0.6786 - val_loss: 0.6182 - val_weighted_accuracy: 0.6786\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6804 - loss: 0.6256 - weighted_accuracy: 0.6733 - val_accuracy: 0.6814 - val_loss: 0.6162 - val_weighted_accuracy: 0.6814\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6890 - loss: 0.6199 - weighted_accuracy: 0.6834 - val_accuracy: 0.6911 - val_loss: 0.6089 - val_weighted_accuracy: 0.6911\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6955 - loss: 0.6145 - weighted_accuracy: 0.6904 - val_accuracy: 0.6881 - val_loss: 0.6081 - val_weighted_accuracy: 0.6881\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7011 - loss: 0.6090 - weighted_accuracy: 0.6978 - val_accuracy: 0.6969 - val_loss: 0.6022 - val_weighted_accuracy: 0.6969\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7084 - loss: 0.6037 - weighted_accuracy: 0.7053 - val_accuracy: 0.6969 - val_loss: 0.5999 - val_weighted_accuracy: 0.6969\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7127 - loss: 0.5989 - weighted_accuracy: 0.7107 - val_accuracy: 0.7054 - val_loss: 0.5943 - val_weighted_accuracy: 0.7054\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7198 - loss: 0.5938 - weighted_accuracy: 0.7188 - val_accuracy: 0.7116 - val_loss: 0.5899 - val_weighted_accuracy: 0.7116\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7250 - loss: 0.5892 - weighted_accuracy: 0.7242 - val_accuracy: 0.7292 - val_loss: 0.5781 - val_weighted_accuracy: 0.7292\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7309 - loss: 0.5843 - weighted_accuracy: 0.7303 - val_accuracy: 0.7220 - val_loss: 0.5815 - val_weighted_accuracy: 0.7220\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7358 - loss: 0.5797 - weighted_accuracy: 0.7369 - val_accuracy: 0.7386 - val_loss: 0.5702 - val_weighted_accuracy: 0.7386\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7409 - loss: 0.5750 - weighted_accuracy: 0.7420 - val_accuracy: 0.7393 - val_loss: 0.5682 - val_weighted_accuracy: 0.7393\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7434 - loss: 0.5709 - weighted_accuracy: 0.7453 - val_accuracy: 0.7401 - val_loss: 0.5666 - val_weighted_accuracy: 0.7401\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7483 - loss: 0.5671 - weighted_accuracy: 0.7508 - val_accuracy: 0.7464 - val_loss: 0.5613 - val_weighted_accuracy: 0.7464\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7513 - loss: 0.5627 - weighted_accuracy: 0.7546 - val_accuracy: 0.7521 - val_loss: 0.5554 - val_weighted_accuracy: 0.7521\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7572 - loss: 0.5583 - weighted_accuracy: 0.7601 - val_accuracy: 0.7563 - val_loss: 0.5499 - val_weighted_accuracy: 0.7563\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7596 - loss: 0.5545 - weighted_accuracy: 0.7627 - val_accuracy: 0.7570 - val_loss: 0.5487 - val_weighted_accuracy: 0.7570\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7633 - loss: 0.5507 - weighted_accuracy: 0.7674 - val_accuracy: 0.7628 - val_loss: 0.5432 - val_weighted_accuracy: 0.7628\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7666 - loss: 0.5469 - weighted_accuracy: 0.7708 - val_accuracy: 0.7615 - val_loss: 0.5438 - val_weighted_accuracy: 0.7615\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7712 - loss: 0.5429 - weighted_accuracy: 0.7764 - val_accuracy: 0.7719 - val_loss: 0.5343 - val_weighted_accuracy: 0.7719\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7737 - loss: 0.5395 - weighted_accuracy: 0.7788 - val_accuracy: 0.7722 - val_loss: 0.5329 - val_weighted_accuracy: 0.7722\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7765 - loss: 0.5360 - weighted_accuracy: 0.7816 - val_accuracy: 0.7719 - val_loss: 0.5331 - val_weighted_accuracy: 0.7719\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7781 - loss: 0.5324 - weighted_accuracy: 0.7844 - val_accuracy: 0.7813 - val_loss: 0.5248 - val_weighted_accuracy: 0.7813\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7805 - loss: 0.5294 - weighted_accuracy: 0.7867 - val_accuracy: 0.7803 - val_loss: 0.5250 - val_weighted_accuracy: 0.7803\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5845 - loss: 0.6793 - weighted_accuracy: 0.5661 - val_accuracy: 0.6576 - val_loss: 0.6351 - val_weighted_accuracy: 0.6576\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6497 - loss: 0.6433 - weighted_accuracy: 0.6410 - val_accuracy: 0.6835 - val_loss: 0.6162 - val_weighted_accuracy: 0.6835\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6800 - loss: 0.6220 - weighted_accuracy: 0.6744 - val_accuracy: 0.7231 - val_loss: 0.5867 - val_weighted_accuracy: 0.7231\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7048 - loss: 0.6029 - weighted_accuracy: 0.7008 - val_accuracy: 0.7138 - val_loss: 0.5913 - val_weighted_accuracy: 0.7138\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7237 - loss: 0.5853 - weighted_accuracy: 0.7231 - val_accuracy: 0.7418 - val_loss: 0.5681 - val_weighted_accuracy: 0.7418\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7410 - loss: 0.5691 - weighted_accuracy: 0.7424 - val_accuracy: 0.7561 - val_loss: 0.5529 - val_weighted_accuracy: 0.7561\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7560 - loss: 0.5541 - weighted_accuracy: 0.7590 - val_accuracy: 0.7735 - val_loss: 0.5341 - val_weighted_accuracy: 0.7735\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7662 - loss: 0.5400 - weighted_accuracy: 0.7703 - val_accuracy: 0.7633 - val_loss: 0.5395 - val_weighted_accuracy: 0.7633\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7746 - loss: 0.5282 - weighted_accuracy: 0.7811 - val_accuracy: 0.7771 - val_loss: 0.5228 - val_weighted_accuracy: 0.7771\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7857 - loss: 0.5167 - weighted_accuracy: 0.7929 - val_accuracy: 0.7903 - val_loss: 0.5081 - val_weighted_accuracy: 0.7903\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.7917 - loss: 0.5058 - weighted_accuracy: 0.7998 - val_accuracy: 0.7942 - val_loss: 0.5003 - val_weighted_accuracy: 0.7942\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8012 - loss: 0.4959 - weighted_accuracy: 0.8104 - val_accuracy: 0.8053 - val_loss: 0.4856 - val_weighted_accuracy: 0.8053\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8040 - loss: 0.4863 - weighted_accuracy: 0.8127 - val_accuracy: 0.8208 - val_loss: 0.4647 - val_weighted_accuracy: 0.8208\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8090 - loss: 0.4776 - weighted_accuracy: 0.8186 - val_accuracy: 0.8145 - val_loss: 0.4680 - val_weighted_accuracy: 0.8145\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8145 - loss: 0.4696 - weighted_accuracy: 0.8247 - val_accuracy: 0.8240 - val_loss: 0.4555 - val_weighted_accuracy: 0.8240\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8187 - loss: 0.4616 - weighted_accuracy: 0.8285 - val_accuracy: 0.8235 - val_loss: 0.4542 - val_weighted_accuracy: 0.8235\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8217 - loss: 0.4541 - weighted_accuracy: 0.8319 - val_accuracy: 0.8293 - val_loss: 0.4450 - val_weighted_accuracy: 0.8293\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.8255 - loss: 0.4474 - weighted_accuracy: 0.8365 - val_accuracy: 0.8350 - val_loss: 0.4319 - val_weighted_accuracy: 0.8350\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8295 - loss: 0.4404 - weighted_accuracy: 0.8403 - val_accuracy: 0.8347 - val_loss: 0.4318 - val_weighted_accuracy: 0.8347\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8309 - loss: 0.4343 - weighted_accuracy: 0.8419 - val_accuracy: 0.8360 - val_loss: 0.4276 - val_weighted_accuracy: 0.8360\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8349 - loss: 0.4277 - weighted_accuracy: 0.8461 - val_accuracy: 0.8423 - val_loss: 0.4154 - val_weighted_accuracy: 0.8423\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8364 - loss: 0.4222 - weighted_accuracy: 0.8483 - val_accuracy: 0.8361 - val_loss: 0.4222 - val_weighted_accuracy: 0.8361\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8368 - loss: 0.4168 - weighted_accuracy: 0.8484 - val_accuracy: 0.8463 - val_loss: 0.4065 - val_weighted_accuracy: 0.8463\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8414 - loss: 0.4115 - weighted_accuracy: 0.8526 - val_accuracy: 0.8387 - val_loss: 0.4134 - val_weighted_accuracy: 0.8387\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8419 - loss: 0.4066 - weighted_accuracy: 0.8539 - val_accuracy: 0.8449 - val_loss: 0.4042 - val_weighted_accuracy: 0.8449\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8459 - loss: 0.4014 - weighted_accuracy: 0.8572 - val_accuracy: 0.8517 - val_loss: 0.3926 - val_weighted_accuracy: 0.8517\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8474 - loss: 0.3967 - weighted_accuracy: 0.8588 - val_accuracy: 0.8530 - val_loss: 0.3907 - val_weighted_accuracy: 0.8530\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8485 - loss: 0.3921 - weighted_accuracy: 0.8598 - val_accuracy: 0.8383 - val_loss: 0.4036 - val_weighted_accuracy: 0.8383\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8505 - loss: 0.3881 - weighted_accuracy: 0.8623 - val_accuracy: 0.8571 - val_loss: 0.3788 - val_weighted_accuracy: 0.8571\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8530 - loss: 0.3836 - weighted_accuracy: 0.8636 - val_accuracy: 0.8547 - val_loss: 0.3814 - val_weighted_accuracy: 0.8547\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5908 - loss: 0.6693 - weighted_accuracy: 0.5819 - val_accuracy: 0.7188 - val_loss: 0.5851 - val_weighted_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6937 - loss: 0.6023 - weighted_accuracy: 0.6904 - val_accuracy: 0.7321 - val_loss: 0.5708 - val_weighted_accuracy: 0.7321\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7440 - loss: 0.5562 - weighted_accuracy: 0.7463 - val_accuracy: 0.7953 - val_loss: 0.4929 - val_weighted_accuracy: 0.7953\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7741 - loss: 0.5201 - weighted_accuracy: 0.7799 - val_accuracy: 0.8130 - val_loss: 0.4611 - val_weighted_accuracy: 0.8130\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7951 - loss: 0.4903 - weighted_accuracy: 0.8020 - val_accuracy: 0.8141 - val_loss: 0.4691 - val_weighted_accuracy: 0.8141\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8100 - loss: 0.4654 - weighted_accuracy: 0.8197 - val_accuracy: 0.8331 - val_loss: 0.4388 - val_weighted_accuracy: 0.8331\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8218 - loss: 0.4436 - weighted_accuracy: 0.8320 - val_accuracy: 0.8450 - val_loss: 0.4143 - val_weighted_accuracy: 0.8450\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8304 - loss: 0.4253 - weighted_accuracy: 0.8408 - val_accuracy: 0.8320 - val_loss: 0.4217 - val_weighted_accuracy: 0.8320\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8377 - loss: 0.4091 - weighted_accuracy: 0.8486 - val_accuracy: 0.8344 - val_loss: 0.4103 - val_weighted_accuracy: 0.8344\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8421 - loss: 0.3954 - weighted_accuracy: 0.8532 - val_accuracy: 0.8457 - val_loss: 0.3930 - val_weighted_accuracy: 0.8457\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.8493 - loss: 0.3812 - weighted_accuracy: 0.8598 - val_accuracy: 0.8640 - val_loss: 0.3614 - val_weighted_accuracy: 0.8640\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8525 - loss: 0.3702 - weighted_accuracy: 0.8626 - val_accuracy: 0.8276 - val_loss: 0.3998 - val_weighted_accuracy: 0.8276\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8572 - loss: 0.3601 - weighted_accuracy: 0.8669 - val_accuracy: 0.8228 - val_loss: 0.4010 - val_weighted_accuracy: 0.8228\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8611 - loss: 0.3514 - weighted_accuracy: 0.8708 - val_accuracy: 0.8646 - val_loss: 0.3505 - val_weighted_accuracy: 0.8646\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8649 - loss: 0.3422 - weighted_accuracy: 0.8748 - val_accuracy: 0.8710 - val_loss: 0.3339 - val_weighted_accuracy: 0.8710\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8669 - loss: 0.3338 - weighted_accuracy: 0.8762 - val_accuracy: 0.8788 - val_loss: 0.3139 - val_weighted_accuracy: 0.8788\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8713 - loss: 0.3272 - weighted_accuracy: 0.8803 - val_accuracy: 0.8760 - val_loss: 0.3218 - val_weighted_accuracy: 0.8760\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8736 - loss: 0.3199 - weighted_accuracy: 0.8828 - val_accuracy: 0.8823 - val_loss: 0.3026 - val_weighted_accuracy: 0.8823\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8772 - loss: 0.3148 - weighted_accuracy: 0.8863 - val_accuracy: 0.8813 - val_loss: 0.3085 - val_weighted_accuracy: 0.8813\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8785 - loss: 0.3079 - weighted_accuracy: 0.8864 - val_accuracy: 0.8831 - val_loss: 0.3029 - val_weighted_accuracy: 0.8831\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8813 - loss: 0.3020 - weighted_accuracy: 0.8894 - val_accuracy: 0.8876 - val_loss: 0.2883 - val_weighted_accuracy: 0.8876\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8838 - loss: 0.2965 - weighted_accuracy: 0.8916 - val_accuracy: 0.8887 - val_loss: 0.2827 - val_weighted_accuracy: 0.8887\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8862 - loss: 0.2906 - weighted_accuracy: 0.8945 - val_accuracy: 0.8893 - val_loss: 0.2839 - val_weighted_accuracy: 0.8893\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8888 - loss: 0.2865 - weighted_accuracy: 0.8966 - val_accuracy: 0.8907 - val_loss: 0.2758 - val_weighted_accuracy: 0.8907\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8893 - loss: 0.2825 - weighted_accuracy: 0.8968 - val_accuracy: 0.8919 - val_loss: 0.2714 - val_weighted_accuracy: 0.8919\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8902 - loss: 0.2774 - weighted_accuracy: 0.8983 - val_accuracy: 0.8930 - val_loss: 0.2694 - val_weighted_accuracy: 0.8930\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8922 - loss: 0.2740 - weighted_accuracy: 0.9001 - val_accuracy: 0.8867 - val_loss: 0.2857 - val_weighted_accuracy: 0.8867\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8933 - loss: 0.2699 - weighted_accuracy: 0.9002 - val_accuracy: 0.8957 - val_loss: 0.2611 - val_weighted_accuracy: 0.8957\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8965 - loss: 0.2656 - weighted_accuracy: 0.9038 - val_accuracy: 0.8932 - val_loss: 0.2715 - val_weighted_accuracy: 0.8932\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8959 - loss: 0.2633 - weighted_accuracy: 0.9030 - val_accuracy: 0.9009 - val_loss: 0.2523 - val_weighted_accuracy: 0.9009\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6151 - loss: 0.6542 - weighted_accuracy: 0.6063 - val_accuracy: 0.7869 - val_loss: 0.4828 - val_weighted_accuracy: 0.7869\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7470 - loss: 0.5257 - weighted_accuracy: 0.7497 - val_accuracy: 0.7223 - val_loss: 0.5382 - val_weighted_accuracy: 0.7223\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.7858 - loss: 0.4619 - weighted_accuracy: 0.7927 - val_accuracy: 0.8102 - val_loss: 0.4364 - val_weighted_accuracy: 0.8102\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 0.4156 - weighted_accuracy: 0.8249 - val_accuracy: 0.8654 - val_loss: 0.3400 - val_weighted_accuracy: 0.8654\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8384 - loss: 0.3794 - weighted_accuracy: 0.8458 - val_accuracy: 0.8492 - val_loss: 0.3632 - val_weighted_accuracy: 0.8492\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8455 - loss: 0.3547 - weighted_accuracy: 0.8538 - val_accuracy: 0.8765 - val_loss: 0.3164 - val_weighted_accuracy: 0.8765\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8554 - loss: 0.3372 - weighted_accuracy: 0.8629 - val_accuracy: 0.8855 - val_loss: 0.2935 - val_weighted_accuracy: 0.8855\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8620 - loss: 0.3219 - weighted_accuracy: 0.8689 - val_accuracy: 0.8899 - val_loss: 0.2806 - val_weighted_accuracy: 0.8899\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8720 - loss: 0.3053 - weighted_accuracy: 0.8778 - val_accuracy: 0.8790 - val_loss: 0.2964 - val_weighted_accuracy: 0.8790\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8757 - loss: 0.2923 - weighted_accuracy: 0.8817 - val_accuracy: 0.8978 - val_loss: 0.2539 - val_weighted_accuracy: 0.8978\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8810 - loss: 0.2824 - weighted_accuracy: 0.8878 - val_accuracy: 0.8989 - val_loss: 0.2537 - val_weighted_accuracy: 0.8989\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8846 - loss: 0.2737 - weighted_accuracy: 0.8901 - val_accuracy: 0.8848 - val_loss: 0.2784 - val_weighted_accuracy: 0.8848\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8920 - loss: 0.2602 - weighted_accuracy: 0.8977 - val_accuracy: 0.8919 - val_loss: 0.2638 - val_weighted_accuracy: 0.8919\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8943 - loss: 0.2513 - weighted_accuracy: 0.8996 - val_accuracy: 0.8357 - val_loss: 0.3614 - val_weighted_accuracy: 0.8357\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8952 - loss: 0.2504 - weighted_accuracy: 0.9007 - val_accuracy: 0.9099 - val_loss: 0.2212 - val_weighted_accuracy: 0.9099\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9003 - loss: 0.2416 - weighted_accuracy: 0.9052 - val_accuracy: 0.8997 - val_loss: 0.2438 - val_weighted_accuracy: 0.8997\n",
      "Epoch 17/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9025 - loss: 0.2337 - weighted_accuracy: 0.9072 - val_accuracy: 0.8606 - val_loss: 0.3126 - val_weighted_accuracy: 0.8606\n",
      "Epoch 18/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9023 - loss: 0.2320 - weighted_accuracy: 0.9065 - val_accuracy: 0.8992 - val_loss: 0.2439 - val_weighted_accuracy: 0.8992\n",
      "Epoch 19/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9043 - loss: 0.2264 - weighted_accuracy: 0.9087 - val_accuracy: 0.9055 - val_loss: 0.2295 - val_weighted_accuracy: 0.9055\n",
      "Epoch 20/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9067 - loss: 0.2220 - weighted_accuracy: 0.9113 - val_accuracy: 0.9174 - val_loss: 0.2102 - val_weighted_accuracy: 0.9174\n",
      "Epoch 21/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9102 - loss: 0.2171 - weighted_accuracy: 0.9142 - val_accuracy: 0.9159 - val_loss: 0.2006 - val_weighted_accuracy: 0.9159\n",
      "Epoch 22/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9128 - loss: 0.2132 - weighted_accuracy: 0.9169 - val_accuracy: 0.9167 - val_loss: 0.2103 - val_weighted_accuracy: 0.9167\n",
      "Epoch 23/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 15ms/step - accuracy: 0.9141 - loss: 0.2099 - weighted_accuracy: 0.9182 - val_accuracy: 0.8882 - val_loss: 0.2424 - val_weighted_accuracy: 0.8882\n",
      "Epoch 24/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9178 - loss: 0.2042 - weighted_accuracy: 0.9222 - val_accuracy: 0.9113 - val_loss: 0.2035 - val_weighted_accuracy: 0.9113\n",
      "Epoch 25/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9169 - loss: 0.2026 - weighted_accuracy: 0.9209 - val_accuracy: 0.9259 - val_loss: 0.1844 - val_weighted_accuracy: 0.9259\n",
      "Epoch 26/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9202 - loss: 0.1965 - weighted_accuracy: 0.9234 - val_accuracy: 0.9261 - val_loss: 0.1820 - val_weighted_accuracy: 0.9261\n",
      "Epoch 27/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9242 - loss: 0.1898 - weighted_accuracy: 0.9286 - val_accuracy: 0.9152 - val_loss: 0.2105 - val_weighted_accuracy: 0.9152\n",
      "Epoch 28/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9211 - loss: 0.1916 - weighted_accuracy: 0.9246 - val_accuracy: 0.9261 - val_loss: 0.1890 - val_weighted_accuracy: 0.9261\n",
      "Epoch 29/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9221 - loss: 0.1896 - weighted_accuracy: 0.9254 - val_accuracy: 0.9254 - val_loss: 0.1784 - val_weighted_accuracy: 0.9254\n",
      "Epoch 30/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.1830 - weighted_accuracy: 0.9296 - val_accuracy: 0.9310 - val_loss: 0.1728 - val_weighted_accuracy: 0.9310\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.6039 - loss: 0.6739 - weighted_accuracy: 0.5933 - val_accuracy: 0.6914 - val_loss: 0.5827 - val_weighted_accuracy: 0.6914\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7311 - loss: 0.5321 - weighted_accuracy: 0.7336 - val_accuracy: 0.8272 - val_loss: 0.4227 - val_weighted_accuracy: 0.8272\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7717 - loss: 0.4699 - weighted_accuracy: 0.7751 - val_accuracy: 0.8615 - val_loss: 0.3336 - val_weighted_accuracy: 0.8615\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8091 - loss: 0.4140 - weighted_accuracy: 0.8142 - val_accuracy: 0.7814 - val_loss: 0.4186 - val_weighted_accuracy: 0.7814\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - accuracy: 0.8222 - loss: 0.3837 - weighted_accuracy: 0.8268 - val_accuracy: 0.8770 - val_loss: 0.2796 - val_weighted_accuracy: 0.8770\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 0.3524 - weighted_accuracy: 0.8440 - val_accuracy: 0.8849 - val_loss: 0.2852 - val_weighted_accuracy: 0.8849\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8494 - loss: 0.3318 - weighted_accuracy: 0.8530 - val_accuracy: 0.8403 - val_loss: 0.3214 - val_weighted_accuracy: 0.8403\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8652 - loss: 0.3089 - weighted_accuracy: 0.8686 - val_accuracy: 0.9025 - val_loss: 0.2343 - val_weighted_accuracy: 0.9025\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8711 - loss: 0.2865 - weighted_accuracy: 0.8750 - val_accuracy: 0.8969 - val_loss: 0.2287 - val_weighted_accuracy: 0.8969\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8774 - loss: 0.2785 - weighted_accuracy: 0.8817 - val_accuracy: 0.7283 - val_loss: 0.5726 - val_weighted_accuracy: 0.7283\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8844 - loss: 0.2648 - weighted_accuracy: 0.8888 - val_accuracy: 0.8838 - val_loss: 0.2721 - val_weighted_accuracy: 0.8838\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8944 - loss: 0.2491 - weighted_accuracy: 0.8981 - val_accuracy: 0.9131 - val_loss: 0.2007 - val_weighted_accuracy: 0.9131\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8941 - loss: 0.2446 - weighted_accuracy: 0.8970 - val_accuracy: 0.9057 - val_loss: 0.2274 - val_weighted_accuracy: 0.9057\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8991 - loss: 0.2398 - weighted_accuracy: 0.9027 - val_accuracy: 0.9240 - val_loss: 0.1875 - val_weighted_accuracy: 0.9240\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9016 - loss: 0.2278 - weighted_accuracy: 0.9052 - val_accuracy: 0.9250 - val_loss: 0.1872 - val_weighted_accuracy: 0.9250\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.9055 - loss: 0.2212 - weighted_accuracy: 0.9086 - val_accuracy: 0.9294 - val_loss: 0.1786 - val_weighted_accuracy: 0.9294\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6050 - loss: 0.6723 - weighted_accuracy: 0.5938 - val_accuracy: 0.7783 - val_loss: 0.5131 - val_weighted_accuracy: 0.7783\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.7098 - loss: 0.5534 - weighted_accuracy: 0.7120 - val_accuracy: 0.7419 - val_loss: 0.5104 - val_weighted_accuracy: 0.7419\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7634 - loss: 0.4742 - weighted_accuracy: 0.7678 - val_accuracy: 0.7589 - val_loss: 0.4559 - val_weighted_accuracy: 0.7589\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7952 - loss: 0.4211 - weighted_accuracy: 0.7997 - val_accuracy: 0.8824 - val_loss: 0.2878 - val_weighted_accuracy: 0.8824\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8148 - loss: 0.3893 - weighted_accuracy: 0.8206 - val_accuracy: 0.8737 - val_loss: 0.2694 - val_weighted_accuracy: 0.8737\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8301 - loss: 0.3562 - weighted_accuracy: 0.8347 - val_accuracy: 0.8942 - val_loss: 0.2582 - val_weighted_accuracy: 0.8942\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8523 - loss: 0.3176 - weighted_accuracy: 0.8562 - val_accuracy: 0.8786 - val_loss: 0.2798 - val_weighted_accuracy: 0.8786\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8573 - loss: 0.3096 - weighted_accuracy: 0.8627 - val_accuracy: 0.7446 - val_loss: 0.5241 - val_weighted_accuracy: 0.7446\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8759 - loss: 0.2744 - weighted_accuracy: 0.8805 - val_accuracy: 0.8513 - val_loss: 0.3018 - val_weighted_accuracy: 0.8513\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8807 - loss: 0.2645 - weighted_accuracy: 0.8845 - val_accuracy: 0.8859 - val_loss: 0.2493 - val_weighted_accuracy: 0.8859\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8853 - loss: 0.2550 - weighted_accuracy: 0.8899 - val_accuracy: 0.8792 - val_loss: 0.2565 - val_weighted_accuracy: 0.8792\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.8940 - loss: 0.2411 - weighted_accuracy: 0.8979 - val_accuracy: 0.9217 - val_loss: 0.1805 - val_weighted_accuracy: 0.9217\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9002 - loss: 0.2286 - weighted_accuracy: 0.9041 - val_accuracy: 0.9257 - val_loss: 0.1779 - val_weighted_accuracy: 0.9257\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.9044 - loss: 0.2156 - weighted_accuracy: 0.9074 - val_accuracy: 0.8700 - val_loss: 0.2785 - val_weighted_accuracy: 0.8700\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9097 - loss: 0.2077 - weighted_accuracy: 0.9132 - val_accuracy: 0.6154 - val_loss: 1.0038 - val_weighted_accuracy: 0.6154\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 13ms/step - accuracy: 0.9119 - loss: 0.2039 - weighted_accuracy: 0.9148 - val_accuracy: 0.9131 - val_loss: 0.2050 - val_weighted_accuracy: 0.9131\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.5948 - loss: 0.6906 - weighted_accuracy: 0.5759 - val_accuracy: 0.7909 - val_loss: 0.4947 - val_weighted_accuracy: 0.7909\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6755 - loss: 0.5920 - weighted_accuracy: 0.6863 - val_accuracy: 0.8217 - val_loss: 0.4351 - val_weighted_accuracy: 0.8217\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7264 - loss: 0.5438 - weighted_accuracy: 0.7267 - val_accuracy: 0.7755 - val_loss: 0.4856 - val_weighted_accuracy: 0.7755\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7660 - loss: 0.4830 - weighted_accuracy: 0.7667 - val_accuracy: 0.8528 - val_loss: 0.3124 - val_weighted_accuracy: 0.8528\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.7985 - loss: 0.4326 - weighted_accuracy: 0.7962 - val_accuracy: 0.8320 - val_loss: 0.3357 - val_weighted_accuracy: 0.8320\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.3990 - weighted_accuracy: 0.8146 - val_accuracy: 0.8765 - val_loss: 0.2738 - val_weighted_accuracy: 0.8765\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8326 - loss: 0.3718 - weighted_accuracy: 0.8328 - val_accuracy: 0.8212 - val_loss: 0.3772 - val_weighted_accuracy: 0.8212\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8467 - loss: 0.3403 - weighted_accuracy: 0.8482 - val_accuracy: 0.8802 - val_loss: 0.2793 - val_weighted_accuracy: 0.8802\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8580 - loss: 0.3154 - weighted_accuracy: 0.8589 - val_accuracy: 0.7850 - val_loss: 0.4831 - val_weighted_accuracy: 0.7850\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.8592 - loss: 0.3119 - weighted_accuracy: 0.8615 - val_accuracy: 0.8546 - val_loss: 0.3276 - val_weighted_accuracy: 0.8546\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8693 - loss: 0.2929 - weighted_accuracy: 0.8713 - val_accuracy: 0.9026 - val_loss: 0.2235 - val_weighted_accuracy: 0.9026\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8774 - loss: 0.2695 - weighted_accuracy: 0.8803 - val_accuracy: 0.9109 - val_loss: 0.1961 - val_weighted_accuracy: 0.9109\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.8859 - loss: 0.2599 - weighted_accuracy: 0.8882 - val_accuracy: 0.9111 - val_loss: 0.2158 - val_weighted_accuracy: 0.9111\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8886 - loss: 0.2573 - weighted_accuracy: 0.8922 - val_accuracy: 0.9225 - val_loss: 0.1911 - val_weighted_accuracy: 0.9225\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.8991 - loss: 0.2388 - weighted_accuracy: 0.9011 - val_accuracy: 0.9168 - val_loss: 0.1860 - val_weighted_accuracy: 0.9168\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9071 - loss: 0.2175 - weighted_accuracy: 0.9086 - val_accuracy: 0.9174 - val_loss: 0.1959 - val_weighted_accuracy: 0.9174\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.5517 - loss: 0.9112 - weighted_accuracy: 0.5045 - val_accuracy: 0.5192 - val_loss: 0.6944 - val_weighted_accuracy: 0.5192\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6074 - loss: 0.6912 - weighted_accuracy: 0.5222 - val_accuracy: 0.6935 - val_loss: 0.6893 - val_weighted_accuracy: 0.6935\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6182 - loss: 0.6915 - weighted_accuracy: 0.5050 - val_accuracy: 0.6941 - val_loss: 0.6927 - val_weighted_accuracy: 0.6941\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.6202 - loss: 0.6908 - weighted_accuracy: 0.5183 - val_accuracy: 0.6680 - val_loss: 0.6824 - val_weighted_accuracy: 0.6680\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6445 - loss: 0.6913 - weighted_accuracy: 0.5116 - val_accuracy: 0.6933 - val_loss: 0.6780 - val_weighted_accuracy: 0.6933\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.6468 - loss: 0.6918 - weighted_accuracy: 0.5027 - val_accuracy: 0.6931 - val_loss: 0.6928 - val_weighted_accuracy: 0.6931\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5786 - loss: 0.6915 - weighted_accuracy: 0.5043 - val_accuracy: 0.6480 - val_loss: 0.6610 - val_weighted_accuracy: 0.6480\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4860 - loss: 0.6918 - weighted_accuracy: 0.4991 - val_accuracy: 0.3112 - val_loss: 0.6939 - val_weighted_accuracy: 0.3112\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4713 - loss: 0.6886 - weighted_accuracy: 0.5160 - val_accuracy: 0.7159 - val_loss: 0.6658 - val_weighted_accuracy: 0.7159\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.6549 - loss: 0.6819 - weighted_accuracy: 0.5544 - val_accuracy: 0.3067 - val_loss: 0.7000 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5166 - loss: 0.6915 - weighted_accuracy: 0.4982 - val_accuracy: 0.3080 - val_loss: 0.6995 - val_weighted_accuracy: 0.3080\n",
      "Epoch 12/30\n",
      "\u001b[1m   4/1596\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 44ms/step - accuracy: 0.2852 - loss: 0.6790 - weighted_accuracy: 0.4699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 18:46:16.879739: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388736 bytes after encountering the first element of size 8388736 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n",
      "2024-11-13 18:46:16.880122: W tensorflow/core/kernels/data/prefetch_autotuner.cc:52] Prefetch autotuner tried to allocate 8388992 bytes after encountering the first element of size 8388992 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.4418 - loss: 0.6908 - weighted_accuracy: 0.5168 - val_accuracy: 0.3078 - val_loss: 0.6962 - val_weighted_accuracy: 0.3078\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5271 - loss: 0.6919 - weighted_accuracy: 0.4969 - val_accuracy: 0.3084 - val_loss: 0.6950 - val_weighted_accuracy: 0.3084\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5156 - loss: 0.6918 - weighted_accuracy: 0.5038 - val_accuracy: 0.3089 - val_loss: 0.6935 - val_weighted_accuracy: 0.3089\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5729 - loss: 0.6917 - weighted_accuracy: 0.4973 - val_accuracy: 0.3090 - val_loss: 0.6959 - val_weighted_accuracy: 0.3090\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5429 - loss: 0.6918 - weighted_accuracy: 0.4982 - val_accuracy: 0.3094 - val_loss: 0.6963 - val_weighted_accuracy: 0.3094\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Epoch 1/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 15ms/step - accuracy: 0.5422 - loss: 1.3444 - weighted_accuracy: 0.4954 - val_accuracy: 0.3067 - val_loss: 0.6939 - val_weighted_accuracy: 0.3067\n",
      "Epoch 2/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5455 - loss: 0.6919 - weighted_accuracy: 0.4952 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 3/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5504 - loss: 0.6920 - weighted_accuracy: 0.4943 - val_accuracy: 0.6934 - val_loss: 0.6931 - val_weighted_accuracy: 0.6934\n",
      "Epoch 4/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5476 - loss: 0.6923 - weighted_accuracy: 0.4915 - val_accuracy: 0.6933 - val_loss: 0.6925 - val_weighted_accuracy: 0.6933\n",
      "Epoch 5/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5547 - loss: 0.6921 - weighted_accuracy: 0.4987 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 6/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.5434 - loss: 0.6922 - weighted_accuracy: 0.4942 - val_accuracy: 0.3067 - val_loss: 0.6932 - val_weighted_accuracy: 0.3067\n",
      "Epoch 7/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5405 - loss: 0.6921 - weighted_accuracy: 0.4939 - val_accuracy: 0.3067 - val_loss: 0.6950 - val_weighted_accuracy: 0.3067\n",
      "Epoch 8/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5484 - loss: 0.6919 - weighted_accuracy: 0.4976 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 9/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5543 - loss: 0.6919 - weighted_accuracy: 0.4936 - val_accuracy: 0.3067 - val_loss: 0.6935 - val_weighted_accuracy: 0.3067\n",
      "Epoch 10/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5600 - loss: 0.6920 - weighted_accuracy: 0.4975 - val_accuracy: 0.3067 - val_loss: 0.6937 - val_weighted_accuracy: 0.3067\n",
      "Epoch 11/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.5504 - loss: 0.6920 - weighted_accuracy: 0.4957 - val_accuracy: 0.3067 - val_loss: 0.6948 - val_weighted_accuracy: 0.3067\n",
      "Epoch 12/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5435 - loss: 0.6919 - weighted_accuracy: 0.4967 - val_accuracy: 0.3067 - val_loss: 0.6934 - val_weighted_accuracy: 0.3067\n",
      "Epoch 13/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5449 - loss: 0.6919 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6954 - val_weighted_accuracy: 0.3067\n",
      "Epoch 14/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5406 - loss: 0.6921 - weighted_accuracy: 0.4947 - val_accuracy: 0.3067 - val_loss: 0.6940 - val_weighted_accuracy: 0.3067\n",
      "Epoch 15/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.5662 - loss: 0.6920 - weighted_accuracy: 0.4970 - val_accuracy: 0.3067 - val_loss: 0.6960 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16/30\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.5359 - loss: 0.6921 - weighted_accuracy: 0.4930 - val_accuracy: 0.3067 - val_loss: 0.6961 - val_weighted_accuracy: 0.3067\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-5, -1, 9)\n",
    "lr_dir = os.path.join(LOG_DIR, \"learning_rate\")\n",
    "\n",
    "loss = \"binary_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "weighted_metrics = [\"accuracy\"]\n",
    "early_stopping = EarlyStopping(patience=8, start_from_epoch=8, restore_best_weights=True, verbose=1)\n",
    "\n",
    "models = [{model: None, history: None} for _ in learning_rates]\n",
    "\n",
    "for i, learning_rate in enumerate(learning_rates):\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model = simple_nn()\n",
    "    model.name = f\"simplenn_lr_{learning_rate}\"\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics, weighted_metrics=weighted_metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(lr_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1,\n",
    "                                                    write_images=True)\n",
    "\n",
    "    history = model.fit(x=train_ds, validation_data=valid_ds, batch_size=batch_size, epochs=30,\n",
    "                        class_weight=class_weights, callbacks=[tensorboard_cb, early_stopping])\n",
    "    models[i][\"model\"] = model\n",
    "    models[i][\"history\"] = history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8436.973568"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes = 128 * 256 * 4 * 64369\n",
    "mb = bytes / 1000 / 1000\n",
    "mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.longdouble('0.64000000000000007106')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float128(0.8)*np.float128(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
